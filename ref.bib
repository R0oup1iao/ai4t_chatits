@misc{aksu_xforecast_2024,
  title      = {{XForecast}: Evaluating Natural Language Explanations for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2410.14180},
  doi        = {10.48550/arXiv.2410.14180},
  shorttitle = {{XForecast}},
  abstract   = {Time series forecasting aids decision-making, especially for stakeholders who rely on accurate predictions, making it very important to understand and explain these models to ensure informed decisions. Traditional explainable {AI} ({XAI}) methods, which underline feature or temporal importance, often require expert knowledge. In contrast, natural language explanations ({NLEs}) are more accessible to laypeople. However, evaluating forecast {NLEs} is difficult due to the complex causal relationships in time series data. To address this, we introduce two new performance metrics based on simulatability, assessing how well a human surrogate can predict model forecasts using the explanations. Experiments show these metrics differentiate good from poor explanations and align with human judgments. Utilizing these metrics, we further evaluate the ability of state-of-the-art large language models ({LLMs}) to generate explanations for time series data, finding that numerical reasoning, rather than model size, is the main factor influencing explanation quality.},
  number     = {{arXiv}:2410.14180},
  publisher  = {{arXiv}},
  author     = {Aksu, Taha and Liu, Chenghao and Saha, Amrita and Tan, Sarah and Xiong, Caiming and Sahoo, Doyen},
  urldate    = {2024-10-23},
  date       = {2024-10-21},
  eprinttype = {arxiv},
  eprint     = {2410.14180},
  keywords   = {Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\QAQ6HAJE\\Aksu 等 - 2024 - XForecast Evaluating Natural Language Explanations for Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\AWM3ELY5\\2410.html:text/html}
}

@article{li_diffusion_2017,
	title = {Diffusion convolutional recurrent neural network: Data-driven traffic forecasting},
	journaltitle = {{arXiv} preprint {arXiv}:1707.01926},
	shortjournal = {{arXiv} preprint {arXiv}:1707.01926},
	author = {Li, Yaguang and Yu, Rose and Shahabi, Cyrus and Liu, Yan},
	date = {2017},
}

@article{wu_graph_2019,
	title = {Graph wavenet for deep spatial-temporal graph modeling},
	journaltitle = {{arXiv} preprint {arXiv}:1906.00121},
	shortjournal = {{arXiv} preprint {arXiv}:1906.00121},
	author = {Wu, Zonghan and Pan, Shirui and Long, Guodong and Jiang, Jing and Zhang, Chengqi},
	date = {2019},
}

@misc{ansari_chronos_2024,
  title      = {Chronos: Learning the Language of Time Series},
  url        = {http://arxiv.org/abs/2403.07815},
  shorttitle = {Chronos},
  abstract   = {We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.},
  number     = {{arXiv}:2403.07815},
  publisher  = {{arXiv}},
  author     = {Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Sundar and Arango, Sebastian Pineda and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Mahoney, Michael W. and Torkkola, Kari and Wilson, Andrew Gordon and Bohlke-Schneider, Michael and Wang, Yuyang},
  urldate    = {2024-03-18},
  date       = {2024-03-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.07815 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_Chronos_Ansari et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9NYTDRK9\\2024_Chronos_Ansari et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\G3LBUSF7\\2403.html:text/html}
}

@misc{arango_chronosx_2025,
  title      = {{ChronosX}: Adapting Pretrained Time Series Models with Exogenous Variables},
  url        = {http://arxiv.org/abs/2503.12107},
  doi        = {10.48550/arXiv.2503.12107},
  shorttitle = {{ChronosX}},
  abstract   = {Covariates provide valuable information on external factors that influence time series and are critical in many real-world time series forecasting tasks. For example, in retail, covariates may indicate promotions or peak dates such as holiday seasons that heavily influence demand forecasts. Recent advances in pretraining large language model architectures for time series forecasting have led to highly accurate forecasters. However, the majority of these models do not readily use covariates as they are often specific to a certain task or domain. This paper introduces a new method to incorporate covariates into pretrained time series forecasting models. Our proposed approach incorporates covariate information into pretrained forecasting models through modular blocks that inject past and future covariate information, without necessarily modifying the pretrained model in consideration. In order to evaluate our approach, we introduce a benchmark composed of 32 different synthetic datasets with varying dynamics to evaluate the effectivity of forecasting models with covariates. Extensive evaluations on both synthetic and real datasets show that our approach effectively incorporates covariate information into pretrained models, outperforming existing baselines.},
  number     = {{arXiv}:2503.12107},
  publisher  = {{arXiv}},
  author     = {Arango, Sebastian Pineda and Mercado, Pedro and Kapoor, Shubham and Ansari, Abdul Fatir and Stella, Lorenzo and Shen, Huibin and Senetaire, Hugo and Turkmen, Caner and Shchur, Oleksandr and Maddix, Danielle C. and Bohlke-Schneider, Michael and Wang, Yuyang and Rangapuram, Syama Sundar},
  urldate    = {2025-03-27},
  date       = {2025-03-15},
  eprinttype = {arxiv},
  eprint     = {2503.12107 [cs]},
  note       = {{TLDR}: This paper introduces a new method to incorporate covariates into pretrained time series forecasting models through modular blocks that inject past and future covariate information, without necessarily modifying the pretrained model in consideration.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\2JY92K66\\Arango 等 - 2025 - ChronosX Adapting Pretrained Time Series Models with Exogenous Variables.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\Y82REGZL\\2503.html:text/html}
}

@misc{ashutosh_llms_2025,
  title      = {{LLMs} can see and hear without any training},
  url        = {http://arxiv.org/abs/2501.18096},
  doi        = {10.48550/arXiv.2501.18096},
  abstract   = {We present {MILS}: Multimodal Iterative {LLM} Solver, a surprisingly simple, training-free approach, to imbue multimodal capabilities into your favorite {LLM}. Leveraging their innate ability to perform multi-step reasoning, {MILS} prompts the {LLM} to generate candidate outputs, each of which are scored and fed back iteratively, eventually generating a solution to the task. This enables various applications that typically require training specialized models on task-specific data. In particular, we establish a new state-of-the-art on emergent zero-shot image, video and audio captioning. {MILS} seamlessly applies to media generation as well, discovering prompt rewrites to improve text-to-image generation, and even edit prompts for style transfer! Finally, being a gradient-free optimization approach, {MILS} can invert multimodal embeddings into text, enabling applications like cross-modal arithmetic.},
  number     = {{arXiv}:2501.18096},
  publisher  = {{arXiv}},
  author     = {Ashutosh, Kumar and Gandelsman, Yossi and Chen, Xinlei and Misra, Ishan and Girdhar, Rohit},
  urldate    = {2025-02-21},
  date       = {2025-01-30},
  eprinttype = {arxiv},
  eprint     = {2501.18096 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\XCL5SG6K\\Ashutosh 等 - 2025 - LLMs can see and hear without any training.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\5LX2W5RZ\\2501.html:text/html}
}

@article{avila_data-driven_2020,
  title        = {Data-driven analysis and forecasting of highway traffic dynamics},
  volume       = {11},
  rights       = {2020 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-020-15582-5},
  doi          = {10.1038/s41467-020-15582-5},
  abstract     = {The unpredictable elements involved in a vehicular traffic system, like human interaction and weather, lead to a very complicated, high-dimensional, nonlinear dynamical system. Therefore, it is difficult to develop a mathematical or artificial intelligence model that describes the time evolution of traffic systems. All the while, the ever-increasing demands on transportation systems has left traffic agencies in dire need of a robust method for analyzing and forecasting traffic. Here we demonstrate how the Koopman mode decomposition can offer a model-free, data-driven approach for analyzing and forecasting traffic dynamics. By obtaining a decomposition of data sets collected by the Federal Highway Administration and the California Department of Transportation, we are able to reconstruct observed data, distinguish any growing or decaying patterns, and obtain a hierarchy of previously identified and never before identified spatiotemporal patterns. Furthermore, it is demonstrated how this methodology can be utilized to forecast highway network conditions.},
  pages        = {2090},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Avila, A. M. and Mezić, I.},
  urldate      = {2025-04-18},
  date         = {2020-04-29},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group
                  {TLDR}: Here it is demonstrated how the Koopman mode decomposition can offer a model-free, data-driven approach for analyzing and forecasting traffic dynamics.},
  keywords     = {Applied mathematics, Scientific data},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\VWSKFZJ8\\Avila和Mezić - 2020 - Data-driven analysis and forecasting of highway traffic dynamics.pdf:application/pdf}
}

@misc{beck_xlstm_2024,
  title      = {{xLSTM}: Extended Long Short-Term Memory},
  url        = {http://arxiv.org/abs/2405.04517},
  shorttitle = {{xLSTM}},
  abstract   = {In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory ({LSTM}). Since then, {LSTMs} have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models ({LLMs}). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing {LSTMs} at scale. We now raise a simple question: How far do we get in language modeling when scaling {LSTMs} to billions of parameters, leveraging the latest techniques from modern {LLMs}, but mitigating known limitations of {LSTMs}? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the {LSTM} memory structure, obtaining: (i) {sLSTM} with a scalar memory, a scalar update, and new memory mixing, (ii) {mLSTM} that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these {LSTM} extensions into residual block backbones yields {xLSTM} blocks that are then residually stacked into {xLSTM} architectures. Exponential gating and modified memory structures boost {xLSTM} capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.},
  number     = {{arXiv}:2405.04517},
  publisher  = {{arXiv}},
  author     = {Beck, Maximilian and Pöppel, Korbinian and Spanring, Markus and Auer, Andreas and Prudnikova, Oleksandra and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
  urldate    = {2024-05-09},
  date       = {2024-05-07},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2405.04517 [cs, stat]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZPPZKNAM\\2405.html:text/html;Beck 等 - 2024 - xLSTM Extended Long Short-Term Memory.pdf:C\:\\Users\\yanha\\Zotero\\storage\\T2H5VR7Y\\Beck 等 - 2024 - xLSTM Extended Long Short-Term Memory.pdf:application/pdf}
}

@misc{behnamghader_llm2vec_2024,
  title      = {{LLM}2Vec: Large Language Models Are Secretly Powerful Text Encoders},
  url        = {http://arxiv.org/abs/2404.05961},
  doi        = {10.48550/arXiv.2404.05961},
  shorttitle = {{LLM}2Vec},
  abstract   = {Large decoder-only language models ({LLMs}) are the state-of-the-art models on most of today's {NLP} tasks and benchmarks. Yet, the community is only slowly adopting these models for text embedding tasks, which require rich contextualized representations. In this work, we introduce {LLM}2Vec, a simple unsupervised approach that can transform any decoder-only {LLM} into a strong text encoder. {LLM}2Vec consists of three simple steps: 1) enabling bidirectional attention, 2) masked next token prediction, and 3) unsupervised contrastive learning. We demonstrate the effectiveness of {LLM}2Vec by applying it to 3 popular {LLMs} ranging from 1.3B to 7B parameters and evaluate the transformed models on English word- and sequence-level tasks. We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark ({MTEB}). Moreover, when combining {LLM}2Vec with supervised contrastive learning, we achieve state-of-the-art performance on {MTEB} among models that train only on publicly available data. Our strong empirical results and extensive analysis demonstrate that {LLMs} can be effectively transformed into universal text encoders in a parameter-efficient manner without the need for expensive adaptation or synthetic {GPT}-4 generated data.},
  number     = {{arXiv}:2404.05961},
  publisher  = {{arXiv}},
  author     = {{BehnamGhader}, Parishad and Adlakha, Vaibhav and Mosbach, Marius and Bahdanau, Dzmitry and Chapados, Nicolas and Reddy, Siva},
  urldate    = {2024-05-06},
  date       = {2024-04-08},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.05961 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, ⭐⭐⭐⭐},
  file       = {2024_LLM2Vec_BehnamGhader et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\M8I66CH8\\2024_LLM2Vec_BehnamGhader et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4KUXRSGI\\2404.html:text/html}
}

@misc{behrouz_mambamixer_2024,
  title      = {{MambaMixer}: Efficient Selective State Space Models with Dual Token and Channel Selection},
  url        = {http://arxiv.org/abs/2403.19888},
  shorttitle = {{MambaMixer}},
  abstract   = {Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models ({SSMs}), and more specifically Selective State Space Models, with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the success of {SSMs}, we present {MambaMixer}, a new architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels, called Selective Token and Channel Mixer. {MambaMixer} connects selective mixers using a weighted averaging mechanism, allowing layers to have direct access to early features. As a proof of concept, we design Vision {MambaMixer} ({ViM}2) and Time Series {MambaMixer} ({TSM}2) architectures based on the {MambaMixer} block and explore their performance in various vision and time series forecasting tasks. Our results underline the importance of selective mixing across both tokens and channels. In {ImageNet} classification, object detection, and semantic segmentation tasks, {ViM}2 achieves competitive performance with well-established vision models and outperforms {SSM}-based vision models. In time series forecasting, {TSM}2 achieves outstanding performance compared to state-of-the-art methods while demonstrating significantly improved computational cost. These results show that while Transformers, cross-channel attention, and {MLPs} are sufficient for good performance in time series forecasting, neither is necessary.},
  number     = {{arXiv}:2403.19888},
  publisher  = {{arXiv}},
  author     = {Behrouz, Ali and Santacatterina, Michele and Zabih, Ramin},
  urldate    = {2024-04-02},
  date       = {2024-03-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.19888 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2024_MambaMixer_Behrouz et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\FNNCBQGJ\\2024_MambaMixer_Behrouz et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\FZT9FDLD\\2403.html:text/html}
}

@misc{bogahawatte_rethinking_2024,
  title      = {Rethinking Time Series Forecasting with {LLMs} via Nearest Neighbor Contrastive Learning},
  url        = {http://arxiv.org/abs/2412.04806},
  doi        = {10.48550/arXiv.2412.04806},
  abstract   = {Adapting Large Language Models ({LLMs}) that are extensively trained on abundant text data, and customizing the input prompt to enable time series forecasting has received considerable attention. While recent work has shown great potential for adapting the learned prior of {LLMs}, the formulation of the prompt to finetune {LLMs} remains challenging as prompt should be aligned with time series data. Additionally, current approaches do not effectively leverage word token embeddings which embody the rich representation space learned by {LLMs}. This emphasizes the need for a robust approach to formulate the prompt which utilizes the word token embeddings while effectively representing the characteristics of the time series. To address these challenges, we propose {NNCL}-{TLLM}: Nearest Neighbor Contrastive Learning for Time series forecasting via {LLMs}. First, we generate time series compatible text prototypes such that each text prototype represents both word token embeddings in its neighborhood and time series characteristics via end-to-end finetuning. Next, we draw inspiration from Nearest Neighbor Contrastive Learning to formulate the prompt while obtaining the top-\$k\$ nearest neighbor time series compatible text prototypes. We then fine-tune the layer normalization and positional embeddings of the {LLM}, keeping the other layers intact, reducing the trainable parameters and decreasing the computational cost. Our comprehensive experiments demonstrate that {NNCL}-{TLLM} outperforms in few-shot forecasting while achieving competitive or superior performance over the state-of-the-art methods in long-term and short-term forecasting tasks.},
  number     = {{arXiv}:2412.04806},
  publisher  = {{arXiv}},
  author     = {Bogahawatte, Jayanie and Seneviratne, Sachith and Perera, Maneesha and Halgamuge, Saman},
  urldate    = {2024-12-12},
  date       = {2024-12-06},
  eprinttype = {arxiv},
  eprint     = {2412.04806 [cs]},
  note       = {{TLDR}: {NCL}-{TLLM}: Nearest Neighbor Contrastive Learning for Time series forecasting via {LLMs} outperforms in few-shot forecasting while achieving competitive or superior performance over the state-of-the-art methods in long-term and short-term forecasting tasks.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\UMHRCM8S\\Bogahawatte 等 - 2024 - Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UKFIRRXZ\\2412.html:text/html}
}

@misc{cai_msgnet_2023,
  title      = {{MSGNet}: Learning Multi-Scale Inter-Series Correlations for Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2401.00423},
  shorttitle = {{MSGNet}},
  abstract   = {Multivariate time series forecasting poses an ongoing challenge across various disciplines. Time series data often exhibit diverse intra-series and inter-series correlations, contributing to intricate and interwoven dependencies that have been the focus of numerous studies. Nevertheless, a significant research gap remains in comprehending the varying inter-series correlations across different time scales among multiple time series, an area that has received limited attention in the literature. To bridge this gap, this paper introduces {MSGNet}, an advanced deep learning model designed to capture the varying inter-series correlations across multiple time scales using frequency domain analysis and adaptive graph convolution. By leveraging frequency domain analysis, {MSGNet} effectively extracts salient periodic patterns and decomposes the time series into distinct time scales. The model incorporates a self-attention mechanism to capture intra-series dependencies, while introducing an adaptive mixhop graph convolution layer to autonomously learn diverse inter-series correlations within each time scale. Extensive experiments are conducted on several real-world datasets to showcase the effectiveness of {MSGNet}. Furthermore, {MSGNet} possesses the ability to automatically learn explainable multi-scale inter-series correlations, exhibiting strong generalization capabilities even when applied to out-of-distribution samples.},
  number     = {{arXiv}:2401.00423},
  publisher  = {{arXiv}},
  author     = {Cai, Wanlin and Liang, Yuxuan and Liu, Xianggen and Feng, Jianshuai and Wu, Yuankai},
  urldate    = {2024-01-05},
  date       = {2023-12-31},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.00423 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\M5TI8JTC\\2401.html:text/html;Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\ENH2Q4LT\\Cai 等 - 2023 - MSGNet Learning Multi-Scale Inter-Series Correlat.pdf:application/pdf}
}

@misc{cai_timeseriesexam_2024,
  title      = {{TimeSeriesExam}: A time series understanding exam},
  url        = {http://arxiv.org/abs/2410.14752},
  doi        = {10.48550/arXiv.2410.14752},
  shorttitle = {{TimeSeriesExam}},
  abstract   = {Large Language Models ({LLMs}) have recently demonstrated a remarkable ability to model time series data. These capabilities can be partly explained if {LLMs} understand basic time series concepts. However, our knowledge of what these models understand about time series data remains relatively limited. To address this gap, we introduce {TimeSeriesExam}, a configurable and scalable multiple-choice question exam designed to assess {LLMs} across five core time series understanding categories: pattern recognition, noise understanding, similarity analysis, anomaly detection, and causality analysis. {TimeSeriesExam} comprises of over 700 questions, procedurally generated using 104 carefully curated templates and iteratively refined to balance difficulty and their ability to discriminate good from bad models. We test 7 state-of-the-art {LLMs} on the {TimeSeriesExam} and provide the first comprehensive evaluation of their time series understanding abilities. Our results suggest that closed-source models such as {GPT}-4 and Gemini understand simple time series concepts significantly better than their open-source counterparts, while all models struggle with complex concepts such as causality analysis. We believe that the ability to programatically generate questions is fundamental to assessing and improving {LLM}'s ability to understand and reason about time series data.},
  number     = {{arXiv}:2410.14752},
  publisher  = {{arXiv}},
  author     = {Cai, Yifu and Choudhry, Arjun and Goswami, Mononito and Dubrawski, Artur},
  urldate    = {2024-12-31},
  date       = {2024-10-18},
  eprinttype = {arxiv},
  eprint     = {2410.14752 [cs]},
  note       = {{TLDR}: This work introduces {TimeSeriesExam}, a configurable and scalable multiple-choice question exam designed to assess {LLMs} across five core time series understanding categories: pattern recognition, noise understanding, similarity analysis, anomaly detection, and causality analysis.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\3RLXYXZ6\\Cai 等 - 2024 - TimeSeriesExam A time series understanding exam.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JBWQ5B45\\2410.html:text/html}
}

@misc{cao_tempo_2023,
  title      = {{TEMPO}: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2310.04948},
  shorttitle = {{TEMPO}},
  abstract   = {The past decade has witnessed significant advances in time series modeling with deep learning. While achieving state-of-the-art results, the best-performing architectures vary highly across applications and domains. Meanwhile, for natural language processing, the Generative Pre-trained Transformer ({GPT}) has demonstrated impressive performance via training one general-purpose model across various textual datasets. It is intriguing to explore whether {GPT}-type architectures can be effective for time series, capturing the intrinsic dynamic attributes and leading to significant accuracy improvements. In this paper, we propose a novel framework, {TEMPO}, that can effectively learn time series representations. We focus on utilizing two essential inductive biases of the time series task for pre-trained models: (i) decomposition of the complex interaction between trend, seasonal and residual components; and (ii) introducing the selection-based prompts to facilitate distribution adaptation in non-stationary time series. {TEMPO} expands the capability for dynamically modeling real-world temporal phenomena from data within diverse domains. Our experiments demonstrate the superior performance of {TEMPOover} state-of-the-art methods on a number of time series benchmark datasets. This performance gain is observed not only in standard supervised learning settings but also in scenarios involving previously unseen datasets as well as in scenarios with multi-modal inputs. This compelling finding highlights {TEMPO}’s potential to constitute a foundational model-building framework.},
  number     = {{arXiv}:2310.04948},
  publisher  = {{arXiv}},
  author     = {Cao, Defu and Jia, Furong and Arik, Sercan O. and Pfister, Tomas and Zheng, Yixiang and Ye, Wen and Liu, Yan},
  urldate    = {2023-12-08},
  date       = {2023-10-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.04948 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language, /unread},
  file       = {2023_TEMPO_Cao et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\U8DK5LJG\\2023_TEMPO_Cao et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\GBJGW3IX\\2310.html:text/html}
}

@article{castro_time_2023,
  title        = {Time series causal relationships discovery through feature importance and ensemble models},
  volume       = {13},
  rights       = {2023 The Author(s)},
  issn         = {2045-2322},
  url          = {https://www.nature.com/articles/s41598-023-37929-w},
  doi          = {10.1038/s41598-023-37929-w},
  abstract     = {Inferring causal relationships from observational data is a key challenge in understanding the interpretability of Machine Learning models. Given the ever-increasing amount of observational data available in many areas, Machine Learning algorithms used for forecasting have become more complex, leading to a less understandable path of how a decision is made by the model. To address this issue, we propose leveraging ensemble models, e.g., Random Forest, to assess which input features the trained model prioritizes when making a forecast and, in this way, establish causal relationships between the variables. The advantage of these algorithms lies in their ability to provide feature importance, which allows us to build the causal network. We present our methodology to estimate causality in time series from oil field production. As it is difficult to extract causal relations from a real field, we also included a synthetic oil production dataset and a weather dataset, which is also synthetic, to provide the ground truth. We aim to perform causal discovery, i.e., establish the existing connections between the variables in each dataset. Through an iterative process of improving the forecasting of a target’s value, we evaluate whether the forecasting improves by adding information from a new potential driver; if so, we state that the driver causally affects the target. On the oil field-related datasets, our causal analysis results agree with the interwell connections already confirmed by tracer information; whenever the tracer data are available, we used it as our ground truth. This consistency between both estimated and confirmed connections provides us the confidence about the effectiveness of our proposed methodology. To our knowledge, this is the first time causal analysis using solely production data is employed to discover interwell connections in an oil field dataset.},
  pages        = {11402},
  number       = {1},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  author       = {Castro, Manuel and Mendes Júnior, Pedro Ribeiro and Soriano-Vargas, Aurea and de Oliveira Werneck, Rafael and Moreira Gonçalves, Maiara and Lusquino Filho, Leopoldo and Moura, Renato and Zampieri, Marcelo and Linares, Oscar and Ferreira, Vitor and Ferreira, Alexandre and Davólio, Alessandra and Schiozer, Denis and Rocha, Anderson},
  urldate      = {2024-05-23},
  date         = {2023-07-14},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group},
  keywords     = {/reading, Computer science, Computational science, Fossil fuels},
  file         = {2023_Time series causal relationships discovery through feature importance and_Castro et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\VBNARR98\\2023_Time series causal relationships discovery through feature importance and_Castro et al.pdf:application/pdf}
}

@misc{chang_llm4ts_2023,
  title      = {{LLM}4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained {LLMs}},
  url        = {http://arxiv.org/abs/2308.08469},
  doi        = {10.48550/arXiv.2308.08469},
  shorttitle = {{LLM}4TS},
  abstract   = {In this work, we leverage pre-trained Large Language Models ({LLMs}) to enhance time-series forecasting. Mirroring the growing interest in unifying models for Natural Language Processing and Computer Vision, we envision creating an analogous model for long-term time-series forecasting. Due to limited large-scale time-series data for building robust foundation models, our approach {LLM}4TS focuses on leveraging the strengths of pre-trained {LLMs}. By combining time-series patching with temporal encoding, we have enhanced the capability of {LLMs} to handle time-series data effectively. Inspired by the supervised fine-tuning in chatbot domains, we prioritize a two-stage fine-tuning process: first conducting supervised fine-tuning to orient the {LLM} towards time-series data, followed by task-specific downstream fine-tuning. Furthermore, to unlock the flexibility of pre-trained {LLMs} without extensive parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning ({PEFT}) techniques. Drawing on these innovations, {LLM}4TS has yielded state-of-the-art results in long-term forecasting. Our model has also shown exceptional capabilities as both a robust representation learner and an effective few-shot learner, thanks to the knowledge transferred from the pre-trained {LLM}.},
  number     = {{arXiv}:2308.08469},
  publisher  = {{arXiv}},
  author     = {Chang, Ching and Peng, Wen-Chih and Chen, Tien-Fu},
  urldate    = {2023-10-19},
  date       = {2023-10-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2308.08469 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, /unread},
  file       = {2023_LLM4TS_Chang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_LLM4TS_Chang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\MKGPL2E6\\2308.html:text/html}
}

@article{chen_data-driven_2024,
  title        = {Data-Driven Traffic Simulation: A Comprehensive Review},
  volume       = {9},
  issn         = {2379-8904},
  url          = {https://ieeexplore.ieee.org/abstract/document/10440492},
  doi          = {10.1109/TIV.2024.3367919},
  shorttitle   = {Data-Driven Traffic Simulation},
  abstract     = {Autonomous vehicles ({AVs}) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation. Recent years have witnessed notable advancements in autonomous driving perception and prediction, but the challenge of validating the performance of {AVs} remains largely unresolved. Data-driven microscopic traffic simulation has become an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of enabling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation. However, a comprehensive review of this topic is currently lacking. This paper aims to fill this gap by summarizing relevant studies. The primary objective of this paper is to review current research efforts and provide a futuristic perspective that will benefit future developments in the field. It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms. After overviewing traffic simulation, various datasets and evaluation metrics commonly used are reviewed. The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, deep generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail. Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions.},
  pages        = {4730--4748},
  number       = {4},
  journaltitle = {{IEEE} Transactions on Intelligent Vehicles},
  author       = {Chen, Di and Zhu, Meixin and Yang, Hao and Wang, Xuesong and Wang, Yinhai},
  urldate      = {2024-11-26},
  date         = {2024-04},
  note         = {Conference Name: {IEEE} Transactions on Intelligent Vehicles},
  keywords     = {Roads, ⭐⭐⭐, Autonomous vehicles, Behavioral sciences, autonomous driving, data-driven modeling, learning methods, Microscopy, Reviews, Testing, Traffic control, Traffic simulation},
  file         = {已提交版本:C\:\\Users\\yanha\\Zotero\\storage\\4JZ5FZ6K\\Chen 等 - 2024 - Data-Driven Traffic Simulation A Comprehensive Review.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\yanha\\Zotero\\storage\\WG4IGW4H\\10440492.html:text/html}
}

@misc{chen_eeg_2024,
  title      = {{EEG} Emotion Copilot: Pruning {LLMs} for Emotional {EEG} Interpretation with Assisted Medical Record Generation},
  url        = {http://arxiv.org/abs/2410.00166},
  doi        = {10.48550/arXiv.2410.00166},
  shorttitle = {{EEG} Emotion Copilot},
  abstract   = {In the fields of affective computing ({AC}) and brain-machine interface ({BMI}), the analysis of physiological and behavioral signals to discern individual emotional states has emerged as a critical research frontier. While deep learning-based approaches have made notable strides in {EEG} emotion recognition, particularly in feature extraction and pattern recognition, significant challenges persist in achieving end-to-end emotion computation, including real-time processing, individual adaptation, and seamless user interaction. This paper presents the {EEG} Emotion Copilot, a system leveraging a lightweight large language model ({LLM}) operating in a local setting. The system is designed to first recognize emotional states directly from {EEG} signals, subsequently generate personalized diagnostic and treatment suggestions, and finally support the automation of electronic medical records. The proposed solution emphasizes both the accuracy of emotion recognition and an enhanced user experience, facilitated by an intuitive interface for participant interaction. We further discuss the construction of the data framework, model pruning, training, and deployment strategies aimed at improving real-time performance and computational efficiency. Privacy concerns are also addressed, with a focus on ethical data collection, processing, and the protection of users' personal information. Through these efforts, we aim to advance the application of {AC} in the medical domain, offering innovative approaches to mental health diagnostics and treatment.},
  number     = {{arXiv}:2410.00166},
  publisher  = {{arXiv}},
  author     = {Chen, Hongyu and Zeng, Weiming and Chen, Chengcheng and Cai, Luhui and Wang, Fei and Wang, Lei and Zhang, Wei and Li, Yueyang and Yan, Hongjie and Siok, Wai Ting and Wang, Nizhuan},
  urldate    = {2024-10-23},
  date       = {2024-09-30},
  eprinttype = {arxiv},
  eprint     = {2410.00166},
  note       = {{TLDR}: The {EEG} Emotion Copilot is presented, a system leveraging a lightweight large language model ({LLM}) operating in a local setting designed to first recognize emotional states directly from {EEG} signals, subsequently generate personalized diagnostic and treatment suggestions, and finally support the automation of electronic medical records.},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\WBFW9KCT\\Chen 等 - 2024 - EEG Emotion Copilot Pruning LLMs for Emotional EEG Interpretation with Assisted Medical Record Gene.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4XN3FRKS\\2410.html:text/html}
}

@misc{chen_fcdnet_2023,
  title      = {{FCDNet}: Frequency-Guided Complementary Dependency Modeling for Multivariate Time-Series Forecasting},
  url        = {http://arxiv.org/abs/2312.16450},
  doi        = {10.48550/arXiv.2312.16450},
  shorttitle = {{FCDNet}},
  abstract   = {Multivariate time-series ({MTS}) forecasting is a challenging task in many real-world non-stationary dynamic scenarios. In addition to intra-series temporal signals, the inter-series dependency also plays a crucial role in shaping future trends. How to enable the model's awareness of dependency information has raised substantial research attention. Previous approaches have either presupposed dependency constraints based on domain knowledge or imposed them using real-time feature similarity. However, {MTS} data often exhibit both enduring long-term static relationships and transient short-term interactions, which mutually influence their evolving states. It is necessary to recognize and incorporate the complementary dependencies for more accurate {MTS} prediction. The frequency information in time series reflects the evolutionary rules behind complex temporal dynamics, and different frequency components can be used to well construct long-term and short-term interactive dependency structures between variables. To this end, we propose {FCDNet}, a concise yet effective framework for multivariate time-series forecasting. Specifically, {FCDNet} overcomes the above limitations by applying two light-weight dependency constructors to help extract long- and short-term dependency information adaptively from multi-level frequency patterns. With the growth of input variables, the number of trainable parameters in {FCDNet} only increases linearly, which is conducive to the model's scalability and avoids over-fitting. Additionally, adopting a frequency-based perspective can effectively mitigate the influence of noise within {MTS} data, which helps capture more genuine dependencies. The experimental results on six real-world datasets from multiple fields show that {FCDNet} significantly exceeds strong baselines, with an average improvement of 6.82\% on {MAE}, 4.98\% on {RMSE}, and 4.91\% on {MAPE}.},
  number     = {{arXiv}:2312.16450},
  publisher  = {{arXiv}},
  author     = {Chen, Weijun and Wang, Heyuan and Tian, Ye and Guan, Shijie and Liu, Ning},
  urldate    = {2024-02-06},
  date       = {2023-12-27},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2312.16450 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\QVMV8RZP\\2312.html:text/html;Chen et al_2023_FCDNet.pdf:C\:\\Users\\yanha\\Zotero\\storage\\WEEAEUNK\\Chen et al_2023_FCDNet.pdf:application/pdf}
}

@misc{chen_gatgpt_2023,
  title      = {{GATGPT}: A Pre-trained Large Language Model with Graph Attention Network for Spatiotemporal Imputation},
  url        = {http://arxiv.org/abs/2311.14332},
  doi        = {10.48550/arXiv.2311.14332},
  shorttitle = {{GATGPT}},
  abstract   = {The analysis of spatiotemporal data is increasingly utilized across diverse domains, including transportation, healthcare, and meteorology. In real-world settings, such data often contain missing elements due to issues like sensor malfunctions and data transmission errors. The objective of spatiotemporal imputation is to estimate these missing values by understanding the inherent spatial and temporal relationships in the observed multivariate time series. Traditionally, spatiotemporal imputation has relied on specific, intricate architectures designed for this purpose, which suffer from limited applicability and high computational complexity. In contrast, our approach integrates pre-trained large language models ({LLMs}) into spatiotemporal imputation, introducing a groundbreaking framework, {GATGPT}. This framework merges a graph attention mechanism with {LLMs}. We maintain most of the {LLM} parameters unchanged to leverage existing knowledge for learning temporal patterns, while fine-tuning the upper layers tailored to various applications. The graph attention component enhances the {LLM}'s ability to understand spatial relationships. Through tests on three distinct real-world datasets, our innovative approach demonstrates comparable results to established deep learning benchmarks.},
  number     = {{arXiv}:2311.14332},
  publisher  = {{arXiv}},
  author     = {Chen, Yakun and Wang, Xianzhi and Xu, Guandong},
  urldate    = {2024-01-22},
  date       = {2023-11-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.14332 [cs, stat]},
  keywords   = {/reading, Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {2023_GATGPT_Chen et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\33THYGUB\\2023_GATGPT_Chen et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\XFJYVH5V\\2311.html:text/html}
}

@misc{chen_llm-ts_2024,
  title      = {{LLM}-{TS} Integrator: Integrating {LLM} for Enhanced Time Series Modeling},
  url        = {http://arxiv.org/abs/2410.16489},
  doi        = {10.48550/arXiv.2410.16489},
  shorttitle = {{LLM}-{TS} Integrator},
  abstract   = {Time series{\textasciitilde}({TS}) modeling is essential in dynamic systems like weather prediction and anomaly detection. Recent studies utilize Large Language Models ({LLMs}) for {TS} modeling, leveraging their powerful pattern recognition capabilities. These methods primarily position {LLMs} as the predictive backbone, often omitting the mathematical modeling within traditional {TS} models, such as periodicity. However, disregarding the potential of {LLMs} also overlooks their pattern recognition capabilities. To address this gap, we introduce {\textbackslash}textit\{{LLM}-{TS} Integrator\}, a novel framework that effectively integrates the capabilities of {LLMs} into traditional {TS} modeling. Central to this integration is our {\textbackslash}textit\{mutual information\} module. The core of this {\textbackslash}textit\{mutual information\} module is a traditional {TS} model enhanced with {LLM}-derived insights for improved predictive abilities. This enhancement is achieved by maximizing the mutual information between traditional model's {TS} representations and {LLM}'s textual representation counterparts, bridging the two modalities. Moreover, we recognize that samples vary in importance for two losses: traditional prediction and mutual information maximization. To address this variability, we introduce the {\textbackslash}textit\{sample reweighting\} module to improve information utilization. This module assigns dual weights to each sample: one for prediction loss and another for mutual information loss, dynamically optimizing these weights via bi-level optimization. Our method achieves state-of-the-art or comparable performance across five mainstream {TS} tasks, including short-term and long-term forecasting, imputation, classification, and anomaly detection.},
  number     = {{arXiv}:2410.16489},
  publisher  = {{arXiv}},
  author     = {Chen, Can and Oliveira, Gabriel and Noghabi, Hossein Sharifi and Sylvain, Tristan},
  urldate    = {2024-11-12},
  date       = {2024-10-21},
  eprinttype = {arxiv},
  eprint     = {2410.16489},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\RJ8AGM4W\\Chen 等 - 2024 - LLM-TS Integrator Integrating LLM for Enhanced Time Series Modeling.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\HNEBN433\\2410.html:text/html}
}

@misc{chen_selfie_2024,
  title      = {{SelfIE}: Self-Interpretation of Large Language Model Embeddings},
  url        = {http://arxiv.org/abs/2403.10949},
  doi        = {10.48550/arXiv.2403.10949},
  shorttitle = {{SelfIE}},
  abstract   = {How do large language models ({LLMs}) obtain their answers? The ability to explain and control an {LLM}'s reasoning process is key for reliability, transparency, and future model developments. We propose {SelfIE} (Self-Interpretation of Embeddings), a framework that enables {LLMs} to interpret their own embeddings in natural language by leveraging their ability to respond to inquiries about a given passage. Capable of interpreting open-world concepts in the hidden embeddings, {SelfIE} reveals {LLM} internal reasoning in cases such as making ethical decisions, internalizing prompt injection, and recalling harmful knowledge. {SelfIE}'s text descriptions on hidden embeddings also open up new avenues to control {LLM} reasoning. We propose Supervised Control, which allows editing open-ended concepts while only requiring gradient computation of individual layer. We extend {RLHF} to hidden embeddings and propose Reinforcement Control that erases harmful knowledge in {LLM} without supervision targets.},
  number     = {{arXiv}:2403.10949},
  publisher  = {{arXiv}},
  author     = {Chen, Haozhe and Vondrick, Carl and Mao, Chengzhi},
  urldate    = {2024-04-10},
  date       = {2024-03-25},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.10949 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_SelfIE_Chen et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\EDRAPIHQ\\2024_SelfIE_Chen et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\DZSLE3YA\\2403.html:text/html}
}


@misc{chen_semantic-enhanced_2024,
  title      = {Semantic-Enhanced Representation Learning for Road Networks with Temporal Dynamics},
  url        = {http://arxiv.org/abs/2403.11495},
  doi        = {10.48550/arXiv.2403.11495},
  abstract   = {In this study, we introduce a novel framework called Toast for learning general-purpose representations of road networks, along with its advanced counterpart {DyToast}, designed to enhance the integration of temporal dynamics to boost the performance of various time-sensitive downstream tasks. Specifically, we propose to encode two pivotal semantic characteristics intrinsic to road networks: traffic patterns and traveling semantics. To achieve this, we refine the skip-gram module by incorporating auxiliary objectives aimed at predicting the traffic context associated with a target road segment. Moreover, we leverage trajectory data and design pre-training strategies based on Transformer to distill traveling semantics on road networks. {DyToast} further augments this framework by employing unified trigonometric functions characterized by their beneficial properties, enabling the capture of temporal evolution and dynamic nature of road networks more effectively. With these proposed techniques, we can obtain representations that encode multi-faceted aspects of knowledge within road networks, applicable across both road segment-based applications and trajectory-based applications. Extensive experiments on two real-world datasets across three tasks demonstrate that our proposed framework consistently outperforms the state-of-the-art baselines by a significant margin.},
  number     = {{arXiv}:2403.11495},
  publisher  = {{arXiv}},
  author     = {Chen, Yile and Li, Xiucheng and Cong, Gao and Bao, Zhifeng and Long, Cheng},
  urldate    = {2024-03-26},
  date       = {2024-03-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.11495 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_Semantic-Enhanced Representation Learning for Road Networks with Temporal_Chen et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\AQB9TALR\\2024_Semantic-Enhanced Representation Learning for Road Networks with Temporal_Chen et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\AACJJ8HT\\2403.html:text/html}
}

@misc{chen_similarity_2024,
  title      = {From Similarity to Superiority: Channel Clustering for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2404.01340},
  doi        = {10.48550/arXiv.2404.01340},
  shorttitle = {From Similarity to Superiority},
  abstract   = {Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent ({CI}) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent ({CD}) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adaptable Channel Clustering Module ({CCM}). {CCM} dynamically groups channels characterized by intrinsic similarities and leverages cluster identity instead of channel identity, combining the best of {CD} and {CI} worlds. Extensive experiments on real-world datasets demonstrate that {CCM} can (1) boost the performance of {CI} and {CD} models by an average margin of 2.4\% and 7.2\% on long-term and short-term forecasting, respectively; (2) enable zero-shot forecasting with mainstream time series forecasting models; (3) uncover intrinsic time series patterns among channels and improve interpretability of complex time series models.},
  number     = {{arXiv}:2404.01340},
  publisher  = {{arXiv}},
  author     = {Chen, Jialin and Lenssen, Jan Eric and Feng, Aosong and Hu, Weihua and Fey, Matthias and Tassiulas, Leandros and Leskovec, Jure and Ying, Rex},
  urldate    = {2024-04-15},
  date       = {2024-03-30},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.01340 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\IDYVFWV2\\2404.html:text/html;Chen et al_2024_From Similarity to Superiority.pdf:C\:\\Users\\yanha\\Zotero\\storage\\X6EBQ479\\Chen et al_2024_From Similarity to Superiority.pdf:application/pdf}
}

@article{cheng_development_2024,
  title        = {Development and Validation of a Deep-Learning Network for Detecting Congenital Heart Disease from Multi-View Multi-Modal Transthoracic Echocardiograms},
  volume       = {7},
  url          = {https://spj.science.org/doi/10.34133/research.0319},
  doi          = {10.34133/research.0319},
  abstract     = {Early detection and treatment of congenital heart disease ({CHD}) can significantly improve the prognosis of children. However, inexperienced sonographers often face difficulties in recognizing {CHD} through transthoracic echocardiogram ({TTE}) images. In this study, 2-dimensional (2D) and Doppler {TTEs} of children collected from 2 clinical groups from Beijing Children's Hospital between 2018 and 2022 were analyzed, including views of apical 4 chamber, subxiphoid long-axis view of 2 atria, parasternal long-axis view of the left ventricle, parasternal short-axis view of aorta, and suprasternal long-axis view. A deep learning ({DL}) framework was developed to identify cardiac views, integrate information from various views and modalities, visualize the high-risk region, and predict the probability of the subject being normal or having an atrial septal defect ({ASD}) or a ventricular septaldefect ({VSD}). A total of 1,932 children (1,255 healthy controls, 292 {ASDs}, and 385 {VSDs}) were collected from 2 clinical groups. For view classification, the {DL} model reached a mean [{SD}] accuracy of 0.989 [0.001]. For {CHD} screening, the model using both 2D and Doppler {TTEs} with 5 views achieved a mean [{SD}] area under the receiver operating characteristic curve ({AUC}) of 0.996 [0.000] and an accuracy of 0.994 [0.002] for within-center evaluation while reaching a mean [{SD}] {AUC} of 0.990 [0.003] and an accuracy of 0.993 [0.001] for cross-center test set. For the classification of healthy, {ASD}, and {VSD}, the model reached the mean [{SD}] accuracy of 0.991 [0.002] and 0.986 [0.001] for within- and cross-center evaluation, respectively. The {DL} models aggregating {TTEs} with more modalities and scanning views attained superior performance to approximate that of experienced sonographers. The incorporation of multiple views and modalities of {TTEs} in the model enables accurate identification of children with {CHD} in a noninvasive manner, suggesting the potential to enhance {CHD} detection performance and simplify the screening process.},
  pages        = {0319},
  journaltitle = {Research},
  author       = {Cheng, Mingmei and Wang, Jing and Liu, Xiaofeng and Wang, Yanzhong and Wu, Qun and Wang, Fangyun and Li, Pei and Wang, Binbin and Zhang, Xin and Xie, Wanqing},
  urldate      = {2025-04-15},
  date         = {2024-03-06},
  note         = {Publisher: American Association for the Advancement of Science
                  {TLDR}: A deep learning framework was developed to identify cardiac views, integrate information from various views and modalities, visualize the high-risk region, and predict the probability of the subject being normal or having an atrial septal defect ({ASD}) or a ventricular septaldefect ({VSD}).},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\R5F78D47\\Cheng 等 - 2024 - Development and Validation of a Deep-Learning Network for Detecting Congenital Heart Disease from Mu.pdf:application/pdf}
}

@online{chow_towards_2024,
  title      = {Towards Time Series Reasoning with {LLMs}},
  url        = {https://arxiv.org/abs/2409.11376v1},
  abstract   = {Multi-modal large language models ({MLLMs}) have enabled numerous advances in understanding and reasoning in domains like vision, but we have not yet seen this broad success for time-series. Although prior works on time-series {MLLMs} have shown promising performance in time-series forecasting, very few works show how an {LLM} could be used for time-series reasoning in natural language. We propose a novel multi-modal time-series {LLM} approach that learns generalizable information across various domains with powerful zero-shot performance. First, we train a lightweight time-series encoder on top of an {LLM} to directly extract time-series information. Then, we fine-tune our model with chain-of-thought augmented time-series tasks to encourage the model to generate reasoning paths. We show that our model learns a latent representation that reflects specific time-series features (e.g. slope, frequency), as well as outperforming {GPT}-4o on a set of zero-shot reasoning tasks on a variety of domains.},
  titleaddon = {{arXiv}.org},
  author     = {Chow, Winnie and Gardiner, Lauren and Hallgrímsson, Haraldur T. and Xu, Maxwell A. and Ren, Shirley You},
  urldate    = {2024-10-09},
  date       = {2024-09-17},
  langid     = {english},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\2EJZJPWA\\Chow 等 - 2024 - Towards Time Series Reasoning with LLMs.pdf:application/pdf}
}

@misc{chow_towards_2024-1,
  title      = {Towards Time Series Reasoning with {LLMs}},
  url        = {http://arxiv.org/abs/2409.11376},
  doi        = {10.48550/arXiv.2409.11376},
  abstract   = {Multi-modal large language models ({MLLMs}) have enabled numerous advances in understanding and reasoning in domains like vision, but we have not yet seen this broad success for time-series. Although prior works on time-series {MLLMs} have shown promising performance in time-series forecasting, very few works show how an {LLM} could be used for time-series reasoning in natural language. We propose a novel multi-modal time-series {LLM} approach that learns generalizable information across various domains with powerful zero-shot performance. First, we train a lightweight time-series encoder on top of an {LLM} to directly extract time-series information. Then, we fine-tune our model with chain-of-thought augmented time-series tasks to encourage the model to generate reasoning paths. We show that our model learns a latent representation that reflects specific time-series features (e.g. slope, frequency), as well as outperforming {GPT}-4o on a set of zero-shot reasoning tasks on a variety of domains.},
  number     = {{arXiv}:2409.11376},
  publisher  = {{arXiv}},
  author     = {Chow, Winnie and Gardiner, Lauren and Hallgrímsson, Haraldur T. and Xu, Maxwell A. and Ren, Shirley You},
  urldate    = {2024-12-19},
  date       = {2024-12-04},
  eprinttype = {arxiv},
  eprint     = {2409.11376 [cs]},
  note       = {{TLDR}: A novel multi-modal time-series {LLM} approach that learns generalizable information across various domains with powerful zero-shot performance and shows that the model learns a latent representation that reflects specific time-series features (e.g. slope, frequency).},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\IT3PMYEH\\Chow 等 - 2024 - Towards Time Series Reasoning with LLMs.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\TANMU6AV\\2409.html:text/html}
}

@misc{chuang_understanding_2024,
  title      = {Understanding Different Design Choices in Training Large Time Series Models},
  url        = {http://arxiv.org/abs/2406.14045},
  doi        = {10.48550/arXiv.2406.14045},
  abstract   = {Inspired by Large Language Models ({LLMs}), Time Series Forecasting ({TSF}), a long-standing task in time series analysis, is undergoing a transition towards Large Time Series Models ({LTSMs}), aiming to train universal transformer-based models for {TSF}. However, training {LTSMs} on heterogeneous time series data poses unique challenges, including diverse frequencies, dimensions, and patterns across datasets. Recent endeavors have studied and evaluated various design choices aimed at enhancing {LTSM} training and generalization capabilities, spanning pre-processing techniques, model configurations, and dataset configurations. In this work, we comprehensively analyze these design choices and aim to identify the best practices for training {LTSM}. Moreover, we propose {\textbackslash}emph\{time series prompt\}, a novel statistical prompting strategy tailored to time series data. Furthermore, based on the observations in our analysis, we introduce {\textbackslash}texttt\{{LTSM}-bundle\}, which bundles the best design choices we have identified. Empirical results demonstrate that {\textbackslash}texttt\{{LTSM}-bundle\} achieves superior zero-shot and few-shot performances compared to state-of-the-art {LSTMs} and traditional {TSF} methods on benchmark datasets.},
  number     = {{arXiv}:2406.14045},
  publisher  = {{arXiv}},
  author     = {Chuang, Yu-Neng and Li, Songchen and Yuan, Jiayi and Wang, Guanchu and Lai, Kwei-Herng and Yu, Leisheng and Ding, Sirui and Chang, Chia-Yuan and Tan, Qiaoyu and Zha, Daochen and Hu, Xia},
  urldate    = {2024-07-26},
  date       = {2024-06-20},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.14045 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2024_Understanding Different Design Choices in Training Large Time Series Models_Chuang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CDXTFT7J\\2024_Understanding Different Design Choices in Training Large Time Series Models_Chuang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\9PD8VKFQ\\2406.html:text/html}
}

@inproceedings{darlow_dam_2023,
  title      = {{DAM}: Towards a Foundation Model for Forecasting},
  url        = {https://openreview.net/forum?id=4NhMhElWqP},
  shorttitle = {{DAM}},
  abstract   = {It is challenging to scale time series forecasting models such that they forecast accurately for multiple distinct domains and datasets, all with potentially different underlying collection procedures (e.g., sample resolution), patterns (e.g., periodicity), and prediction requirements (e.g., reconstruction vs. forecasting). We call this general task universal forecasting. Existing methods usually assume that input data is regularly sampled, and they forecast to pre-determined horizons, resulting in failure to generalise outside of the scope of their training. We propose the {DAM} -- a neural model that takes randomly sampled histories and outputs an adjustable basis composition as a continuous function of time for forecasting to non-fixed horizons. It involves three key components: (1) a flexible approach for using randomly sampled histories from a long-tail distribution, that enables an efficient global perspective of the underlying temporal dynamics while retaining focus on the recent history; (2) a transformer backbone that is trained on these actively sampled histories to produce, as representational output, (3) the basis coefficients of a continuous function of time. We show that a single univariate {DAM}, trained on 25 time series datasets, either outperformed or closely matched existing {SoTA} models at multivariate long-term forecasting across 18 datasets, including 8 held-out for zero-shot transfer, even though these models were trained to specialise for each dataset-horizon combination. This single {DAM} excels at zero-shot transfer and very-long-term forecasting, performs well at imputation, is interpretable via basis function composition and attention, can be tuned for different inference-cost requirements, is robust to missing and irregularly sampled data by design.},
  eventtitle = {The Twelfth International Conference on Learning Representations},
  author     = {Darlow, Luke Nicholas and Deng, Qiwen and Hassan, Ahmed and Asenov, Martin and Singh, Rajkarn and Joosen, Artjom and Barker, Adam and Storkey, Amos},
  urldate    = {2024-04-02},
  date       = {2023-10-13},
  langid     = {english},
  keywords   = {/unread},
  file       = {2023_DAM_Darlow et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\VD5BCTHB\\2023_DAM_Darlow et al.pdf:application/pdf}
}

@misc{das_decoder-only_2024,
  title      = {A decoder-only foundation model for time-series forecasting},
  url        = {http://arxiv.org/abs/2310.10688},
  doi        = {10.48550/arXiv.2310.10688},
  abstract   = {Motivated by recent advances in large language models for Natural Language Processing ({NLP}), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset. Our model is based on pretraining a patched-decoder style attention model on a large time-series corpus, and can work well across different forecasting history lengths, prediction lengths and temporal granularities.},
  number     = {{arXiv}:2310.10688},
  publisher  = {{arXiv}},
  author     = {Das, Abhimanyu and Kong, Weihao and Sen, Rajat and Zhou, Yichen},
  urldate    = {2024-05-28},
  date       = {2024-04-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.10688 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_A decoder-only foundation model for time-series forecasting_Das et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\FMV7VPH6\\2024_A decoder-only foundation model for time-series forecasting_Das et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\489NSHPR\\2310.html:text/html}
}

@article{deng_hierarchical_2021,
  title        = {Hierarchical Network with Label Embedding for Contextual Emotion Recognition},
  rights       = {Copyright © 2021 Jiawen Deng and Fuji Ren.},
  url          = {https://spj.science.org/doi/10.34133/2021/3067943},
  doi          = {10.34133/2021/3067943},
  abstract     = {Emotion recognition has been used widely in various applications such as mental health monitoring and emotional management. Usually, emotion recognition is regarded as a text classification task. Emotion recognition is a more complex problem, and the ...},
  journaltitle = {Research},
  author       = {Deng, Jiawen and Ren, Fuji},
  urldate      = {2025-04-15},
  date         = {2021-01-04},
  note         = {Publisher: {AAAS}
                  {TLDR}: A hierarchical model with label embedding is proposed for contextual emotion recognition to give emotion correlation-based recognition, and experimental results indicate that the approach has a satisfying performance in textual emotion recognition task.},
  file         = {PubMed Central Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\3XQGXBBJ\\Deng和Ren - 2021 - Hierarchical Network with Label Embedding for Contextual Emotion Recognition.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\7UZLWNIB\\3067943.html:text/html}
}

@article{deng_spatio-temporal_2023,
  title        = {Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction},
  volume       = {37},
  rights       = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/25542},
  doi          = {10.1609/aaai.v37i4.25542},
  abstract     = {As a representative of public transportation, the fundamental issue of managing bike-sharing systems is bike flow prediction. Recent methods overemphasize the spatio-temporal correlations in the data, ignoring the effects of contextual conditions on the transportation system and the inter-regional time-varying causality. In addition, due to the disturbance of incomplete observations in the data, random contextual conditions lead to spurious correlations between data and features, making the prediction of the model ineffective in special scenarios. To overcome this issue, we propose a Spatio-temporal Neural Structure Causal Model({STNSCM}) from the perspective of causality. First, we build a causal graph to describe the traffic prediction, and further analyze the causal relationship between the input data, contextual conditions, spatio-temporal states, and prediction results. Second, we propose to apply the frontdoor criterion to eliminate confounding biases in the feature extraction process. Finally, we propose a counterfactual representation reasoning module to extrapolate the spatio-temporal state under the factual scenario to future counterfactual scenarios to improve the prediction performance. Experiments on real-world datasets demonstrate the superior performance of our model, especially its resistance to fluctuations caused by the external environment. The source code and data will be released.},
  pages        = {4242--4249},
  number       = {4},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Deng, Pan and Zhao, Yu and Liu, Junting and Jia, Xiaofeng and Wang, Mulan},
  urldate      = {2023-08-15},
  date         = {2023-06-26},
  langid       = {english},
  note         = {Number: 4},
  keywords     = {/unread, and Causality, Change, {KRR}: Action},
  file         = {2023_Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction_Deng et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction_Deng et al.pdf:application/pdf}
}

@misc{dettmers_qlora_2023,
  title      = {{QLoRA}: Efficient Finetuning of Quantized {LLMs}},
  url        = {http://arxiv.org/abs/2305.14314},
  doi        = {10.48550/arXiv.2305.14314},
  shorttitle = {{QLoRA}},
  abstract   = {We present {QLoRA}, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB {GPU} while preserving full 16-bit finetuning task performance. {QLoRA} backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters{\textasciitilde}({LoRA}). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3\% of the performance level of {ChatGPT} while only requiring 24 hours of finetuning on a single {GPU}. {QLoRA} introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit {NormalFloat} ({NF}4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use {QLoRA} to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types ({LLaMA}, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that {QLoRA} finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous {SoTA}. We provide a detailed analysis of chatbot performance based on both human and {GPT}-4 evaluations showing that {GPT}-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to {ChatGPT}. We release all of our models and code, including {CUDA} kernels for 4-bit training.},
  number     = {{arXiv}:2305.14314},
  publisher  = {{arXiv}},
  author     = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  urldate    = {2023-10-31},
  date       = {2023-05-23},
  eprinttype = {arxiv},
  eprint     = {2305.14314 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, /unread},
  file       = {2023_QLoRA_Dettmers et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_QLoRA_Dettmers et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\YNEU8KYI\\2305.html:text/html}
}

@misc{dong_heterogeneity-informed_2024,
  title      = {Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series Forecasting},
  url        = {http://arxiv.org/abs/2405.10800},
  doi        = {10.48550/arXiv.2405.10800},
  abstract   = {Spatiotemporal time series forecasting plays a key role in a wide range of real-world applications. While significant progress has been made in this area, fully capturing and leveraging spatiotemporal heterogeneity remains a fundamental challenge. Therefore, we propose a novel Heterogeneity-Informed Meta-Parameter Learning scheme. Specifically, our approach implicitly captures spatiotemporal heterogeneity through learning spatial and temporal embeddings, which can be viewed as a clustering process. Then, a novel spatiotemporal meta-parameter learning paradigm is proposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity. Based on these ideas, we develop a Heterogeneity-Informed Spatiotemporal Meta-Network ({HimNet}) for spatiotemporal time series forecasting. Extensive experiments on five widely-used benchmarks demonstrate our method achieves state-of-the-art performance while exhibiting superior interpretability. Our code is available at https://github.com/{XDZhelheim}/{HimNet}.},
  number     = {{arXiv}:2405.10800},
  publisher  = {{arXiv}},
  author     = {Dong, Zheng and Jiang, Renhe and Gao, Haotian and Liu, Hangchen and Deng, Jinliang and Wen, Qingsong and Song, Xuan},
  urldate    = {2024-05-22},
  date       = {2024-05-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2405.10800 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series_Dong et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\Q5795PFI\\2024_Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series_Dong et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\NT9B7WPC\\2405.html:text/html}
}

@online{dong_metadata_2024,
  title      = {Metadata Matters for Time Series: Informative Forecasting with Transformers},
  url        = {https://arxiv.org/abs/2410.03806v1},
  shorttitle = {Metadata Matters for Time Series},
  abstract   = {Time series forecasting is prevalent in extensive real-world applications, such as financial analysis and energy planning. Previous studies primarily focus on time series modality, endeavoring to capture the intricate variations and dependencies inherent in time series. Beyond numerical time series data, we notice that metadata (e.g.{\textasciitilde}dataset and variate descriptions) also carries valuable information essential for forecasting, which can be used to identify the application scenario and provide more interpretable knowledge than digit sequences. Inspired by this observation, we propose a Metadata-informed Time Series Transformer ({MetaTST}), which incorporates multiple levels of context-specific metadata into Transformer forecasting models to enable informative time series forecasting. To tackle the unstructured nature of metadata, {MetaTST} formalizes them into natural languages by pre-designed templates and leverages large language models ({LLMs}) to encode these texts into metadata tokens as a supplement to classic series tokens, resulting in an informative embedding. Further, a Transformer encoder is employed to communicate series and metadata tokens, which can extend series representations by metadata information for more accurate forecasting. This design also allows the model to adaptively learn context-specific patterns across various scenarios, which is particularly effective in handling large-scale, diverse-scenario forecasting tasks. Experimentally, {MetaTST} achieves state-of-the-art compared to advanced time series models and {LLM}-based methods on widely acknowledged short- and long-term forecasting benchmarks, covering both single-dataset individual and multi-dataset joint training settings.},
  titleaddon = {{arXiv}.org},
  author     = {Dong, Jiaxiang and Wu, Haixu and Wang, Yuxuan and Zhang, Li and Wang, Jianmin and Long, Mingsheng},
  urldate    = {2024-10-09},
  date       = {2024-10-04},
  langid     = {english},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\HM6A4AEL\\Dong 等 - 2024 - Metadata Matters for Time Series Informative Forecasting with Transformers.pdf:application/pdf}
}

@misc{dong_metadata_2024-1,
  title      = {Metadata Matters for Time Series: Informative Forecasting with Transformers},
  url        = {http://arxiv.org/abs/2410.03806},
  doi        = {10.48550/arXiv.2410.03806},
  shorttitle = {Metadata Matters for Time Series},
  abstract   = {Time series forecasting is prevalent in extensive real-world applications, such as financial analysis and energy planning. Previous studies primarily focus on time series modality, endeavoring to capture the intricate variations and dependencies inherent in time series. Beyond numerical time series data, we notice that metadata (e.g.{\textasciitilde}dataset and variate descriptions) also carries valuable information essential for forecasting, which can be used to identify the application scenario and provide more interpretable knowledge than digit sequences. Inspired by this observation, we propose a Metadata-informed Time Series Transformer ({MetaTST}), which incorporates multiple levels of context-specific metadata into Transformer forecasting models to enable informative time series forecasting. To tackle the unstructured nature of metadata, {MetaTST} formalizes them into natural languages by pre-designed templates and leverages large language models ({LLMs}) to encode these texts into metadata tokens as a supplement to classic series tokens, resulting in an informative embedding. Further, a Transformer encoder is employed to communicate series and metadata tokens, which can extend series representations by metadata information for more accurate forecasting. This design also allows the model to adaptively learn context-specific patterns across various scenarios, which is particularly effective in handling large-scale, diverse-scenario forecasting tasks. Experimentally, {MetaTST} achieves state-of-the-art compared to advanced time series models and {LLM}-based methods on widely acknowledged short- and long-term forecasting benchmarks, covering both single-dataset individual and multi-dataset joint training settings.},
  number     = {{arXiv}:2410.03806},
  publisher  = {{arXiv}},
  author     = {Dong, Jiaxiang and Wu, Haixu and Wang, Yuxuan and Zhang, Li and Wang, Jianmin and Long, Mingsheng},
  urldate    = {2024-10-23},
  date       = {2024-10-04},
  eprinttype = {arxiv},
  eprint     = {2410.03806},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language, ⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\VIFC4YJI\\Dong 等 - 2024 - Metadata Matters for Time Series Informative Forecasting with Transformers.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\54FJUS42\\2410.html:text/html}
}

@misc{dooley_forecastpfn_2023,
  title      = {{ForecastPFN}: Synthetically-Trained Zero-Shot Forecasting},
  url        = {http://arxiv.org/abs/2311.01933},
  doi        = {10.48550/arXiv.2311.01933},
  shorttitle = {{ForecastPFN}},
  abstract   = {The vast majority of time-series forecasting approaches require a substantial training dataset. However, many real-life forecasting applications have very little initial observations, sometimes just 40 or fewer. Thus, the applicability of most forecasting methods is restricted in data-sparse commercial applications. While there is recent work in the setting of very limited initial data (so-called `zero-shot' forecasting), its performance is inconsistent depending on the data used for pretraining. In this work, we take a different approach and devise {ForecastPFN}, the first zero-shot forecasting model trained purely on a novel synthetic data distribution. {ForecastPFN} is a prior-data fitted network, trained to approximate Bayesian inference, which can make predictions on a new time series dataset in a single forward pass. Through extensive experiments, we show that zero-shot predictions made by {ForecastPFN} are more accurate and faster compared to state-of-the-art forecasting methods, even when the other methods are allowed to train on hundreds of additional in-distribution data points.},
  number     = {{arXiv}:2311.01933},
  publisher  = {{arXiv}},
  author     = {Dooley, Samuel and Khurana, Gurnoor Singh and Mohapatra, Chirag and Naidu, Siddartha and White, Colin},
  urldate    = {2024-01-17},
  date       = {2023-11-03},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.01933 [cs]},
  keywords   = {Computer Science - Machine Learning, /unread},
  file       = {2023_ForecastPFN_Dooley et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\P2292TA6\\2023_ForecastPFN_Dooley et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZMFVDSTK\\2311.html:text/html}
}

@misc{du_cosyvoice_2024,
  title      = {{CosyVoice} 2: Scalable Streaming Speech Synthesis with Large Language Models},
  url        = {http://arxiv.org/abs/2412.10117},
  doi        = {10.48550/arXiv.2412.10117},
  shorttitle = {{CosyVoice} 2},
  abstract   = {In our previous work, we introduced {CosyVoice}, a multilingual speech synthesis model based on supervised discrete speech tokens. By employing progressive semantic decoding with two popular generative models, language models ({LMs}) and Flow Matching, {CosyVoice} demonstrated high prosody naturalness, content consistency, and speaker similarity in speech in-context learning. Recently, significant progress has been made in multi-modal large language models ({LLMs}), where the response latency and real-time factor of speech synthesis play a crucial role in the interactive experience. Therefore, in this report, we present an improved streaming speech synthesis model, {CosyVoice} 2, which incorporates comprehensive and systematic optimizations. Specifically, we introduce finite-scalar quantization to improve the codebook utilization of speech tokens. For the text-speech {LM}, we streamline the model architecture to allow direct use of a pre-trained {LLM} as the backbone. In addition, we develop a chunk-aware causal flow matching model to support various synthesis scenarios, enabling both streaming and non-streaming synthesis within a single model. By training on a large-scale multilingual dataset, {CosyVoice} 2 achieves human-parity naturalness, minimal response latency, and virtually lossless synthesis quality in the streaming mode. We invite readers to listen to the demos at https://funaudiollm.github.io/cosyvoice2.},
  number     = {{arXiv}:2412.10117},
  publisher  = {{arXiv}},
  author     = {Du, Zhihao and Wang, Yuxuan and Chen, Qian and Shi, Xian and Lv, Xiang and Zhao, Tianyu and Gao, Zhifu and Yang, Yexin and Gao, Changfeng and Wang, Hui and Yu, Fan and Liu, Huadai and Sheng, Zhengyan and Gu, Yue and Deng, Chong and Wang, Wen and Zhang, Shiliang and Yan, Zhijie and Zhou, Jingren},
  urldate    = {2025-01-06},
  date       = {2024-12-25},
  eprinttype = {arxiv},
  eprint     = {2412.10117 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\4IZB2G48\\Du 等 - 2024 - CosyVoice 2 Scalable Streaming Speech Synthesis with Large Language Models.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JZ8Z36NZ\\2412.html:text/html}
}

@article{duan_spatiotemporal_2023,
  title        = {Spatiotemporal dynamics of traffic bottlenecks yields an early signal of heavy congestions},
  volume       = {14},
  rights       = {2023 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-023-43591-7},
  doi          = {10.1038/s41467-023-43591-7},
  abstract     = {Heavy traffic jams are difficult to predict due to the complexity of traffic dynamics. Understanding the network dynamics of traffic bottlenecks can help avoid critical large traffic jams and improve overall traffic conditions. Here, we develop a method to forecast heavy congestions based on their early propagation stage. Our framework follows the network propagation and dissipation of the traffic jams originated from a bottleneck emergence, growth, and its recovery and disappearance. Based on large-scale urban traffic-speed data, we find that dissipation duration of jams follows approximately power-law distributions, and typically, traffic jams dissolve nearly twice slower than their growth. Importantly, we find that the growth speed, even at the first 15 minutes of a jam, is highly correlated with the maximal size of the jam. Our methodology can be applied in urban traffic control systems to forecast heavy traffic bottlenecks and prevent them before they propagate to large network congestions.},
  pages        = {8002},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Duan, Jinxiao and Zeng, Guanwen and Serok, Nimrod and Li, Daqing and Lieberthal, Efrat Blumenfeld and Huang, Hai-Jun and Havlin, Shlomo},
  urldate      = {2025-04-18},
  date         = {2023-12-04},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group
                  {TLDR}: A method to forecast heavy congestions based on their early propagation stage and finds that the growth speed, even at the first 15 minutes of a jam, is highly correlated with the maximal size of the jam.},
  keywords     = {Statistical physics, Complex networks},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\9NPRB2IH\\Duan 等 - 2023 - Spatiotemporal dynamics of traffic bottlenecks yields an early signal of heavy congestions.pdf:application/pdf}
}

@misc{fan_addressing_2024,
  title      = {Addressing Distribution Shift in Time Series Forecasting with Instance Normalization Flows},
  url        = {http://arxiv.org/abs/2401.16777},
  doi        = {10.48550/arXiv.2401.16777},
  abstract   = {Due to non-stationarity of time series, the distribution shift problem largely hinders the performance of time series forecasting. Existing solutions either fail for the shifts beyond simple statistics or the limited compatibility with forecasting models. In this paper, we propose a general decoupled formulation for time series forecasting, with no reliance on fixed statistics and no restriction on forecasting architectures. Then, we make such a formulation formalized into a bi-level optimization problem, to enable the joint learning of the transformation (outer loop) and forecasting (inner loop). Moreover, the special requirements of expressiveness and bi-direction for the transformation motivate us to propose instance normalization flows ({IN}-Flow), a novel invertible network for time series transformation. Extensive experiments demonstrate our method consistently outperforms state-of-the-art baselines on both synthetic and real-world data.},
  number     = {{arXiv}:2401.16777},
  publisher  = {{arXiv}},
  author     = {Fan, Wei and Zheng, Shun and Wang, Pengyang and Xie, Rui and Bian, Jiang and Fu, Yanjie},
  urldate    = {2024-02-06},
  date       = {2024-01-30},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.16777 [cs]},
  keywords   = {Computer Science - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\BT6C888C\\2401.html:text/html;Fan et al_2024_Addressing Distribution Shift in Time Series Forecasting with Instance.pdf:C\:\\Users\\yanha\\Zotero\\storage\\KAFIKKD3\\Fan et al_2024_Addressing Distribution Shift in Time Series Forecasting with Instance.pdf:application/pdf}
}

@article{fan_development_2025,
  title        = {Development of an Efficient and Generalized {MTSCAM} Model to Predict Liquid Chromatography Retention Times of Organic Compounds},
  rights       = {Copyright © 2025 Mengdie Fan et al.},
  url          = {https://spj.science.org/doi/10.34133/research.0607},
  doi          = {10.34133/research.0607},
  abstract     = {Accurate prediction of liquid chromatographic retention times is becoming increasingly important in nontargeted screening applications. Traditional retention time approaches heavily rely on the use of standard compounds, which is limited by the speed of ...},
  journaltitle = {Research},
  author       = {Fan, Mengdie and Sang, Chenhui and Li, Hua and Wei, Yue and Zhang, Bin and Xing, Yang and Zhang, Jing and Yin, Jie and An, Wei and Shao, Bing},
  urldate      = {2025-04-15},
  date         = {2025-02-07},
  note         = {Publisher: {AAAS}},
  file         = {Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\YSBFISWI\\research.html:text/html}
}

@misc{fan_learning_2024,
  title      = {Learning Traffic Crashes as Language: Datasets, Benchmarks, and What-if Causal Analyses},
  url        = {http://arxiv.org/abs/2406.10789},
  doi        = {10.48550/arXiv.2406.10789},
  shorttitle = {Learning Traffic Crashes as Language},
  abstract   = {The increasing rate of road accidents worldwide results not only in significant loss of life but also imposes billions financial burdens on societies. Current research in traffic crash frequency modeling and analysis has predominantly approached the problem as classification tasks, focusing mainly on learning-based classification or ensemble learning methods. These approaches often overlook the intricate relationships among the complex infrastructure, environmental, human and contextual factors related to traffic crashes and risky situations. In contrast, we initially propose a large-scale traffic crash language dataset, named {CrashEvent}, summarizing 19,340 real-world crash reports and incorporating infrastructure data, environmental and traffic textual and visual information in Washington State. Leveraging this rich dataset, we further formulate the crash event feature learning as a novel text reasoning problem and further fine-tune various large language models ({LLMs}) to predict detailed accident outcomes, such as crash types, severity and number of injuries, based on contextual and environmental factors. The proposed model, {CrashLLM}, distinguishes itself from existing solutions by leveraging the inherent text reasoning capabilities of {LLMs} to parse and learn from complex, unstructured data, thereby enabling a more nuanced analysis of contributing factors. Our experiments results shows that our {LLM}-based approach not only predicts the severity of accidents but also classifies different types of accidents and predicts injury outcomes, all with averaged F1 score boosted from 34.9\% to 53.8\%. Furthermore, {CrashLLM} can provide valuable insights for numerous open-world what-if situational-awareness traffic safety analyses with learned reasoning features, which existing models cannot offer. We make our benchmark, datasets, and model public available for further exploration.},
  number     = {{arXiv}:2406.10789},
  publisher  = {{arXiv}},
  author     = {Fan, Zhiwen and Wang, Pu and Zhao, Yang and Zhao, Yibo and Ivanovic, Boris and Wang, Zhangyang and Pavone, Marco and Yang, Hao Frank},
  urldate    = {2024-11-26},
  date       = {2024-06-16},
  eprinttype = {arxiv},
  eprint     = {2406.10789},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, ⭐⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\QLRFJAL4\\Fan 等 - 2024 - Learning Traffic Crashes as Language Datasets, Benchmarks, and What-if Causal Analyses.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\CMYD9VJJ\\2406.html:text/html}
}

@misc{fan_small_2025,
  title      = {Small but Mighty: Enhancing Time Series Forecasting with Lightweight {LLMs}},
  url        = {http://arxiv.org/abs/2503.03594},
  doi        = {10.48550/arXiv.2503.03594},
  shorttitle = {Small but Mighty},
  abstract   = {While {LLMs} have demonstrated remarkable potential in time series forecasting, their practical deployment remains constrained by excessive computational demands and memory footprints. Existing {LLM}-based approaches typically suffer from three critical limitations: Inefficient parameter utilization in handling numerical time series patterns; Modality misalignment between continuous temporal signals and discrete text embeddings; and Inflexibility for real-time expert knowledge integration. We present {SMETimes}, the first systematic investigation of sub-3B parameter {SLMs} for efficient and accurate time series forecasting. Our approach centers on three key innovations: A statistically-enhanced prompting mechanism that bridges numerical time series with textual semantics through descriptive statistical features; A adaptive fusion embedding architecture that aligns temporal patterns with language model token spaces through learnable parameters; And a dynamic mixture-of-experts framework enabled by {SLMs}' computational efficiency, adaptively combining base predictions with domain-specific models. Extensive evaluations across seven benchmark datasets demonstrate that our 3B-parameter {SLM} achieves state-of-the-art performance on five primary datasets while maintaining 3.8x faster training and 5.2x lower memory consumption compared to 7B-parameter {LLM} baselines. Notably, the proposed model exhibits better learning capabilities, achieving 12.3\% lower {MSE} than conventional {LLM}. Ablation studies validate that our statistical prompting and cross-modal fusion modules respectively contribute 15.7\% and 18.2\% error reduction in long-horizon forecasting tasks. By redefining the efficiency-accuracy trade-off landscape, this work establishes {SLMs} as viable alternatives to resource-intensive {LLMs} for practical time series forecasting. Code and models are available at https://github.com/xiyan1234567/{SMETimes}.},
  number     = {{arXiv}:2503.03594},
  publisher  = {{arXiv}},
  author     = {Fan, Haoran and Li, Bin and Weng, Yixuan and Zhou, Shoujun},
  urldate    = {2025-03-12},
  date       = {2025-03-09},
  eprinttype = {arxiv},
  eprint     = {2503.03594 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\J3Q7M249\\Fan 等 - 2025 - Small but Mighty Enhancing Time Series Forecasting with Lightweight LLMs.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\F623XV68\\2503.html:text/html}
}

@article{fang_learning_2023,
  title        = {Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling},
  volume       = {37},
  rights       = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/25915},
  doi          = {10.1609/aaai.v37i6.25915},
  abstract     = {Modeling multi-variate time-series ({MVTS}) data is a long-standing research subject and has found wide applications. Recently, there is a surge of interest in modeling spatial relations between variables as graphs, i.e., first learning one static graph for each dataset and then exploiting the graph structure via graph neural networks. However, as spatial relations may differ substantially across samples, building one static graph for all the samples inherently limits flexibility and severely degrades the performance in practice. To address this issue, we propose a framework for fine-grained modeling and utilization of spatial correlation between variables. By analyzing the statistical properties of real-world datasets, a universal decomposition of spatial correlation graphs is first identified. Specifically, the hidden spatial relations can be decomposed into a prior part, which applies across all the samples, and a dynamic part, which varies between samples, and building different graphs is necessary to model these relations. To better coordinate the learning of the two relational graphs, we propose a min-max learning paradigm that not only regulates the common part of different dynamic graphs but also guarantees spatial distinguishability among samples. The experimental results show that our proposed model outperforms the state-of-the-art baseline methods on both time-series forecasting and time-series point prediction tasks.},
  pages        = {7530--7538},
  number       = {6},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Fang, Yuchen and Ren, Kan and Shan, Caihua and Shen, Yifei and Li, You and Zhang, Weinan and Yu, Yong and Li, Dongsheng},
  urldate      = {2023-08-15},
  date         = {2023-06-26},
  langid       = {english},
  note         = {Number: 6},
  keywords     = {/unread, {ML}: Graph-based Machine Learning},
  file         = {2023_Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling_Fang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\Human mobility\\2023_Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling_Fang et al.pdf:application/pdf}
}

@misc{feng_citygpt_2024,
  title      = {{CityGPT}: Empowering Urban Spatial Cognition of Large Language Models},
  url        = {http://arxiv.org/abs/2406.13948},
  doi        = {10.48550/arXiv.2406.13948},
  shorttitle = {{CityGPT}},
  abstract   = {Large language models({LLMs}) with powerful language generation and reasoning capabilities have already achieved success in many domains, e.g., math and code generation. However, due to the lacking of physical world's corpus and knowledge during training, they usually fail to solve many real-life tasks in the urban space. In this paper, we propose {CityGPT}, a systematic framework for enhancing the capability of {LLMs} on understanding urban space and solving the related urban tasks by building a city-scale world model in the model. First, we construct a diverse instruction tuning dataset {CityInstruction} for injecting urban knowledge and enhancing spatial reasoning capability effectively. By using a mixture of {CityInstruction} and general instruction data, we fine-tune various {LLMs} (e.g., {ChatGLM}3-6B, Qwen1.5 and {LLama}3 series) to enhance their capability without sacrificing general abilities. To further validate the effectiveness of proposed methods, we construct a comprehensive benchmark {CityEval} to evaluate the capability of {LLMs} on diverse urban scenarios and problems. Extensive evaluation results demonstrate that small {LLMs} trained with {CityInstruction} can achieve competitive performance with commercial {LLMs} in the comprehensive evaluation of {CityEval}. The source codes are openly accessible to the research community via https://github.com/tsinghua-fib-lab/{CityGPT}.},
  number     = {{arXiv}:2406.13948},
  publisher  = {{arXiv}},
  author     = {Feng, Jie and Du, Yuwei and Liu, Tianhui and Guo, Siqi and Lin, Yuming and Li, Yong},
  urldate    = {2024-08-01},
  date       = {2024-06-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.13948 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_CityGPT_Feng et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GQG3W3ZR\\2024_CityGPT_Feng et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\AZF4KPNT\\2406.html:text/html}
}

@article{feng_latent_2024,
  title        = {Latent Diffusion Transformer for Probabilistic Time Series Forecasting},
  volume       = {38},
  rights       = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/29085},
  doi          = {10.1609/aaai.v38i11.29085},
  abstract     = {The probability prediction of multivariate time series is a notoriously challenging but practical task. This research proposes to condense high-dimensional multivariate time series forecasting into a problem of latent space time series generation, to improve the expressiveness of each timestamp and make forecasting more manageable. To solve the problem that the existing work is hard to extend to high-dimensional multivariate time series, we present a latent multivariate time series diffusion framework called Latent Diffusion Transformer ({LDT}), which consists of a symmetric statistics-aware autoencoder and a diffusion-based conditional generator, to implement this idea. Through careful design, the time series autoencoder can compress multivariate timestamp patterns into a concise latent representation by considering dynamic statistics. Then, the diffusion-based conditional generator is able to efficiently generate realistic multivariate timestamp values on a continuous latent space under a novel self-conditioning guidance which is modeled in a non-autoregressive way. Extensive experiments demonstrate that our model achieves state-of-the-art performance on many popular high-dimensional multivariate time series datasets.},
  pages        = {11979--11987},
  number       = {11},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Feng, Shibo and Miao, Chunyan and Zhang, Zhong and Zhao, Peilin},
  urldate      = {2024-05-22},
  date         = {2024-03-24},
  langid       = {english},
  note         = {Number: 11},
  keywords     = {/reading, {KRR}: Applications},
  file         = {2024_Latent Diffusion Transformer for Probabilistic Time Series Forecasting_Feng et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\PNMMMYJF\\2024_Latent Diffusion Transformer for Probabilistic Time Series Forecasting_Feng et al.pdf:application/pdf}
}

@article{feng_macromicro_2023,
  title        = {A macro–micro spatio-temporal neural network for traffic prediction},
  volume       = {156},
  issn         = {0968-090X},
  url          = {https://www.sciencedirect.com/science/article/pii/S0968090X23003200},
  doi          = {10.1016/j.trc.2023.104331},
  abstract     = {Accurate traffic prediction is crucial for planning, management and control of intelligent transportation systems. Most state-of-the-art methods for traffic prediction effectively capture complex traffic patterns (e.g. spatial and temporal correlations of traffic data) by employing spatio-temporal neural networks as prediction models, together with graph convolution networks to learn spatial correlations of prediction objects (e.g. traffic states of road segments, as in this study). Such spatial correlations can be regarded as micro correlations. However, there are also macro correlations between regions, each of which is composed of multiple road segments or artificially partitioned areas. Macro correlations represent another type of interaction within road segments, and should be carefully considered when predicting traffic. The diversity of micro spatial correlations and corresponding macro spatial correlations (e.g. correlations based on physical proximity or traffic pattern similarity) further increases the complexity of traffic prediction. We overcome these challenges by developing a macro–micro spatio-temporal neural network model, denoted ‘{MMSTNet}’. {MMSTNet} captures spatio-temporal patterns by (a) utilizing a graph convolution network and a spatial attention network to capture micro and macro spatial correlations, respectively; (b) employing a temporal convolution network and a temporal attention network to learn temporal patterns; and (c) integrating hierarchically learned representations based on designed attention mechanisms. We perform evaluations on two real-world datasets and thereby demonstrate that {MMSTNet} outperforms state-of-the-art models in traffic prediction tasks.},
  pages        = {104331},
  journaltitle = {Transportation Research Part C: Emerging Technologies},
  shortjournal = {Transportation Research Part C: Emerging Technologies},
  author       = {Feng, Siyuan and Wei, Shuqing and Zhang, Junbo and Li, Yexin and Ke, Jintao and Chen, Gaode and Zheng, Yu and Yang, Hai},
  urldate      = {2023-12-21},
  date         = {2023-11-01},
  langid       = {english},
  keywords     = {/unread, Attention mechanism, Graph convolution, Traffic prediction, Urban computing}
}

@misc{gao_units_2024,
  title      = {{UniTS}: Building a Unified Time Series Model},
  url        = {http://arxiv.org/abs/2403.00131},
  shorttitle = {{UniTS}},
  abstract   = {Foundation models, especially {LLMs}, are profoundly transforming deep learning. Instead of training many task-specific models, we can adapt a single pretrained model to many tasks via fewshot prompting or fine-tuning. However, current foundation models apply to sequence data but not to time series, which present unique challenges due to the inherent diverse and multidomain time series datasets, diverging task specifications across forecasting, classification and other types of tasks, and the apparent need for task-specialized models. We developed {UNITS}, a unified time series model that supports a universal task specification, accommodating classification, forecasting, imputation, and anomaly detection tasks. This is achieved through a novel unified network backbone, which incorporates sequence and variable attention along with a dynamic linear operator and is trained as a unified model. Across 38 multi-domain datasets, {UNITS} demonstrates superior performance compared to task-specific models and repurposed natural language-based {LLMs}. {UNITS} exhibits remarkable zero-shot, few-shot, and prompt learning capabilities when evaluated on new data domains and tasks. The source code and datasets are available at https://github.com/mims-harvard/{UniTS}.},
  number     = {{arXiv}:2403.00131},
  publisher  = {{arXiv}},
  author     = {Gao, Shanghua and Koker, Teddy and Queen, Owen and Hartvigsen, Thomas and Tsiligkaridis, Theodoros and Zitnik, Marinka},
  urldate    = {2024-03-18},
  date       = {2024-02-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.00131 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_UniTS_Gao et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\3TNZU5XP\\2024_UniTS_Gao et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\WHRKG5WV\\2403.html:text/html}
}

@misc{gillman_fourier_2024,
  title      = {Fourier Head: Helping Large Language Models Learn Complex Probability Distributions},
  url        = {http://arxiv.org/abs/2410.22269},
  doi        = {10.48550/arXiv.2410.22269},
  shorttitle = {Fourier Head},
  abstract   = {As the quality of large language models has improved, there has been increased interest in using them to model non-linguistic tokens. For example, the Decision Transformer recasts agentic decision making as a sequence modeling problem, using a decoder-only {LLM} to model the distribution over the discrete action space for an Atari agent. However, when adapting {LLMs} to non-linguistic domains, it remains unclear if softmax over discrete bins captures the continuous structure of the tokens and the potentially complex distributions needed for high quality token generation. We introduce a neural network layer, constructed using Fourier series, which we can easily substitute for any linear layer if we want the outputs to have a more continuous structure. We perform extensive analysis on synthetic datasets, as well as on large-scale decision making and time series forecasting tasks. We also provide theoretical evidence that this layer can better learn signal from data while ignoring high-frequency noise. All of our results support the effectiveness of our proposed Fourier head in scenarios where the underlying data distribution has a natural continuous structure. For example, the Fourier head improves a Decision Transformer agent's returns by 46\% on the Atari Seaquest game, and increases a state-of-the-art times series foundation model's forecasting performance by 3.5\% across 20 benchmarks unseen during training.},
  number     = {{arXiv}:2410.22269},
  publisher  = {{arXiv}},
  author     = {Gillman, Nate and Aggarwal, Daksh and Freeman, Michael and Singh, Saurabh and Sun, Chen},
  urldate    = {2024-11-12},
  date       = {2024-10-29},
  eprinttype = {arxiv},
  eprint     = {2410.22269},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\RSCXGWPN\\Gillman 等 - 2024 - Fourier Head Helping Large Language Models Learn Complex Probability Distributions.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\8X6YBKQD\\2410.html:text/html}
}

@misc{gruver_large_2023,
  title      = {Large Language Models Are Zero-Shot Time Series Forecasters},
  url        = {http://arxiv.org/abs/2310.07820},
  abstract   = {By encoding time series as a string of numerical digits, we can frame time series forecasting as next-token prediction in text. Developing this approach, we find that large language models ({LLMs}) such as {GPT}-3 and {LLaMA}-2 can surprisingly zeroshot extrapolate time series at a level comparable to or exceeding the performance of purpose-built time series models trained on the downstream tasks. To facilitate this performance, we propose procedures for effectively tokenizing time series data and converting discrete distributions over tokens into highly flexible densities over continuous values. We argue the success of {LLMs} for time series stems from their ability to naturally represent multimodal distributions, in conjunction with biases for simplicity, and repetition, which align with the salient features in many time series, such as repeated seasonal trends. We also show how {LLMs} can naturally handle missing data without imputation through non-numerical text, accommodate textual side information, and answer questions to help explain predictions. While we find that increasing model size generally improves performance on time series, we show {GPT}-4 can perform worse than {GPT}-3 because of how it tokenizes numbers, and poor uncertainty calibration, which is likely the result of alignment interventions such as {RLHF}.},
  number     = {{arXiv}:2310.07820},
  publisher  = {{arXiv}},
  author     = {Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew Gordon},
  urldate    = {2023-10-18},
  date       = {2023-10-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.07820 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2023_Large Language Models Are Zero-Shot Time Series Forecasters_Gruver et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\8N3UDRQJ\\2023_Large Language Models Are Zero-Shot Time Series Forecasters_Gruver et al.pdf:application/pdf}
}

@misc{gu_efficiently_2022,
  title      = {Efficiently Modeling Long Sequences with Structured State Spaces},
  url        = {http://arxiv.org/abs/2111.00396},
  doi        = {10.48550/arXiv.2111.00396},
  abstract   = {A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including {RNNs}, {CNNs}, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of \$10000\$ or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model ({SSM}) {\textbackslash}( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) {\textbackslash}), and showed that for appropriate choices of the state matrix {\textbackslash}( A {\textbackslash}), this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the {SSM}, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning {\textbackslash}( A {\textbackslash}) with a low-rank correction, allowing it to be diagonalized stably and reducing the {SSM} to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91{\textbackslash}\% accuracy on sequential {CIFAR}-10 with no data augmentation or auxiliary losses, on par with a larger 2-D {ResNet}, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation \$60{\textbackslash}times\$ faster (iii) {SoTA} on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.},
  number     = {{arXiv}:2111.00396},
  publisher  = {{arXiv}},
  author     = {Gu, Albert and Goel, Karan and Ré, Christopher},
  urldate    = {2023-12-12},
  date       = {2022-08-05},
  eprinttype = {arxiv},
  eprint     = {2111.00396 [cs]},
  keywords   = {Computer Science - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\HG46F9EG\\2111.html:text/html}
}

@article{gu_mamba_nodate,
  title    = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
  abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models ({SSMs}) have been developed to address Transformers’ computational ineﬃciency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the {SSM} parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of eﬃcient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective {SSMs} into a simpliﬁed end-to-end neural network architecture without attention or even {MLP} blocks (Mamba). Mamba enjoys fast inference (5× higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
  author   = {Gu, Albert and Dao, Tri},
  langid   = {english},
  keywords = {/reading, /unread, ⛔ No {DOI} found},
  file     = {Mamba_Gu_Dao.pdf:C\:\\Users\\yanha\\Zotero\\storage\\BA4UNDRY\\Mamba_Gu_Dao.pdf:application/pdf}
}

@misc{guo_explainable_2024,
  title      = {Explainable Traffic Flow Prediction with Large Language Models},
  url        = {http://arxiv.org/abs/2404.02937},
  abstract   = {Traffic flow prediction is crucial for urban planning, transportation management, and infrastructure development. However, achieving both accuracy and interpretability in prediction models remains challenging due to the complexity of traffic data and the inherent opacity of deep learning methodologies. In this paper, we propose a novel approach, Traffic Flow Prediction {LLM} ({TF}-{LLM}), which leverages large language models ({LLMs}) to generate interpretable traffic flow predictions. By transferring multi-modal traffic data into natural language descriptions, {TF}-{LLM} captures complex spatial-temporal patterns and external factors such as weather conditions, Points of Interest ({PoIs}), date, and holidays. We fine-tune the {LLM} framework using language-based instructions to align with spatial-temporal traffic flow data. Our comprehensive multi-modal traffic flow dataset ({CATraffic}) in California enables the evaluation of {TF}-{LLM} against state-of-the-art deep learning baselines. Results demonstrate {TF}-{LLM}'s competitive accuracy while providing intuitive and interpretable predictions. We discuss the spatial-temporal and input dependencies for explainable future flow forecasting, showcasing {TF}-{LLM}'s potential for diverse city prediction tasks. This paper contributes to advancing explainable traffic prediction models and lays a foundation for future exploration of {LLM} applications in transportation.},
  number     = {{arXiv}:2404.02937},
  publisher  = {{arXiv}},
  author     = {Guo, Xusen and Zhang, Qiming and Peng, Mingxing and Zhu, Meixin and Hao and Yang},
  urldate    = {2024-04-09},
  date       = {2024-04-08},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.02937 [cs]},
  note       = {version: 2},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_Explainable Traffic Flow Prediction with Large Language Models_Guo et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\RT3NG3HA\\2024_Explainable Traffic Flow Prediction with Large Language Models_Guo et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\AJIFGV6F\\2404.html:text/html}
}

@misc{guo_graphedit_2024,
  title      = {{GraphEdit}: Large Language Models for Graph Structure Learning},
  url        = {http://arxiv.org/abs/2402.15183},
  doi        = {10.48550/arXiv.2402.15183},
  shorttitle = {{GraphEdit}},
  abstract   = {Graph Structure Learning ({GSL}) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks ({GNNs}) have emerged as promising {GSL} solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing {GSL} methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose {GraphEdit}, an approach that leverages large language models ({LLMs}) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of {LLMs} through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy connections but also identifies node-wise dependencies from a global perspective, providing a comprehensive understanding of the graph structure. We conduct extensive experiments on multiple benchmark datasets to demonstrate the effectiveness and robustness of {GraphEdit} across various settings. We have made our model implementation available at: https://github.com/{HKUDS}/{GraphEdit}.},
  number     = {{arXiv}:2402.15183},
  publisher  = {{arXiv}},
  author     = {Guo, Zirui and Xia, Lianghao and Yu, Yanhua and Wang, Yuling and Yang, Zixuan and Wei, Wei and Pang, Liang and Chua, Tat-Seng and Huang, Chao},
  urldate    = {2024-03-27},
  date       = {2024-03-05},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.15183 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_GraphEdit_Guo et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\TJL63TUR\\2024_GraphEdit_Guo et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\QH9ZTW4J\\2402.html:text/html}
}

@article{guo_integrating_2024,
  title        = {Integrating spoken instructions into flight trajectory prediction to optimize automation in air traffic control},
  volume       = {15},
  rights       = {2024 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-024-54069-5},
  doi          = {10.1038/s41467-024-54069-5},
  abstract     = {The booming air transportation industry inevitably burdens air traffic controllers’ workload, causing unexpected human factor-related incidents. Current air traffic control systems fail to consider spoken instructions for traffic prediction, bringing significant challenges in detecting human errors during real-time traffic operations. Here, we present an automation paradigm integrating controlling intent into the information processing loop through the spoken instruction-aware flight trajectory prediction framework. A 3-stage progressive multi-modal learning paradigm is proposed to address the modality gap between the trajectory and spoken instructions, as well as minimize the data requirements. Experiments on a real-world dataset show the proposed framework achieves flight trajectory prediction with high predictability and timeliness, obtaining over 20\% relative reduction in mean deviation error. Moreover, the generalizability of the proposed framework is also confirmed by various model architectures. The proposed framework can formulate full-automated information processing in real-world air traffic applications, supporting human error detection and enhancing aviation safety.},
  pages        = {9662},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Guo, Dongyue and Zhang, Zheng and Yang, Bo and Zhang, Jianwei and Yang, Hongyu and Lin, Yi},
  urldate      = {2025-04-22},
  date         = {2024-11-07},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group
                  {TLDR}: An automation paradigm integrating controlling intent into the information processing loop through the spoken instruction-aware flight trajectory prediction framework to address the modality gap between the trajectory and spoken instructions, as well as minimize the data requirements.},
  keywords     = {Aerospace engineering, Electrical and electronic engineering},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\YCRJRFLZ\\Guo 等 - 2024 - Integrating spoken instructions into flight trajectory prediction to optimize automation in air traf.pdf:application/pdf}
}

@article{guo_towards_2024,
  title        = {Towards explainable traffic flow prediction with large language models},
  volume       = {4},
  issn         = {2772-4247},
  url          = {https://www.sciencedirect.com/science/article/pii/S2772424724000337},
  doi          = {10.1016/j.commtr.2024.100150},
  abstract     = {Traffic forecasting is crucial for intelligent transportation systems. It has experienced significant advancements thanks to the power of deep learning in capturing latent patterns of traffic data. However, recent deep-learning architectures require intricate model designs and lack an intuitive understanding of the mapping from input data to predicted results. Achieving both accuracy and explainability in traffic prediction models remains a challenge due to the complexity of traffic data and the inherent opacity of deep learning models. To tackle these challenges, we propose a traffic flow prediction model based on large language models ({LLMs}) to generate explainable traffic predictions, named {xTP}-{LLM}. By transferring multi-modal traffic data into natural language descriptions, {xTP}-{LLM} captures complex time-series patterns and external factors from comprehensive traffic data. The {LLM} framework is fine-tuned using language-based instructions to align with spatial-temporal traffic flow data. Empirically, {xTP}-{LLM} shows competitive accuracy compared with deep learning baselines, while providing an intuitive and reliable explanation for predictions. This study contributes to advancing explainable traffic prediction models and lays a foundation for future exploration of {LLM} applications in transportation.},
  pages        = {100150},
  journaltitle = {Communications in Transportation Research},
  shortjournal = {Communications in Transportation Research},
  author       = {Guo, Xusen and Zhang, Qiming and Jiang, Junyue and Peng, Mingxing and Zhu, Meixin and Yang, Hao Frank},
  urldate      = {2025-04-18},
  date         = {2024-12-01},
  note         = {{TLDR}: This paper proposes a Traffic flow Prediction model based on Large Language Models ({LLMs}) to generate explainable traffic predictions, named {xTP}-{LLM}, and is the first study to use {LLM} for explainable prediction of traffic flows.},
  keywords     = {Large language models, Spatial-temporal prediction, Traffic flow prediction, Explainability},
  file         = {已提交版本:C\:\\Users\\yanha\\Zotero\\storage\\64Y6Q8KB\\Guo 等 - 2024 - Towards explainable traffic flow prediction with large language models.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\N95YZABB\\S2772424724000337.html:text/html}
}

@misc{guo_towards_2024,
  location  = {Rochester, {NY}},
  title     = {Towards Responsible and Reliable Traffic Flow Prediction with Large Language Models},
  url       = {https://papers.ssrn.com/abstract=4805901},
  doi       = {10.2139/ssrn.4805901},
  abstract  = {Traffic forecasting is crucial for intelligent transportation systems. It has experienced significant advancements thanks to the power of deep learning in capturing latent patterns of traffic data. However, recent deep-learning architectures require intricate model designs and lack an intuitive understanding of the mapping from input data to predicted results. Achieving both accuracy and responsibility in traffic prediction models remains a challenge due to the complexity of traffic data and the inherent opacity of deep learning models. To tackle these challenges, we propose a Responsible and Reliable Traffic flow forecasting model with Large Language Models (R2T-{LLM}), which leverages large language models ({LLMs}) to generate responsible traffic predictions. By transferring multi-modal traffic data into natural language descriptions, R2T-{LLM} captures complex spatial-temporal patterns and external factors from comprehensive traffic data. The {LLM} framework is fine-tuned using language-based instructions to align with spatial-temporal traffic flow data. Empirically, R2T-{LLM} shows competitive accuracy compared with deep learning baselines, while providing an intuitive and reliable explanation for predictions. We discuss the spatialtemporal and input dependencies for conditional future flow forecasting, showcasing R2T-{LLM}'s potential for diverse city prediction tasks. This paper contributes to advancing accountable traffic prediction models and lays a foundation for future exploration of {LLM} applications in transportation. To the best of our knowledge, this is the first study to use {LLM} for accountable and reliable prediction of traffic flows.},
  number    = {4805901},
  publisher = {Social Science Research Network},
  author    = {Guo, Xusen and Zhang, Qiming and Jiang, Junyue and Peng, Mingxing and Yang, Hao Frank and Zhu, Meixin},
  urldate   = {2024-11-26},
  date      = {2024-04-24},
  langid    = {english},
  keywords  = {Large language models, Responsibility., Spatial-temporal prediction, Traffic flow prediction, ⭐⭐⭐⭐},
  file      = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\RK5N5QC2\\Guo 等 - 2024 - Towards Responsible and Reliable Traffic Flow Prediction with Large Language Models.pdf:application/pdf}
}

@misc{gupta_last_2025,
  title      = {{LAST} {SToP} For Modeling Asynchronous Time Series},
  url        = {http://arxiv.org/abs/2502.01922},
  doi        = {10.48550/arXiv.2502.01922},
  abstract   = {We present a novel prompt design for Large Language Models ({LLMs}) tailored to Asynchronous Time Series. Unlike regular time series, which assume values at evenly spaced time points, asynchronous time series consist of timestamped events occurring at irregular intervals, each described in natural language. Our approach effectively utilizes the rich natural language of event descriptions, allowing {LLMs} to benefit from their broad world knowledge for reasoning across different domains and tasks. This allows us to extend the scope of asynchronous time series analysis beyond forecasting to include tasks like anomaly detection and data imputation. We further introduce Stochastic Soft Prompting, a novel prompt-tuning mechanism that significantly improves model performance, outperforming existing fine-tuning methods such as {QLoRA}. Through extensive experiments on real world datasets, we demonstrate that our approach achieves state-of-the-art performance across different tasks and datasets.},
  number     = {{arXiv}:2502.01922},
  publisher  = {{arXiv}},
  author     = {Gupta, Shubham and Durand, Thibaut and Taylor, Graham and Białokozowicz, Lilian W.},
  urldate    = {2025-02-24},
  date       = {2025-02-04},
  eprinttype = {arxiv},
  eprint     = {2502.01922 [cs]},
  note       = {{TLDR}: A novel prompt design for Large Language Models tailored to Asynchronous Time Series is presented and Stochastic Soft Prompting, a novel prompt-tuning mechanism that significantly improves model performance, outperforming existing fine-tuning methods such as {QLoRA} is introduced.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\24VPQ3VX\\Gupta 等 - 2025 - LAST SToP For Modeling Asynchronous Time Series.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4RHWYGB4\\2502.html:text/html}
}

@misc{han_uncertainty-aware_2025,
  title      = {Uncertainty-Aware Graph Structure Learning},
  url        = {http://arxiv.org/abs/2502.12618},
  doi        = {10.48550/arXiv.2502.12618},
  abstract   = {Graph Neural Networks ({GNNs}) have become a prominent approach for learning from graph-structured data. However, their effectiveness can be significantly compromised when the graph structure is suboptimal. To address this issue, Graph Structure Learning ({GSL}) has emerged as a promising technique that refines node connections adaptively. Nevertheless, we identify two key limitations in existing {GSL} methods: 1) Most methods primarily focus on node similarity to construct relationships, while overlooking the quality of node information. Blindly connecting low-quality nodes and aggregating their ambiguous information can degrade the performance of other nodes. 2) The constructed graph structures are often constrained to be symmetric, which may limit the model's flexibility and effectiveness. To overcome these limitations, we propose an Uncertainty-aware Graph Structure Learning ({UnGSL}) strategy. {UnGSL} estimates the uncertainty of node information and utilizes it to adjust the strength of directional connections, where the influence of nodes with high uncertainty is adaptively reduced. Importantly, {UnGSL} serves as a plug-in module that can be seamlessly integrated into existing {GSL} methods with minimal additional computational cost. In our experiments, we implement {UnGSL} into six representative {GSL} methods, demonstrating consistent performance improvements.},
  number     = {{arXiv}:2502.12618},
  publisher  = {{arXiv}},
  author     = {Han, Shen and Zhou, Zhiyao and Chen, Jiawei and Hao, Zhezheng and Zhou, Sheng and Wang, Gang and Feng, Yan and Chen, Chun and Wang, Can},
  urldate    = {2025-03-06},
  date       = {2025-02-19},
  eprinttype = {arxiv},
  eprint     = {2502.12618 [cs]},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\8Y6CTRI7\\Han 等 - 2025 - Uncertainty-Aware Graph Structure Learning.pdf:application/pdf}
}

@misc{hao_large_2024,
  title      = {Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools},
  url        = {http://arxiv.org/abs/2404.11891},
  doi        = {10.48550/arXiv.2404.11891},
  abstract   = {The recent advancements of Large Language Models ({LLMs}), with their abundant world knowledge and capabilities of tool-using and reasoning, fostered many {LLM} planning algorithms. However, {LLMs} have not shown to be able to accurately solve complex combinatorial optimization problems. In Xie et al. (2024), the authors proposed {TravelPlanner}, a U.S. domestic travel planning benchmark, and showed that {LLMs} themselves cannot make travel plans that satisfy user requirements with a best success rate of 0.6\%. In this work, we propose a framework that enables {LLMs} to formally formulate and solve the travel planning problem as a satisfiability modulo theory ({SMT}) problem and use {SMT} solvers interactively and automatically solve the combinatorial search problem. The {SMT} solvers guarantee the satisfiable of input constraints and the {LLMs} can enable a language-based interaction with our framework. When the input constraints cannot be satisfiable, our {LLM}-based framework will interactively offer suggestions to users to modify their travel requirements via automatic reasoning using the {SMT} solvers. We evaluate our framework with {TravelPlanner} and achieve a success rate of 97\%. We also create a separate dataset that contain international travel benchmarks and use both dataset to evaluate the effectiveness of our interactive planning framework when the initial user queries cannot be satisfied. Our framework could generate valid plans with an average success rate of 78.6\% for our dataset and 85.0\% for {TravelPlanner} according to diverse humans preferences.},
  number     = {{arXiv}:2404.11891},
  publisher  = {{arXiv}},
  author     = {Hao, Yilun and Chen, Yongchao and Zhang, Yang and Fan, Chuchu},
  urldate    = {2024-05-06},
  date       = {2024-04-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.11891 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
  file       = {2024_Large Language Models Can Plan Your Travels Rigorously with Formal Verification_Hao et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\6SQZS45B\\2024_Large Language Models Can Plan Your Travels Rigorously with Formal Verification_Hao et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\AW24I2ZK\\2404.html:text/html}
}

@article{hastings_monte_nodate,
  title    = {Monte Carlo Sampling Methods Using Markov Chains and Their Applications},
  abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  author   = {Hastings, W K},
  langid   = {english},
  keywords = {/unread, ❓ Multiple {DOI}},
  file     = {Hastings - Monte Carlo Sampling Methods Using Markov Chains a.pdf:C\:\\Users\\yanha\\Zotero\\storage\\7MJE4YBP\\Hastings - Monte Carlo Sampling Methods Using Markov Chains a.pdf:application/pdf}
}

@misc{hu_context-alignment_2025,
  title      = {Context-Alignment: Activating and Enhancing {LLM} Capabilities in Time Series},
  url        = {http://arxiv.org/abs/2501.03747},
  doi        = {10.48550/arXiv.2501.03747},
  shorttitle = {Context-Alignment},
  abstract   = {Recently, leveraging pre-trained Large Language Models ({LLMs}) for time series ({TS}) tasks has gained increasing attention, which involves activating and enhancing {LLMs}' capabilities. Many methods aim to activate {LLMs}' capabilities based on token-level alignment but overlook {LLMs}' inherent strength on natural language processing -- their deep understanding of linguistic logic and structure rather than superficial embedding processing. We propose Context-Alignment, a new paradigm that aligns {TS} with a linguistic component in the language environments familiar to {LLMs} to enable {LLMs} to contextualize and comprehend {TS} data, thereby activating their capabilities. Specifically, such context-level alignment comprises structural alignment and logical alignment, which is achieved by a Dual-Scale Context-Alignment {GNNs} ({DSCA}-{GNNs}) applied to {TS}-language multimodal inputs. Structural alignment utilizes dual-scale nodes to describe hierarchical structure in {TS}-language, enabling {LLMs} treat long {TS} data as a whole linguistic component while preserving intrinsic token features. Logical alignment uses directed edges to guide logical relationships, ensuring coherence in the contextual semantics. Demonstration examples prompt are employed to construct Demonstration Examples based Context-Alignment ({DECA}) following {DSCA}-{GNNs} framework. {DECA} can be flexibly and repeatedly integrated into various layers of pre-trained {LLMs} to improve awareness of logic and structure, thereby enhancing performance. Extensive experiments show the effectiveness of {DECA} and the importance of Context-Alignment across tasks, particularly in few-shot and zero-shot forecasting, confirming that Context-Alignment provide powerful prior knowledge on context.},
  number     = {{arXiv}:2501.03747},
  publisher  = {{arXiv}},
  author     = {Hu, Yuxiao and Li, Qian and Zhang, Dongxiao and Yan, Jinyue and Chen, Yuntian},
  urldate    = {2025-01-22},
  date       = {2025-01-07},
  eprinttype = {arxiv},
  eprint     = {2501.03747 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language, Statistics - Applications},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\UICUJYGF\\Hu 等 - 2025 - Context-Alignment Activating and Enhancing LLM Capabilities in Time Series.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\YSQXPKRX\\2501.html:text/html}
}

@misc{hu_fm-ts_2024,
  title      = {{FM}-{TS}: Flow Matching for Time Series Generation},
  url        = {http://arxiv.org/abs/2411.07506},
  doi        = {10.48550/arXiv.2411.07506},
  shorttitle = {{FM}-{TS}},
  abstract   = {Time series generation has emerged as an essential tool for analyzing temporal data across numerous fields. While diffusion models have recently gained significant attention in generating high-quality time series, they tend to be computationally demanding and reliant on complex stochastic processes. To address these limitations, we introduce {FM}-{TS}, a rectified Flow Matching-based framework for Time Series generation, which simplifies the time series generation process by directly optimizing continuous trajectories. This approach avoids the need for iterative sampling or complex noise schedules typically required in diffusion-based models. {FM}-{TS} is more efficient in terms of training and inference. Moreover, {FM}-{TS} is highly adaptive, supporting both conditional and unconditional time series generation. Notably, through our novel inference design, the model trained in an unconditional setting can seamlessly generalize to conditional tasks without the need for retraining. Extensive benchmarking across both settings demonstrates that {FM}-{TS} consistently delivers superior performance compared to existing approaches while being more efficient in terms of training and inference. For instance, in terms of discriminative score, {FM}-{TS} achieves 0.005, 0.019, 0.011, 0.005, 0.053, and 0.106 on the Sines, Stocks, {ETTh}, {MuJoCo}, Energy, and {fMRI} unconditional time series datasets, respectively, significantly outperforming the second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and 0.167 on the same datasets. We have achieved superior performance in solar forecasting and {MuJoCo} imputation tasks, significantly enhanced by our innovative \$t\$ power sampling method. The code is available at https://github.com/{UNITES}-Lab/{FMTS}.},
  number     = {{arXiv}:2411.07506},
  publisher  = {{arXiv}},
  author     = {Hu, Yang and Wang, Xiao and Wu, Lirong and Zhang, Huatian and Li, Stan Z. and Wang, Sheng and Chen, Tianlong},
  urldate    = {2024-11-28},
  date       = {2024-11-12},
  eprinttype = {arxiv},
  eprint     = {2411.07506},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, ⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\C2MLA26J\\Hu 等 - 2024 - FM-TS Flow Matching for Time Series Generation.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RIZH3VK3\\2411.html:text/html}
}

@misc{huang_can_2023,
  title      = {Can {LLMs} Effectively Leverage Graph Structural Information: When and Why},
  url        = {http://arxiv.org/abs/2309.16595},
  doi        = {10.48550/arXiv.2309.16595},
  shorttitle = {Can {LLMs} Effectively Leverage Graph Structural Information},
  abstract   = {This paper studies Large Language Models ({LLMs}) augmented with structured data--particularly graphs--a crucial data modality that remains underexplored in the {LLM} literature. We aim to understand when and why the incorporation of structural information inherent in graph data can improve the prediction performance of {LLMs} on node classification tasks with textual features. To address the ``when'' question, we examine a variety of prompting methods for encoding structural information, in settings where textual node features are either rich or scarce. For the ``why'' questions, we probe into two potential contributing factors to the {LLM} performance: data leakage and homophily. Our exploration of these questions reveals that (i) {LLMs} can benefit from structural information, especially when textual node features are scarce; (ii) there is no substantial evidence indicating that the performance of {LLMs} is significantly attributed to data leakage; and (iii) the performance of {LLMs} on a target node is strongly positively related to the local homophily ratio of the node{\textbackslash}footnote\{Codes and datasets are at: {\textbackslash}url\{https://github.com/{TRAIS}-Lab/{LLM}-Structured-Data\}\}.},
  number     = {{arXiv}:2309.16595},
  publisher  = {{arXiv}},
  author     = {Huang, Jin and Zhang, Xingjian and Mei, Qiaozhu and Ma, Jiaqi},
  urldate    = {2023-10-24},
  date       = {2023-09-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2309.16595 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2023_Can LLMs Effectively Leverage Graph Structural Information_Huang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Can LLMs Effectively Leverage Graph Structural Information_Huang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\3QZ8RN7N\\2309.html:text/html}
}

@misc{ilbert_samformer_2024,
  title      = {{SAMformer}: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention},
  url        = {http://arxiv.org/abs/2402.10198},
  doi        = {10.48550/arXiv.2402.10198},
  shorttitle = {{SAMformer}},
  abstract   = {Transformer-based architectures achieved breakthrough performance in natural language processing and computer vision, yet they remain inferior to simpler linear baselines in multivariate long-term forecasting. To better understand this phenomenon, we start by studying a toy linear forecasting problem for which we show that transformers are incapable of converging to their true solution despite their high expressive power. We further identify the attention of transformers as being responsible for this low generalization capacity. Building upon this insight, we propose a shallow lightweight transformer model that successfully escapes bad local minima when optimized with sharpness-aware optimization. We empirically demonstrate that this result extends to all commonly used real-world multivariate time series datasets. In particular, {SAMformer} surpasses current state-of-the-art methods and is on par with the biggest foundation model {MOIRAI} while having significantly fewer parameters. The code is available at https://github.com/romilbert/samformer.},
  number     = {{arXiv}:2402.10198},
  publisher  = {{arXiv}},
  author     = {Ilbert, Romain and Odonnat, Ambroise and Feofanov, Vasilii and Virmaux, Aladin and Paolo, Giuseppe and Palpanas, Themis and Redko, Ievgen},
  urldate    = {2024-08-06},
  date       = {2024-06-03},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.10198 [cs, stat]},
  keywords   = {/reading, Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {2024_SAMformer_Ilbert et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\548TUKRX\\2024_SAMformer_Ilbert et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\B4LMIAVL\\2402.html:text/html}
}

@misc{ito_clasp_2024,
  title      = {{CLaSP}: Learning Concepts for Time-Series Signals from Natural Language Supervision},
  url        = {http://arxiv.org/abs/2411.08397},
  doi        = {10.48550/arXiv.2411.08397},
  shorttitle = {{CLaSP}},
  abstract   = {This paper proposes a foundation model called "{CLaSP}" that can search time series signals using natural language that describes the characteristics of the signals as queries. Previous efforts to represent time series signal data in natural language have had challenges in designing a conventional class of time series signal characteristics, formulating their quantification, and creating a dictionary of synonyms. To overcome these limitations, the proposed method introduces a neural network based on contrastive learning. This network is first trained using the datasets {TRUCE} and {SUSHI}, which consist of time series signals and their corresponding natural language descriptions. Previous studies have proposed vocabularies that data analysts use to describe signal characteristics, and {SUSHI} was designed to cover these terms. We believe that a neural network trained on these datasets will enable data analysts to search using natural language vocabulary. Furthermore, our method does not require a dictionary of predefined synonyms, and it leverages common sense knowledge embedded in a large-scale language model ({LLM}). Experimental results demonstrate that {CLaSP} enables natural language search of time series signal data and can accurately learn the points at which signal data changes.},
  number     = {{arXiv}:2411.08397},
  publisher  = {{arXiv}},
  author     = {Ito, Aoi and Dohi, Kota and Kawaguchi, Yohei},
  urldate    = {2025-01-08},
  date       = {2024-11-13},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2411.08397 [cs]},
  note       = {{TLDR}: Experimental results demonstrate that {CLaSP} enables natural language search of time series signal data and can accurately learn the points at which signal data changes.},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\PX73DCAK\\Ito 等 - 2024 - CLaSP Learning Concepts for Time-Series Signals from Natural Language Supervision.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\BKC2M3MV\\2411.html:text/html}
}

@article{ji_spatio-temporal_2023,
  title        = {Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction},
  volume       = {37},
  rights       = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/25555},
  doi          = {10.1609/aaai.v37i4.25555},
  abstract     = {Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning ({ST}-{SSL}) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our {ST}-{SSL} is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our {ST}-{SSL} first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two {SSL} auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that {ST}-{SSL} consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/{ST}-{SSL}.},
  pages        = {4356--4364},
  number       = {4},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Ji, Jiahao and Wang, Jingyuan and Huang, Chao and Wu, Junjie and Xu, Boren and Wu, Zhenhe and Zhang, Junbo and Zheng, Yu},
  urldate      = {2023-08-15},
  date         = {2023-06-26},
  langid       = {english},
  note         = {Number: 4},
  keywords     = {/reading, {APP}: Transportation},
  file         = {2023_Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction_Ji et al.pdf:E\:\\BaiduNetdiskWorkspace\\zotero\\storage\\交通预测\\2023_Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction_Ji et al.pdf:application/pdf}
}

@article{jia_gpt4mts_2024,
  title        = {{GPT}4MTS: Prompt-based Large Language Model for Multimodal Time-series Forecasting},
  volume       = {38},
  rights       = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/30383},
  doi          = {10.1609/aaai.v38i21.30383},
  shorttitle   = {{GPT}4MTS},
  abstract     = {Time series forecasting is an essential area of machine learning with a wide range of real-world applications. Most of the previous forecasting models aim to capture dynamic characteristics from uni-modal numerical historical data. Although extra knowledge can boost the time series forecasting performance, it is hard to collect such information. In addition, how to fuse the multimodal information is non-trivial. In this paper, we first propose a general principle of collecting the corresponding textual information from different data sources with the help of modern large language models ({LLM}). Then, we propose a prompt-based {LLM} framework to utilize both the numerical data and the textual information simultaneously, named {GPT}4MTS. In practice, we propose a {GDELT}-based multimodal time series dataset for news impact forecasting, which provides a concise and well-structured version of time series dataset with textual information for further research in communication. Through extensive experiments, we demonstrate the effectiveness of our proposed method on forecasting tasks with extra-textual information.},
  pages        = {23343--23351},
  number       = {21},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Jia, Furong and Wang, Kevin and Zheng, Yixiang and Cao, Defu and Liu, Yan},
  urldate      = {2024-04-09},
  date         = {2024-03-24},
  langid       = {english},
  note         = {Number: 21},
  keywords     = {/reading, {AI} For Accessibility},
  file         = {2024_GPT4MTS_Jia et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\VXEH3ADW\\2024_GPT4MTS_Jia et al.pdf:application/pdf}
}

@misc{jiang_explainable_2025,
  title      = {Explainable Multi-modal Time Series Prediction with {LLM}-in-the-Loop},
  url        = {http://arxiv.org/abs/2503.01013},
  doi        = {10.48550/arXiv.2503.01013},
  abstract   = {Time series analysis provides essential insights for real-world system dynamics and informs downstream decision-making, yet most existing methods often overlook the rich contextual signals present in auxiliary modalities. To bridge this gap, we introduce {TimeXL}, a multi-modal prediction framework that integrates a prototype-based time series encoder with three collaborating Large Language Models ({LLMs}) to deliver more accurate predictions and interpretable explanations. First, a multi-modal prototype-based encoder processes both time series and textual inputs to generate preliminary forecasts alongside case-based rationales. These outputs then feed into a prediction {LLM}, which refines the forecasts by reasoning over the encoder's predictions and explanations. Next, a reflection {LLM} compares the predicted values against the ground truth, identifying textual inconsistencies or noise. Guided by this feedback, a refinement {LLM} iteratively enhances text quality and triggers encoder retraining. This closed-loop workflow -- prediction, critique (reflect), and refinement -- continuously boosts the framework's performance and interpretability. Empirical evaluations on four real-world datasets demonstrate that {TimeXL} achieves up to 8.9{\textbackslash}\% improvement in {AUC} and produces human-centric, multi-modal explanations, highlighting the power of {LLM}-driven reasoning for time series prediction.},
  number     = {{arXiv}:2503.01013},
  publisher  = {{arXiv}},
  author     = {Jiang, Yushan and Yu, Wenchao and Lee, Geon and Song, Dongjin and Shin, Kijung and Cheng, Wei and Liu, Yanchi and Chen, Haifeng},
  urldate    = {2025-03-12},
  date       = {2025-03-02},
  eprinttype = {arxiv},
  eprint     = {2503.01013 [cs]},
  note       = {{TLDR}: {TimeXL}, a multi-modal prediction framework that integrates a prototype-based time series encoder with three collaborating Large Language Models to deliver more accurate predictions and interpretable explanations, is introduced.},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\TJXGFYFY\\Jiang 等 - 2025 - Explainable Multi-modal Time Series Prediction with LLM-in-the-Loop.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\J5ENR5ZA\\2503.html:text/html}
}

@misc{jiang_pdformer_2023,
  title      = {{PDFormer}: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction},
  url        = {http://arxiv.org/abs/2301.07945},
  doi        = {10.48550/arXiv.2301.07945},
  shorttitle = {{PDFormer}},
  abstract   = {As a core technology of Intelligent Transportation System, traffic flow prediction has a wide range of applications. The fundamental challenge in traffic flow prediction is to effectively model the complex spatial-temporal dependencies in traffic data. Spatial-temporal Graph Neural Network ({GNN}) models have emerged as one of the most promising methods to solve this problem. However, {GNN}-based models have three major limitations for traffic prediction: i) Most methods model spatial dependencies in a static manner, which limits the ability to learn dynamic urban traffic patterns; ii) Most methods only consider short-range spatial information and are unable to capture long-range spatial dependencies; iii) These methods ignore the fact that the propagation of traffic conditions between locations has a time delay in traffic systems. To this end, we propose a novel Propagation Delay-aware dynamic long-range {transFormer}, namely {PDFormer}, for accurate traffic flow prediction. Specifically, we design a spatial self-attention module to capture the dynamic spatial dependencies. Then, two graph masking matrices are introduced to highlight spatial dependencies from short- and long-range views. Moreover, a traffic delay-aware feature transformation module is proposed to empower {PDFormer} with the capability of explicitly modeling the time delay of spatial information propagation. Extensive experimental results on six real-world public traffic datasets show that our method can not only achieve state-of-the-art performance but also exhibit competitive computational efficiency. Moreover, we visualize the learned spatial-temporal attention map to make our model highly interpretable.},
  number     = {{arXiv}:2301.07945},
  publisher  = {{arXiv}},
  author     = {Jiang, Jiawei and Han, Chengkai and Zhao, Wayne Xin and Wang, Jingyuan},
  urldate    = {2024-02-06},
  date       = {2023-03-04},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2301.07945 [cs]},
  keywords   = {Computer Science - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\DKJKX3XD\\2301.html:text/html;Jiang et al_2023_PDFormer.pdf:C\:\\Users\\yanha\\Zotero\\storage\\P4V2BEFD\\Jiang et al_2023_PDFormer.pdf:application/pdf}
}

@misc{jin_graph_2024,
  title      = {Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs},
  url        = {http://arxiv.org/abs/2404.07103},
  doi        = {10.48550/arXiv.2404.07103},
  shorttitle = {Graph Chain-of-Thought},
  abstract   = {Large language models ({LLMs}), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment {LLMs} with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains, texts are interconnected (e.g., academic papers in a bibliographic graph are linked by citations and co-authorships) which form a (text-attributed) graph. The knowledge in such graphs is encoded not only in single texts/nodes but also in their associated connections. To facilitate the research of augmenting {LLMs} with graphs, we manually construct a Graph Reasoning Benchmark dataset called {GRBench}, containing 1,740 questions that can be answered with the knowledge from 10 domain graphs. Then, we propose a simple and effective framework called Graph Chain-of-thought (Graph-{CoT}) to augment {LLMs} with graphs by encouraging {LLMs} to reason on the graph iteratively. Each Graph-{CoT} iteration consists of three sub-steps: {LLM} reasoning, {LLM}-graph interaction, and graph execution. We conduct systematic experiments with three {LLM} backbones on {GRBench}, where Graph-{CoT} outperforms the baselines consistently. The code is available at https://github.com/{PeterGriffinJin}/Graph-{CoT}.},
  number     = {{arXiv}:2404.07103},
  publisher  = {{arXiv}},
  author     = {Jin, Bowen and Xie, Chulin and Zhang, Jiawei and Roy, Kashob Kumar and Zhang, Yu and Wang, Suhang and Meng, Yu and Han, Jiawei},
  urldate    = {2024-05-07},
  date       = {2024-04-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.07103 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Information Retrieval},
  file       = {2024_Graph Chain-of-Thought_Jin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\I7BCDPGT\\2024_Graph Chain-of-Thought_Jin et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\B6AJ5QHD\\2404.html:text/html}
}

@misc{jin_large_2023,
  title      = {Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook},
  url        = {http://arxiv.org/abs/2310.10196},
  doi        = {10.48550/arXiv.2310.10196},
  shorttitle = {Large Models for Time Series and Spatio-Temporal Data},
  abstract   = {Temporal data, notably time series and spatio-temporal data, are prevalent in real-world applications. They capture dynamic system measurements and are produced in vast quantities by both physical and virtual sensors. Analyzing these data types is vital to harnessing the rich information they encompass and thus benefits a wide range of downstream tasks. Recent advances in large language and other foundational models have spurred increased use of these models in time series and spatio-temporal data mining. Such methodologies not only enable enhanced pattern recognition and reasoning across diverse domains but also lay the groundwork for artificial general intelligence capable of comprehending and processing common temporal data. In this survey, we offer a comprehensive and up-to-date review of large models tailored (or adapted) for time series and spatio-temporal data, spanning four key facets: data types, model categories, model scopes, and application areas/tasks. Our objective is to equip practitioners with the knowledge to develop applications and further research in this underexplored domain. We primarily categorize the existing literature into two major clusters: large models for time series analysis ({LM}4TS) and spatio-temporal data mining ({LM}4STD). On this basis, we further classify research based on model scopes (i.e., general vs. domain-specific) and application areas/tasks. We also provide a comprehensive collection of pertinent resources, including datasets, model assets, and useful tools, categorized by mainstream applications. This survey coalesces the latest strides in large model-centric research on time series and spatio-temporal data, underscoring the solid foundations, current advances, practical applications, abundant resources, and future research opportunities.},
  number     = {{arXiv}:2310.10196},
  publisher  = {{arXiv}},
  author     = {Jin, Ming and Wen, Qingsong and Liang, Yuxuan and Zhang, Chaoli and Xue, Siqiao and Wang, Xue and Zhang, James and Wang, Yi and Chen, Haifeng and Li, Xiaoli and Pan, Shirui and Tseng, Vincent S. and Zheng, Yu and Chen, Lei and Xiong, Hui},
  urldate    = {2023-10-25},
  date       = {2023-10-20},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.10196 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2023_Large Models for Time Series and Spatio-Temporal Data_Jin et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Large Models for Time Series and Spatio-Temporal Data_Jin et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZYEEZSIY\\2310.html:text/html}
}

@online{jin_time_2024,
  title      = {Time Series Forecasting with {LLMs}: Understanding and Enhancing Model Capabilities},
  url        = {https://arxiv.org/abs/2402.10835v2},
  shorttitle = {Time Series Forecasting with {LLMs}},
  abstract   = {Large language models ({LLMs}) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from {LLMs}. However, there is a research gap in the {LLMs}' preferences in this field. In this paper, by comparing {LLMs} with traditional models, many properties of {LLMs} in time series prediction are found. For example, our study shows that {LLMs} excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require {LLMs} to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of {LLMs} for time series. Overall, this study contributes to insight into the advantages and limitations of {LLMs} in time series forecasting under different conditions.},
  titleaddon = {{arXiv}.org},
  author     = {Jin, Mingyu and Tang, Hua and Zhang, Chong and Yu, Qinkai and Liu, Chengzhi and Zhu, Suiyuan and Zhang, Yongfeng and Du, Mengnan},
  urldate    = {2024-05-07},
  date       = {2024-02-16},
  langid     = {english},
  keywords   = {/reading},
  file       = {2024_Time Series Forecasting with LLMs_Jin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\864E6BAW\\2024_Time Series Forecasting with LLMs_Jin et al.pdf:application/pdf}
}

@misc{jin_time_2024-1,
  title      = {Time Series Forecasting with {LLMs}: Understanding and Enhancing Model Capabilities},
  url        = {http://arxiv.org/abs/2402.10835},
  doi        = {10.48550/arXiv.2402.10835},
  shorttitle = {Time Series Forecasting with {LLMs}},
  abstract   = {Large language models ({LLMs}) have been applied in many fields with rapid development in recent years. As a classic machine learning task, time series forecasting has recently received a boost from {LLMs}. However, there is a research gap in the {LLMs}' preferences in this field. In this paper, by comparing {LLMs} with traditional models, many properties of {LLMs} in time series prediction are found. For example, our study shows that {LLMs} excel in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. We explain our findings through designing prompts to require {LLMs} to tell the period of the datasets. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases positively affects the predictive performance of {LLMs} for time series. Overall, this study contributes to insight into the advantages and limitations of {LLMs} in time series forecasting under different conditions.},
  number     = {{arXiv}:2402.10835},
  publisher  = {{arXiv}},
  author     = {Jin, Mingyu and Tang, Hua and Zhang, Chong and Yu, Qinkai and Liu, Chengzhi and Zhu, Suiyuan and Zhang, Yongfeng and Du, Mengnan},
  urldate    = {2024-04-10},
  date       = {2024-02-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.10835 [cs]},
  keywords   = {/reading, Computer Science - Computation and Language},
  file       = {2024_Time Series Forecasting with LLMs_Jin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\K7I7DK8Q\\2024_Time Series Forecasting with LLMs_Jin et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\23IZD8XA\\2402.html:text/html}
}

@misc{jin_time-llm_2023,
  title      = {Time-{LLM}: Time Series Forecasting by Reprogramming Large Language Models},
  url        = {http://arxiv.org/abs/2310.01728},
  doi        = {10.48550/arXiv.2310.01728},
  shorttitle = {Time-{LLM}},
  abstract   = {Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process ({NLP}) and computer vision ({CV}), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in {NLP} and {CV}, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models ({LLMs}) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-{LLM}, a reprogramming framework to repurpose {LLMs} for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen {LLM} to align the two modalities. To augment the {LLM}'s ability to reason with time series data, we propose Prompt-as-Prefix ({PaP}), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the {LLM} are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-{LLM} is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-{LLM} excels in both few-shot and zero-shot learning scenarios.},
  number     = {{arXiv}:2310.01728},
  publisher  = {{arXiv}},
  author     = {Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y. and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and Wen, Qingsong},
  urldate    = {2023-10-19},
  date       = {2023-10-02},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.01728 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2023_Time-LLM_Jin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\TILMWLZ8\\2023_Time-LLM_Jin et al.pdf:application/pdf;2023_Time-LLM_Jin et al.pdf:E\:\\BaiduNetdiskWorkspace\\zotero\\storage\\交通预测\\2023_Time-LLM_Jin et al.pdf:application/pdf;2023_Time-LLM_Jin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\5HDRCAYZ\\2023_Time-LLM_Jin et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\KHESHJ6L\\2310.html:text/html}
}

@misc{kim_multi-modal_2024,
  title      = {Multi-Modal Forecaster: Jointly Predicting Time Series and Textual Data},
  url        = {http://arxiv.org/abs/2411.06735},
  doi        = {10.48550/arXiv.2411.06735},
  shorttitle = {Multi-Modal Forecaster},
  abstract   = {Current forecasting approaches are largely unimodal and ignore the rich textual data that often accompany the time series due to lack of well-curated multimodal benchmark dataset. In this work, we develop {TimeText} Corpus ({TTC}), a carefully curated, time-aligned text and time dataset for multimodal forecasting. Our dataset is composed of sequences of numbers and text aligned to timestamps, and includes data from two different domains: climate science and healthcare. Our data is a significant contribution to the rare selection of available multimodal datasets. We also propose the Hybrid Multi-Modal Forecaster (Hybrid-{MMF}), a multimodal {LLM} that jointly forecasts both text and time series data using shared embeddings. However, contrary to our expectations, our Hybrid-{MMF} model does not outperform existing baselines in our experiments. This negative result highlights the challenges inherent in multimodal forecasting. Our code and data are available at https://github.com/Rose-{STL}-Lab/Multimodal\_ Forecasting.},
  number     = {{arXiv}:2411.06735},
  publisher  = {{arXiv}},
  author     = {Kim, Kai and Tsai, Howard and Sen, Rajat and Das, Abhimanyu and Zhou, Zihao and Tanpure, Abhishek and Luo, Mathew and Yu, Rose},
  urldate    = {2024-11-12},
  date       = {2024-11-11},
  eprinttype = {arxiv},
  eprint     = {2411.06735},
  keywords   = {Computer Science - Artificial Intelligence},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\K7VTD89D\\Kim 等 - 2024 - Multi-Modal Forecaster Jointly Predicting Time Series and Textual Data.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\FIKCESYB\\2411.html:text/html}
}

@inproceedings{kim_reversible_2021,
  title      = {Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift},
  url        = {https://openreview.net/forum?id=cGDAkQo1C0p},
  abstract   = {Statistical properties such as mean and variance often change over time in time series, i.e., time-series data suffer from a distribution shift problem. This change in temporal distribution is one of the main challenges that prevent accurate time-series forecasting. To address this issue, we propose a simple yet effective normalization method called reversible instance normalization ({RevIN}), a generally-applicable normalization-and-denormalization method with learnable affine transformation. The proposed method is symmetrically structured to remove and restore the statistical information of a time-series instance, leading to significant performance improvements in time-series forecasting, as shown in Fig. 1. We demonstrate the effectiveness of {RevIN} via extensive quantitative and qualitative analyses on various real-world datasets, addressing the distribution shift problem.},
  eventtitle = {International Conference on Learning Representations},
  author     = {Kim, Taesung and Kim, Jinhee and Tae, Yunwon and Park, Cheonbok and Choi, Jang-Ho and Choo, Jaegul},
  urldate    = {2024-02-06},
  date       = {2021-10-06},
  langid     = {english},
  keywords   = {/unread},
  file       = {Kim et al_2021_Reversible Instance Normalization for Accurate Time-Series Forecasting against.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9CWECIJY\\Kim et al_2021_Reversible Instance Normalization for Accurate Time-Series Forecasting against.pdf:application/pdf}
}

@article{kingma2014adam,
  title   = {Adam: A method for stochastic optimization},
  author  = {Kingma, Diederik P and Ba, Jimmy},
  journal = {arXiv preprint arXiv:1412.6980},
  year    = {2014}
}

@misc{klemmer_positional_2021,
  title      = {Positional Encoder Graph Neural Networks for Geographic Data},
  url        = {http://arxiv.org/abs/2111.10144},
  abstract   = {Graph neural networks ({GNNs}) provide a powerful and scalable solution for modeling continuous spatial data. However, they often rely on Euclidean distances to construct the input graphs. This assumption can be improbable in many real-world settings, where the spatial structure is more complex and explicitly non-Euclidean (e.g., road networks). Here, we propose {PE}-{GNN}, a new framework that incorporates spatial context and correlation explicitly into the models. Building on recent advances in geospatial auxiliary task learning and semantic spatial embeddings, our proposed method (1) learns a context-aware vector encoding of the geographic coordinates and (2) predicts spatial autocorrelation in the data in parallel with the main task. On spatial interpolation and regression tasks, we show the effectiveness of our approach, improving performance over different state-of-the-art {GNN} approaches. We observe that our approach not only vastly improves over the {GNN} baselines, but can match Gaussian processes, the most commonly utilized method for spatial interpolation problems.},
  number     = {{arXiv}:2111.10144},
  publisher  = {{arXiv}},
  author     = {Klemmer, Konstantin and Safir, Nathan and Neill, Daniel B.},
  urldate    = {2023-12-21},
  date       = {2021-11-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2111.10144 [cs]},
  note       = {version: 1},
  keywords   = {Computer Science - Machine Learning, /unread, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2021_Positional Encoder Graph Neural Networks for Geographic Data_Klemmer et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\MZXXUN49\\2021_Positional Encoder Graph Neural Networks for Geographic Data_Klemmer et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RCCBBMED\\2111.html:text/html}
}

@article{klingwort_framework_2023,
  title        = {A framework for population inference: Combining machine learning, network analysis, and non-probability road sensor data},
  volume       = {103},
  issn         = {01989715},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S019897152300039X},
  doi          = {10.1016/j.compenvurbsys.2023.101976},
  shorttitle   = {A framework for population inference},
  pages        = {101976},
  journaltitle = {Computers, Environment and Urban Systems},
  shortjournal = {Computers, Environment and Urban Systems},
  author       = {Klingwort, Jonas and Burger, Joep},
  urldate      = {2023-07-25},
  date         = {2023-07},
  langid       = {english},
  keywords     = {/unread},
  file         = {2023_A framework for population inference_Klingwort_Burger.pdf:C\:\\Users\\yanha\\Zotero\\storage\\J6EFU4LJ\\2023_A framework for population inference_Klingwort_Burger.pdf:application/pdf}
}

@misc{kollovieh_flow_2024,
  title      = {Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting},
  url        = {http://arxiv.org/abs/2410.03024},
  doi        = {10.48550/arXiv.2410.03024},
  abstract   = {Recent advancements in generative modeling, particularly diffusion models, have opened new directions for time series modeling, achieving state-of-the-art performance in forecasting and synthesis. However, the reliance of diffusion-based models on a simple, fixed prior complicates the generative process since the data and prior distributions differ significantly. We introduce {TSFlow}, a conditional flow matching ({CFM}) model for time series that simplifies the generative problem by combining Gaussian processes, optimal transport paths, and data-dependent prior distributions. By incorporating (conditional) Gaussian processes, {TSFlow} aligns the prior distribution more closely with the temporal structure of the data, enhancing both unconditional and conditional generation. Furthermore, we propose conditional prior sampling to enable probabilistic forecasting with an unconditionally trained model. In our experimental evaluation on eight real-world datasets, we demonstrate the generative capabilities of {TSFlow}, producing high-quality unconditional samples. Finally, we show that both conditionally and unconditionally trained models achieve competitive results in forecasting benchmarks, surpassing other methods on 6 out of 8 datasets.},
  number     = {{arXiv}:2410.03024},
  publisher  = {{arXiv}},
  author     = {Kollovieh, Marcel and Lienen, Marten and Lüdke, David and Schwinn, Leo and Günnemann, Stephan},
  urldate    = {2024-10-24},
  date       = {2024-10-03},
  eprinttype = {arxiv},
  eprint     = {2410.03024},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning, ⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\MVYR7RF8\\Kollovieh 等 - 2024 - Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\5TCYSSY7\\2410.html:text/html}
}

@misc{koloveas_can_2025,
  title      = {Can {LLMs} Predict Citation Intent? An Experimental Analysis of In-context Learning and Fine-tuning on Open {LLMs}},
  url        = {http://arxiv.org/abs/2502.14561},
  doi        = {10.48550/arXiv.2502.14561},
  shorttitle = {Can {LLMs} Predict Citation Intent?},
  abstract   = {This work investigates the ability of open Large Language Models ({LLMs}) to predict citation intent through in-context learning and fine-tuning. Unlike traditional approaches that rely on pre-trained models like {SciBERT}, which require extensive domain-specific pretraining and specialized architectures, we demonstrate that general-purpose {LLMs} can be adapted to this task with minimal task-specific data. We evaluate twelve model variations across five prominent open {LLM} families using zero, one, few, and many-shot prompting to assess performance across scenarios. Our experimental study identifies the top-performing model through extensive experimentation of in-context learning-related parameters, which we fine-tune to further enhance task performance. The results highlight the strengths and limitations of {LLMs} in recognizing citation intents, providing valuable insights for model selection and prompt engineering. Additionally, we make our end-to-end evaluation framework and models openly available for future use.},
  number     = {{arXiv}:2502.14561},
  publisher  = {{arXiv}},
  author     = {Koloveas, Paris and Chatzopoulos, Serafeim and Vergoulis, Thanasis and Tryfonopoulos, Christos},
  urldate    = {2025-02-25},
  date       = {2025-02-20},
  eprinttype = {arxiv},
  eprint     = {2502.14561 [cs]},
  keywords   = {Computer Science - Computation and Language, Computer Science - Digital Libraries},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\58WM6LF9\\Koloveas 等 - 2025 - Can LLMs Predict Citation Intent An Experimental Analysis of In-context Learning and Fine-tuning on.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\MAAU6IU8\\2502.html:text/html}
}

@misc{kong_position_2025,
  title      = {Position: Empowering Time Series Reasoning with Multimodal {LLMs}},
  url        = {http://arxiv.org/abs/2502.01477},
  doi        = {10.48550/arXiv.2502.01477},
  shorttitle = {Position},
  abstract   = {Understanding time series data is crucial for multiple real-world applications. While large language models ({LLMs}) show promise in time series tasks, current approaches often rely on numerical data alone, overlooking the multimodal nature of time-dependent information, such as textual descriptions, visual data, and audio signals. Moreover, these methods underutilize {LLMs}' reasoning capabilities, limiting the analysis to surface-level interpretations instead of deeper temporal and multimodal reasoning. In this position paper, we argue that multimodal {LLMs} ({MLLMs}) can enable more powerful and flexible reasoning for time series analysis, enhancing decision-making and real-world applications. We call on researchers and practitioners to leverage this potential by developing strategies that prioritize trust, interpretability, and robust reasoning in {MLLMs}. Lastly, we highlight key research directions, including novel reasoning paradigms, architectural innovations, and domain-specific applications, to advance time series reasoning with {MLLMs}.},
  number     = {{arXiv}:2502.01477},
  publisher  = {{arXiv}},
  author     = {Kong, Yaxuan and Yang, Yiyuan and Wang, Shiyu and Liu, Chenghao and Liang, Yuxuan and Jin, Ming and Zohren, Stefan and Pei, Dan and Liu, Yan and Wen, Qingsong},
  urldate    = {2025-02-17},
  date       = {2025-02-03},
  eprinttype = {arxiv},
  eprint     = {2502.01477 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\9XG79VDC\\Kong 等 - 2025 - Position Empowering Time Series Reasoning with Multimodal LLMs.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\GKI9ZJXJ\\2502.html:text/html}
}

@misc{kong_time-mqa_2025,
  title      = {Time-{MQA}: Time Series Multi-Task Question Answering with Context Enhancement},
  url        = {http://arxiv.org/abs/2503.01875},
  doi        = {10.48550/arXiv.2503.01875},
  shorttitle = {Time-{MQA}},
  abstract   = {Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-{MQA}), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-{MQA} is the {TSQA} dataset, a large-scale dataset containing \${\textbackslash}sim\$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the {TSQA} dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete {TSQA} dataset, models, executable codes, user study questionnaires for evaluation, and results have all been open-sourced.},
  number     = {{arXiv}:2503.01875},
  publisher  = {{arXiv}},
  author     = {Kong, Yaxuan and Yang, Yiyuan and Hwang, Yoontae and Du, Wenjie and Zohren, Stefan and Wang, Zhangyang and Jin, Ming and Wen, Qingsong},
  urldate    = {2025-03-30},
  date       = {2025-02-26},
  eprinttype = {arxiv},
  eprint     = {2503.01875 [cs]},
  note       = {{TLDR}: This work introduces Time Series Multi-Task Question Answering (Time-{MQA}), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\2H2BPT4F\\Kong 等 - 2025 - Time-MQA Time Series Multi-Task Question Answering with Context Enhancement.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\A4PMPPAG\\2503.html:text/html}
}

@misc{kowsher_llm-mixer_2024,
  title      = {{LLM}-Mixer: Multiscale Mixing in {LLMs} for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2410.11674},
  doi        = {10.48550/arXiv.2410.11674},
  shorttitle = {{LLM}-Mixer},
  abstract   = {Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns. This study presents {LLM}-Mixer, a framework that improves forecasting accuracy through the combination of multiscale time-series decomposition with pre-trained {LLMs} (Large Language Models). {LLM}-Mixer captures both short-term fluctuations and long-term trends by decomposing the data into multiple temporal resolutions and processing them with a frozen {LLM}, guided by a textual prompt specifically designed for time-series data. Extensive experiments conducted on multivariate and univariate datasets demonstrate that {LLM}-Mixer achieves competitive performance, outperforming recent state-of-the-art models across various forecasting horizons. This work highlights the potential of combining multiscale analysis and {LLMs} for effective and scalable time-series forecasting.},
  number     = {{arXiv}:2410.11674},
  publisher  = {{arXiv}},
  author     = {Kowsher, Md and Sobuj, Md Shohanur Islam and Prottasha, Nusrat Jahan and Alanis, E. Alejandro and Garibay, Ozlem Ozmen and Yousefi, Niloofar},
  urldate    = {2024-11-12},
  date       = {2024-10-15},
  eprinttype = {arxiv},
  eprint     = {2410.11674},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\MA6LGB8K\\Kowsher 等 - 2024 - LLM-Mixer Multiscale Mixing in LLMs for Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\IXAUVGFN\\2410.html:text/html}
}

@article{lablack_spatio-temporal_2023,
  title        = {Spatio-temporal graph mixformer for traffic forecasting},
  volume       = {228},
  issn         = {0957-4174},
  url          = {https://www.sciencedirect.com/science/article/pii/S0957417423007832},
  doi          = {10.1016/j.eswa.2023.120281},
  abstract     = {Traffic forecasting is of great importance for intelligent transportation systems ({ITS}). Because of the intricacy implied in traffic behavior and the non-Euclidean nature of traffic data, it is challenging to give an accurate traffic prediction. Despite that previous studies considered the relationship between different nodes, the majority have relied on a static representation and failed to capture the dynamic node interactions over time. Additionally, prior studies employed {RNN}-based models to capture the temporal dependency. While {RNNs} are a popular choice for forecasting problems, they tend to be memory hungry and slow to train. Furthermore, recent studies start utilizing similarity algorithms to better express the implication of a node over the other. However, to our knowledge, none have explored the contribution of node i’s past, over the future state of node j. In this paper, we propose a Spatio-Temporal Graph Mixformer ({STGM}) network, a highly optimized model with low memory footprint. We address the aforementioned limits by utilizing a novel attention mechanism to capture the correlation between temporal and spatial dependencies. Specifically, we use convolution layers with a variable fields of view for each head to capture long–short term temporal dependency. Additionally, we train an estimator model that express the contribution of a node over the desired prediction. The estimation is fed alongside a distance matrix to the attention mechanism. Meanwhile, we use a gated mechanism and a mixer layer to further select and incorporate the different perspectives. Extensive experiments show that the proposed model enjoys a performance gain compared to the baselines while maintaining the lowest parameter counts.},
  pages        = {120281},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  author       = {Lablack, Mourad and Shen, Yanming},
  urldate      = {2024-01-10},
  date         = {2023-10-15},
  langid       = {english},
  keywords     = {/reading, Attention mechanism, Graph neural network, Spatio-temporal multivariate time series, Traffic forecasting},
  file         = {2023_Spatio-temporal graph mixformer for traffic forecasting_Lablack_Shen.pdf:C\:\\Users\\yanha\\Zotero\\storage\\MM6BZ76H\\Lablack 和 Shen - 2023 - Spatio-temporal graph mixformer for traffic foreca.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\FB2NZ4AK\\S0957417423007832.html:text/html}
}

@misc{lee_gecko_2024,
  title      = {Gecko: Versatile Text Embeddings Distilled from Large Language Models},
  url        = {http://arxiv.org/abs/2403.20327},
  shorttitle = {Gecko},
  abstract   = {We present Gecko, a compact and versatile text embedding model. Gecko achieves strong retrieval performance by leveraging a key idea: distilling knowledge from large language models ({LLMs}) into a retriever. Our two-step distillation process begins with generating diverse, synthetic paired data using an {LLM}. Next, we further refine the data quality by retrieving a set of candidate passages for each query, and relabeling the positive and hard negative passages using the same {LLM}. The effectiveness of our approach is demonstrated by the compactness of the Gecko. On the Massive Text Embedding Benchmark ({MTEB}), Gecko with 256 embedding dimensions outperforms all existing entries with 768 embedding size. Gecko with 768 embedding dimensions achieves an average score of 66.31, competing with 7x larger models and 5x higher dimensional embeddings.},
  number     = {{arXiv}:2403.20327},
  publisher  = {{arXiv}},
  author     = {Lee, Jinhyuk and Dai, Zhuyun and Ren, Xiaoqi and Chen, Blair and Cer, Daniel and Cole, Jeremy R. and Hui, Kai and Boratko, Michael and Kapadia, Rajvi and Ding, Wen and Luan, Yi and Duddu, Sai Meher Karthik and Abrego, Gustavo Hernandez and Shi, Weiqiang and Gupta, Nithi and Kusupati, Aditya and Jain, Prateek and Jonnalagadda, Siddhartha Reddy and Chang, Ming-Wei and Naim, Iftekhar},
  urldate    = {2024-04-03},
  date       = {2024-03-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.20327 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {2024_Gecko_Lee et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\KHUWZZQL\\2024_Gecko_Lee et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\KJMTSSJJ\\2403.html:text/html}
}

@misc{lee_timecap_2025,
  title      = {{TimeCAP}: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents},
  url        = {http://arxiv.org/abs/2502.11418},
  doi        = {10.48550/arXiv.2502.11418},
  shorttitle = {{TimeCAP}},
  abstract   = {Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce {TimeCAP}, a time-series processing framework that creatively employs Large Language Models ({LLMs}) as contextualizers of time series data, extending their typical usage as predictors. {TimeCAP} incorporates two independent {LLM} agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, {TimeCAP} employs a multi-modal encoder that synergizes with the {LLM} agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that {TimeCAP} outperforms state-of-the-art methods for time series event prediction, including those utilizing {LLMs} as predictors, achieving an average improvement of 28.75\% in F1 score.},
  number     = {{arXiv}:2502.11418},
  publisher  = {{arXiv}},
  author     = {Lee, Geon and Yu, Wenchao and Shin, Kijung and Cheng, Wei and Chen, Haifeng},
  urldate    = {2025-03-18},
  date       = {2025-03-10},
  eprinttype = {arxiv},
  eprint     = {2502.11418 [cs]},
  note       = {{TLDR}: Experimental results on real-world datasets demonstrate that {TimeCAP} outperforms state-of-the-art methods for time series event prediction, including those utilizing {LLMs} as predictors, achieving an average improvement of 28.75\% in F1 score.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\7PBFKCAR\\Lee 等 - 2025 - TimeCAP Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Mode.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\97YAP2BY\\2502.html:text/html}
}

@misc{lei_meta-task_2024,
  title      = {Meta-Task Prompting Elicits Embedding from Large Language Models},
  url        = {http://arxiv.org/abs/2402.18458},
  doi        = {10.48550/arXiv.2402.18458},
  abstract   = {In this work, we introduce a new unsupervised embedding method, Meta-Task Prompting with Explicit One-Word Limitation ({MetaEOL}), for generating high-quality sentence embeddings from Large Language Models ({LLMs}) without the need for model fine-tuning or task-specific engineering. Leveraging meta-task prompting, {MetaEOL} guides {LLMs} to produce embeddings through a series of carefully designed prompts that address multiple representational aspects. Our comprehensive experiments demonstrate that embeddings averaged from various meta-tasks yield competitive performance on Semantic Textual Similarity ({STS}) benchmarks and excel in downstream tasks, surpassing contrastive-trained models. Our findings suggest a new scaling law for embedding generation, offering a versatile, resource-efficient approach for embedding extraction across diverse sentence-centric scenarios.},
  number     = {{arXiv}:2402.18458},
  publisher  = {{arXiv}},
  author     = {Lei, Yibin and Wu, Di and Zhou, Tianyi and Shen, Tao and Cao, Yu and Tao, Chongyang and Yates, Andrew},
  urldate    = {2024-03-18},
  date       = {2024-02-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.18458 [cs]},
  keywords   = {/reading, Computer Science - Computation and Language},
  file       = {2024_Meta-Task Prompting Elicits Embedding from Large Language Models_Lei et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\H5CSRQZQ\\2024_Meta-Task Prompting Elicits Embedding from Large Language Models_Lei et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\6Q4NT7KG\\2402.html:text/html}
}

@misc{li_hunyuan-dit_2024,
  title      = {Hunyuan-{DiT}: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding},
  url        = {http://arxiv.org/abs/2405.08748},
  doi        = {10.48550/arXiv.2405.08748},
  shorttitle = {Hunyuan-{DiT}},
  abstract   = {We present Hunyuan-{DiT}, a text-to-image diffusion transformer with fine-grained understanding of both English and Chinese. To construct Hunyuan-{DiT}, we carefully design the transformer structure, text encoder, and positional encoding. We also build from scratch a whole data pipeline to update and evaluate data for iterative model optimization. For fine-grained language understanding, we train a Multimodal Large Language Model to refine the captions of the images. Finally, Hunyuan-{DiT} can perform multi-turn multimodal dialogue with users, generating and refining images according to the context. Through our holistic human evaluation protocol with more than 50 professional human evaluators, Hunyuan-{DiT} sets a new state-of-the-art in Chinese-to-image generation compared with other open-source models. Code and pretrained models are publicly available at github.com/Tencent/{HunyuanDiT}},
  number     = {{arXiv}:2405.08748},
  publisher  = {{arXiv}},
  author     = {Li, Zhimin and Zhang, Jianwei and Lin, Qin and Xiong, Jiangfeng and Long, Yanxin and Deng, Xinchi and Zhang, Yingfang and Liu, Xingchao and Huang, Minbin and Xiao, Zedong and Chen, Dayou and He, Jiajun and Li, Jiahao and Li, Wenyue and Zhang, Chen and Quan, Rongwei and Lu, Jianxiang and Huang, Jiabin and Yuan, Xiaoyan and Zheng, Xiaoxiao and Li, Yixuan and Zhang, Jihong and Zhang, Chao and Chen, Meng and Liu, Jie and Fang, Zheng and Wang, Weiyan and Xue, Jinbao and Tao, Yangyu and Zhu, Jianchen and Liu, Kai and Lin, Sihuan and Sun, Yifu and Li, Yun and Wang, Dongdong and Chen, Mingtao and Hu, Zhichao and Xiao, Xiao and Chen, Yan and Liu, Yuhong and Liu, Wei and Wang, Di and Yang, Yong and Jiang, Jie and Lu, Qinglin},
  urldate    = {2024-11-18},
  date       = {2024-05-14},
  eprinttype = {arxiv},
  eprint     = {2405.08748},
  keywords   = {Computer Science - Computer Vision and Pattern Recognition, ⭐⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\FH5VCTY6\\Li 等 - 2024 - Hunyuan-DiT A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understandi.pdf:application/pdf}
}

@misc{li_language_2025,
  title      = {Language in the Flow of Time: Time-Series-Paired Texts Weaved into a Unified Temporal Narrative},
  url        = {http://arxiv.org/abs/2502.08942},
  doi        = {10.48550/arXiv.2502.08942},
  shorttitle = {Language in the Flow of Time},
  abstract   = {While many advances in time series models focus exclusively on numerical data, research on multimodal time series, particularly those involving contextual textual information commonly encountered in real-world scenarios, remains in its infancy. Consequently, effectively integrating the text modality remains challenging. In this work, we highlight an intuitive yet significant observation that has been overlooked by existing works: time-series-paired texts exhibit periodic properties that closely mirror those of the original time series. Building on this insight, we propose a novel framework, Texts as Time Series ({TaTS}), which considers the time-series-paired texts to be auxiliary variables of the time series. {TaTS} can be plugged into any existing numerical-only time series models and enable them to handle time series data with paired texts effectively. Through extensive experiments on both multimodal time series forecasting and imputation tasks across benchmark datasets with various existing time series models, we demonstrate that {TaTS} can enhance predictive performance and achieve outperformance without modifying model architectures.},
  number     = {{arXiv}:2502.08942},
  publisher  = {{arXiv}},
  author     = {Li, Zihao and Lin, Xiao and Liu, Zhining and Zou, Jiaru and Wu, Ziwei and Zheng, Lecheng and Fu, Dongqi and Zhu, Yada and Hamann, Hendrik and Tong, Hanghang and He, Jingrui},
  urldate    = {2025-02-17},
  date       = {2025-02-13},
  eprinttype = {arxiv},
  eprint     = {2502.08942 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\6747IWSN\\Li 等 - 2025 - Language in the Flow of Time Time-Series-Paired Texts Weaved into a Unified Temporal Narrative.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\6CZM3X9A\\2502.html:text/html}
}

@article{li_transferable_2024,
  title        = {Transferable Time-Series Forecasting Under Causal Conditional Shift},
  volume       = {46},
  issn         = {1939-3539},
  url          = {https://ieeexplore.ieee.org/document/10214679},
  doi          = {10.1109/TPAMI.2023.3304354},
  abstract     = {This paper focuses on the problem of semi-supervised domain adaptation for time-series forecasting, which is underexplored in literature, despite being often encountered in practice. Existing methods on time-series domain adaptation mainly follow the paradigm designed for static data, which cannot handle domain-specific complex conditional dependencies raised by data offset, time lags, and variant data distributions. In order to address these challenges, we analyze variational conditional dependencies in time-series data and find that the causal structures are usually stable among domains, and further raise the causal conditional shift assumption. Enlightened by this assumption, we consider the causal generation process for time-series data and propose an end-to-end model for the semi-supervised domain adaptation problem on time-series forecasting. Our method can not only discover the Granger-Causal structures among cross-domain data but also address the cross-domain time-series forecasting problem with accurate and interpretable predicted results. We further theoretically analyze the superiority of the proposed method, where the generalization error on the target domain is bounded by the empirical risks and by the discrepancy between the causal structures from different domains. Experimental results on both synthetic and real data demonstrate the effectiveness of our method for the semi-supervised domain adaptation method on time-series forecasting.},
  pages        = {1932--1949},
  number       = {4},
  journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  author       = {Li, Zijian and Cai, Ruichu and Fu, Tom Z. J. and Hao, Zhifeng and Zhang, Kun},
  urldate      = {2024-05-23},
  date         = {2024-04},
  langid       = {english},
  note         = {Conference Name: {IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  keywords     = {/reading, Forecasting, Predictive models, Data models, Adaptation models, Data mining, Granger Causality, Mathematical models, semi-supervised domain adaptation, Time series, Time series analysis, transfer learning},
  file         = {2024_Transferable Time-Series Forecasting Under Causal Conditional Shift_Li et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\BWLRFQ2Z\\2024_Transferable Time-Series Forecasting Under Causal Conditional Shift_Li et al.pdf:application/pdf;2024_Transferable Time-Series Forecasting Under Causal Conditional Shift_Li et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9D6U9LW6\\2024_Transferable Time-Series Forecasting Under Causal Conditional Shift_Li et al.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\yanha\\Zotero\\storage\\IZ9C26XQ\\10214679.html:text/html}
}

@misc{li_urbangpt_2024,
  title      = {{UrbanGPT}: Spatio-Temporal Large Language Models},
  url        = {http://arxiv.org/abs/2403.00813},
  doi        = {10.48550/arXiv.2403.00813},
  shorttitle = {{UrbanGPT}},
  abstract   = {Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models ({LLMs}), our objective is to create a spatio-temporal {LLM} that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the {UrbanGPT}, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables {LLMs} to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our {UrbanGPT}, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce.},
  number     = {{arXiv}:2403.00813},
  publisher  = {{arXiv}},
  author     = {Li, Zhonghang and Xia, Lianghao and Tang, Jiabin and Xu, Yong and Shi, Lei and Xia, Long and Yin, Dawei and Huang, Chao},
  urldate    = {2024-03-21},
  date       = {2024-02-25},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.00813 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computers and Society},
  file       = {2024_UrbanGPT_Li et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9WFDYU63\\2024_UrbanGPT_Li et al.pdf:application/pdf;审稿-TRC-23-01498_R1_reviewer.pdf:C\:\\Users\\yanha\\Zotero\\storage\\L4NMPTBH\\审稿-TRC-23-01498_R1_reviewer.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\58B4QYAQ\\2403.html:text/html}
}

@misc{liang_foundation_2024,
  title      = {Foundation Models for Time Series Analysis: A Tutorial and Survey},
  url        = {http://arxiv.org/abs/2403.14735},
  doi        = {10.48550/arXiv.2403.14735},
  shorttitle = {Foundation Models for Time Series Analysis},
  abstract   = {Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models ({FMs}) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned {FMs} to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of {FMs} for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of {FMs} in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how {FMs} benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series {FMs}, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in {FMs} pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.},
  number     = {{arXiv}:2403.14735},
  publisher  = {{arXiv}},
  author     = {Liang, Yuxuan and Wen, Haomin and Nie, Yuqi and Jiang, Yushan and Jin, Ming and Song, Dongjin and Pan, Shirui and Wen, Qingsong},
  urldate    = {2024-05-07},
  date       = {2024-04-02},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.14735 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_Foundation Models for Time Series Analysis_Liang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9QA24KDQ\\2024_Foundation Models for Time Series Analysis_Liang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4489FAFB\\2403.html:text/html}
}

@online{lin_cyclenet_2024,
  title      = {{CycleNet}: Enhancing Time Series Forecasting through Modeling Periodic Patterns},
  url        = {https://arxiv.org/abs/2409.18479v1},
  shorttitle = {{CycleNet}},
  abstract   = {The stable periodic patterns present in time series data serve as the foundation for conducting long-horizon forecasts. In this paper, we pioneer the exploration of explicitly modeling this periodicity to enhance the performance of models in long-term time series forecasting ({LTSF}) tasks. Specifically, we introduce the Residual Cycle Forecasting ({RCF}) technique, which utilizes learnable recurrent cycles to model the inherent periodic patterns within sequences, and then performs predictions on the residual components of the modeled cycles. Combining {RCF} with a Linear layer or a shallow {MLP} forms the simple yet powerful method proposed in this paper, called {CycleNet}. {CycleNet} achieves state-of-the-art prediction accuracy in multiple domains including electricity, weather, and energy, while offering significant efficiency advantages by reducing over 90\% of the required parameter quantity. Furthermore, as a novel plug-and-play technique, the {RCF} can also significantly improve the prediction accuracy of existing models, including {PatchTST} and {iTransformer}. The source code is available at: https://github.com/{ACAT}-{SCUT}/{CycleNet}.},
  titleaddon = {{arXiv}.org},
  author     = {Lin, Shengsheng and Lin, Weiwei and Hu, Xinyi and Wu, Wentai and Mo, Ruichao and Zhong, Haocheng},
  urldate    = {2024-10-09},
  date       = {2024-09-27},
  langid     = {english},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\VUZJPLJQ\\Lin 等 - 2024 - CycleNet Enhancing Time Series Forecasting through Modeling Periodic Patterns.pdf:application/pdf}
}

@misc{lin_decoding_2024,
  title      = {Decoding Time Series with {LLMs}: A Multi-Agent Framework for Cross-Domain Annotation},
  url        = {http://arxiv.org/abs/2410.17462},
  doi        = {10.48550/arXiv.2410.17462},
  shorttitle = {Decoding Time Series with {LLMs}},
  abstract   = {Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose {TESSA}, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. {TESSA} introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that {TESSA} effectively generates high-quality annotations, outperforming existing methods.},
  number     = {{arXiv}:2410.17462},
  publisher  = {{arXiv}},
  author     = {Lin, Minhua and Chen, Zhengzhang and Liu, Yanchi and Zhao, Xujiang and Wu, Zongyu and Wang, Junxiang and Zhang, Xiang and Wang, Suhang and Chen, Haifeng},
  urldate    = {2025-01-08},
  date       = {2024-10-22},
  eprinttype = {arxiv},
  eprint     = {2410.17462 [cs]},
  note       = {{TLDR}: {TESSA}, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data, is proposed and demonstrates that {TESSA} effectively generates high-quality annotations, outperforming existing methods.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\K4BVEG7W\\Lin 等 - 2024 - Decoding Time Series with LLMs A Multi-Agent Framework for Cross-Domain Annotation.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\347AF6FL\\2410.html:text/html}
}

@misc{lin_decoding_2024-1,
  title      = {Decoding Time Series with {LLMs}: A Multi-Agent Framework for Cross-Domain Annotation},
  url        = {http://arxiv.org/abs/2410.17462},
  doi        = {10.48550/arXiv.2410.17462},
  shorttitle = {Decoding Time Series with {LLMs}},
  abstract   = {Time series data is ubiquitous across various domains, including manufacturing, finance, and healthcare. High-quality annotations are essential for effectively understanding time series and facilitating downstream tasks; however, obtaining such annotations is challenging, particularly in mission-critical domains. In this paper, we propose {TESSA}, a multi-agent system designed to automatically generate both general and domain-specific annotations for time series data. {TESSA} introduces two agents: a general annotation agent and a domain-specific annotation agent. The general agent captures common patterns and knowledge across multiple source domains, leveraging both time-series-wise and text-wise features to generate general annotations. Meanwhile, the domain-specific agent utilizes limited annotations from the target domain to learn domain-specific terminology and generate targeted annotations. Extensive experiments on multiple synthetic and real-world datasets demonstrate that {TESSA} effectively generates high-quality annotations, outperforming existing methods.},
  number     = {{arXiv}:2410.17462},
  publisher  = {{arXiv}},
  author     = {Lin, Minhua and Chen, Zhengzhang and Liu, Yanchi and Zhao, Xujiang and Wu, Zongyu and Wang, Junxiang and Zhang, Xiang and Wang, Suhang and Chen, Haifeng},
  urldate    = {2025-01-08},
  date       = {2024-10-22},
  eprinttype = {arxiv},
  eprint     = {2410.17462 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\TK32NGRS\\Lin 等 - 2024 - Decoding Time Series with LLMs A Multi-Agent Framework for Cross-Domain Annotation.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4Y4PVHDV\\2410.html:text/html}
}

@misc{lin_specstg_2024,
  title      = {{SpecSTG}: A Fast Spectral Diffusion Framework for Probabilistic Spatio-Temporal Traffic Forecasting},
  url        = {http://arxiv.org/abs/2401.08119},
  doi        = {10.48550/arXiv.2401.08119},
  shorttitle = {{SpecSTG}},
  abstract   = {Traffic forecasting, a crucial application of spatio-temporal graph ({STG}) learning, has traditionally relied on deterministic models for accurate point estimations. Yet, these models fall short of identifying latent risks of unexpected volatility in future observations. To address this gap, probabilistic methods, especially variants of diffusion models, have emerged as uncertainty-aware solutions. However, existing diffusion methods typically focus on generating separate future time series for individual sensors in the traffic network, resulting in insufficient involvement of spatial network characteristics in the probabilistic learning process. To better leverage spatial dependencies and systematic patterns inherent in traffic data, we propose {SpecSTG}, a novel spectral diffusion framework. Our method generates the Fourier representation of future time series, transforming the learning process into the spectral domain enriched with spatial information. Additionally, our approach incorporates a fast spectral graph convolution designed for Fourier input, alleviating the computational burden associated with existing models. Numerical experiments show that {SpecSTG} achieves outstanding performance with traffic flow and traffic speed datasets compared to state-of-the-art baselines. The source code for {SpecSTG} is available at https://anonymous.4open.science/r/{SpecSTG}.},
  number     = {{arXiv}:2401.08119},
  publisher  = {{arXiv}},
  author     = {Lin, Lequan and Shi, Dai and Han, Andi and Gao, Junbin},
  urldate    = {2024-05-09},
  date       = {2024-01-23},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.08119 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_SpecSTG_Lin et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\HR3NJP6Y\\2024_SpecSTG_Lin et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JTTIIMLJ\\2401.html:text/html}
}

@misc{liu_autotimes_2024,
  title      = {{AutoTimes}: Autoregressive Time Series Forecasters via Large Language Models},
  url        = {http://arxiv.org/abs/2402.02370},
  shorttitle = {{AutoTimes}},
  abstract   = {Foundation models of time series have not been fully developed due to the limited availability of large-scale time series and the underexploration of scalable pre-training. Based on the similar sequential structure of time series and natural language, increasing research demonstrates the feasibility of leveraging large language models ({LLM}) for time series. Nevertheless, prior methods may overlook the consistency in aligning time series and natural language, resulting in insufficient utilization of the {LLM} potentials. To fully exploit the general-purpose token transitions learned from language modeling, we propose {AutoTimes} to repurpose {LLMs} as Autoregressive Time series forecasters, which is consistent with the acquisition and utilization of {LLMs} without updating the parameters. The consequent forecasters can handle flexible series lengths and achieve competitive performance as prevalent models. Further, we present token-wise prompting that utilizes corresponding timestamps to make our method applicable to multimodal scenarios. Analysis demonstrates our forecasters inherit zero-shot and in-context learning capabilities of {LLMs}. Empirically, {AutoTimes} exhibits notable method generality and achieves enhanced performance by basing on larger {LLMs}, additional texts, or time series as instructions.},
  number     = {{arXiv}:2402.02370},
  publisher  = {{arXiv}},
  author     = {Liu, Yong and Qin, Guo and Huang, Xiangdong and Wang, Jianmin and Long, Mingsheng},
  urldate    = {2024-03-25},
  date       = {2024-02-04},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.02370 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\44R784VQ\\2402.html:text/html;Liu et al_2024_AutoTimes.pdf:C\:\\Users\\yanha\\Zotero\\storage\\WE93A9YI\\Liu et al_2024_AutoTimes.pdf:application/pdf}
}

@misc{liu_dgcformer_2024,
  title      = {{DGCformer}: Deep Graph Clustering Transformer for Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2405.08440},
  doi        = {10.48550/arXiv.2405.08440},
  shorttitle = {{DGCformer}},
  abstract   = {Multivariate time series forecasting tasks are usually conducted in a channel-dependent ({CD}) way since it can incorporate more variable-relevant information. However, it may also involve a lot of irrelevant variables, and this even leads to worse performance than the channel-independent ({CI}) strategy. This paper combines the strengths of both strategies and proposes the Deep Graph Clustering Transformer ({DGCformer}) for multivariate time series forecasting. Specifically, it first groups these relevant variables by a graph convolutional network integrated with an autoencoder, and a former-latter masked self-attention mechanism is then considered with the {CD} strategy being applied to each group of variables while the {CI} one for different groups. Extensive experimental results on eight datasets demonstrate the superiority of our method against state-of-the-art models, and our code will be publicly available upon acceptance.},
  number     = {{arXiv}:2405.08440},
  publisher  = {{arXiv}},
  author     = {Liu, Qinshuo and Fang, Yanwen and Jiang, Pengtao and Li, Guodong},
  urldate    = {2024-05-23},
  date       = {2024-05-14},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2405.08440 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_DGCformer_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\F92C7WSA\\2024_DGCformer_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZRMWJYY9\\2405.html:text/html}
}

@misc{liu_how_2024,
  title      = {How Can Large Language Models Understand Spatial-Temporal Data?},
  url        = {http://arxiv.org/abs/2401.14192},
  doi        = {10.48550/arXiv.2401.14192},
  abstract   = {While Large Language Models ({LLMs}) dominate tasks like natural language processing and computer vision, harnessing their power for spatial-temporal forecasting remains challenging. The disparity between sequential text and complex spatial-temporal data hinders this application. To address this issue, this paper introduces {STG}-{LLM}, an innovative approach empowering {LLMs} for spatial-temporal forecasting. We tackle the data mismatch by proposing: 1) {STG}-Tokenizer: This spatial-temporal graph tokenizer transforms intricate graph data into concise tokens capturing both spatial and temporal relationships; 2) {STG}-Adapter: This minimalistic adapter, consisting of linear encoding and decoding layers, bridges the gap between tokenized data and {LLM} comprehension. By fine-tuning only a small set of parameters, it can effectively grasp the semantics of tokens generated by {STG}-Tokenizer, while preserving the original natural language understanding capabilities of {LLMs}. Extensive experiments on diverse spatial-temporal benchmark datasets show that {STG}-{LLM} successfully unlocks {LLM} potential for spatial-temporal forecasting. Remarkably, our approach achieves competitive performance on par with dedicated {SOTA} methods.},
  number     = {{arXiv}:2401.14192},
  publisher  = {{arXiv}},
  author     = {Liu, Lei and Yu, Shuo and Wang, Runze and Ma, Zhenxun and Shen, Yanming},
  urldate    = {2024-03-18},
  date       = {2024-01-25},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.14192 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_How Can Large Language Models Understand Spatial-Temporal Data_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\QXR84G2Q\\2024_How Can Large Language Models Understand Spatial-Temporal Data_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\IT93CUT8\\2401.html:text/html}
}

@misc{liu_itransformer_2023,
  title      = {{iTransformer}: Inverted Transformers Are Effective for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2310.06625},
  doi        = {10.48550/arXiv.2310.06625},
  shorttitle = {{iTransformer}},
  abstract   = {The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformer is challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the unified embedding for each temporal token fuses multiple variates with potentially unaligned timestamps and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any adaptation on the basic components. We propose {iTransformer} that simply inverts the duties of the attention mechanism and the feed-forward network. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The {iTransformer} model achieves consistent state-of-the-art on several real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting.},
  number     = {{arXiv}:2310.06625},
  publisher  = {{arXiv}},
  author     = {Liu, Yong and Hu, Tengge and Zhang, Haoran and Wu, Haixu and Wang, Shiyu and Ma, Lintao and Long, Mingsheng},
  urldate    = {2023-10-24},
  date       = {2023-10-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.06625 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, /unread},
  file       = {2023_iTransformer_Liu et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_iTransformer_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4GFFRTB4\\2310.html:text/html}
}

@misc{liu_largest_2023,
  title      = {{LargeST}: A Benchmark Dataset for Large-Scale Traffic Forecasting},
  url        = {http://arxiv.org/abs/2306.08259},
  shorttitle = {{LargeST}},
  abstract   = {Road traffic forecasting plays a critical role in smart city initiatives and has experienced significant advancements thanks to the power of deep learning in capturing non-linear patterns of traffic data. However, the promising results achieved on current public datasets may not be applicable to practical scenarios due to limitations within these datasets. First, the limited sizes of them may not reflect the real-world scale of traffic networks. Second, the temporal coverage of these datasets is typically short, posing hurdles in studying long-term patterns and acquiring sufficient samples for training deep models. Third, these datasets often lack adequate metadata for sensors, which compromises the reliability and interpretability of the data. To mitigate these limitations, we introduce the {LargeST} benchmark dataset. It encompasses a total number of 8,600 sensors in California with a 5-year time coverage and includes comprehensive metadata. Using {LargeST}, we perform in-depth data analysis to extract data insights, benchmark well-known baselines in terms of their performance and efficiency, and identify challenges as well as opportunities for future research. We release the datasets and baseline implementations at: https://github.com/liuxu77/{LargeST}.},
  number     = {{arXiv}:2306.08259},
  publisher  = {{arXiv}},
  author     = {Liu, Xu and Xia, Yutong and Liang, Yuxuan and Hu, Junfeng and Wang, Yiwei and Bai, Lei and Huang, Chao and Liu, Zhenguang and Hooi, Bryan and Zimmermann, Roger},
  urldate    = {2023-10-31},
  date       = {2023-10-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2306.08259 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, /unread},
  file       = {2023_LargeST_Liu et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_LargeST_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\M8FPPSXY\\2306.html:text/html}
}

@misc{liu_llms_2024,
  title      = {{LLMs} learn governing principles of dynamical systems, revealing an in-context neural scaling law},
  url        = {http://arxiv.org/abs/2402.00795},
  doi        = {10.48550/arXiv.2402.00795},
  abstract   = {Pretrained large language models ({LLMs}) are surprisingly effective at performing zero-shot tasks, including time-series forecasting. However, understanding the mechanisms behind such capabilities remains highly challenging due to the complexity of the models. In this paper, we study {LLMs}' ability to extrapolate the behavior of dynamical systems whose evolution is governed by principles of physical interest. Our results show that {LLaMA} 2, a language model trained primarily on texts, achieves accurate predictions of dynamical system time series without fine-tuning or prompt engineering. Moreover, the accuracy of the learned physical rules increases with the length of the input context window, revealing an in-context version of neural scaling law. Along the way, we present a flexible and efficient algorithm for extracting probability density functions of multi-digit numbers directly from {LLMs}.},
  number     = {{arXiv}:2402.00795},
  publisher  = {{arXiv}},
  author     = {Liu, Toni J. B. and Boullé, Nicolas and Sarfati, Raphaël and Earls, Christopher J.},
  urldate    = {2024-04-02},
  date       = {2024-02-01},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.00795 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_LLMs learn governing principles of dynamical systems, revealing an in-context_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\6APNA6NM\\2024_LLMs learn governing principles of dynamical systems, revealing an in-context_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\MW9RPYWM\\2402.html:text/html}
}

@misc{liu_lstprompt_2024,
  title      = {{LSTPrompt}: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting},
  url        = {http://arxiv.org/abs/2402.16132},
  doi        = {10.48550/arXiv.2402.16132},
  shorttitle = {{LSTPrompt}},
  abstract   = {Time-series forecasting ({TSF}) finds broad applications in real-world scenarios. Prompting off-the-shelf Large Language Models ({LLMs}) demonstrates strong zero-shot {TSF} capabilities while preserving computational efficiency. However, existing prompting methods oversimplify {TSF} as language next-token predictions, overlooking its dynamic nature and lack of integration with state-of-the-art prompt strategies such as Chain-of-Thought. Thus, we propose {LSTPrompt}, a novel approach for prompting {LLMs} in zero-shot {TSF} tasks. {LSTPrompt} decomposes {TSF} into short-term and long-term forecasting sub-tasks, tailoring prompts to each. {LSTPrompt} guides {LLMs} to regularly reassess forecasting mechanisms to enhance adaptability. Extensive evaluations demonstrate consistently better performance of {LSTPrompt} than existing prompting methods, and competitive results compared to foundation {TSF} models.},
  number     = {{arXiv}:2402.16132},
  publisher  = {{arXiv}},
  author     = {Liu, Haoxin and Zhao, Zhiyuan and Wang, Jindong and Kamarthi, Harshavardhan and Prakash, B. Aditya},
  urldate    = {2024-03-19},
  date       = {2024-02-25},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.16132 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {2024_LSTPrompt_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\69UDDBQ2\\2024_LSTPrompt_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\PPXDAUDP\\2402.html:text/html}
}

@misc{liu_moirai-moe_2024,
  title      = {Moirai-{MoE}: Empowering Time Series Foundation Models with Sparse Mixture of Experts},
  url        = {http://arxiv.org/abs/2410.10469},
  doi        = {10.48550/arXiv.2410.10469},
  shorttitle = {Moirai-{MoE}},
  abstract   = {Time series foundation models have demonstrated impressive performance as zero-shot forecasters. However, achieving effectively unified training on time series remains an open challenge. Existing approaches introduce some level of model specialization to account for the highly heterogeneous nature of time series data. For instance, Moirai pursues unified training by employing multiple input/output projection layers, each tailored to handle time series at a specific frequency. Similarly, {TimesFM} maintains a frequency embedding dictionary for this purpose. We identify two major drawbacks to this human-imposed frequency-level model specialization: (1) Frequency is not a reliable indicator of the underlying patterns in time series. For example, time series with different frequencies can display similar patterns, while those with the same frequency may exhibit varied patterns. (2) Non-stationarity is an inherent property of real-world time series, leading to varied distributions even within a short context window of a single time series. Frequency-level specialization is too coarse-grained to capture this level of diversity. To address these limitations, this paper introduces Moirai-{MoE}, using a single input/output projection layer while delegating the modeling of diverse time series patterns to the sparse mixture of experts ({MoE}) within Transformers. With these designs, Moirai-{MoE} reduces reliance on human-defined heuristics and enables automatic token-level specialization. Extensive experiments on 39 datasets demonstrate the superiority of Moirai-{MoE} over existing foundation models in both in-distribution and zero-shot scenarios. Furthermore, this study conducts comprehensive model analyses to explore the inner workings of time series {MoE} foundation models and provides valuable insights for future research.},
  number     = {{arXiv}:2410.10469},
  publisher  = {{arXiv}},
  author     = {Liu, Xu and Liu, Juncheng and Woo, Gerald and Aksu, Taha and Liang, Yuxuan and Zimmermann, Roger and Liu, Chenghao and Savarese, Silvio and Xiong, Caiming and Sahoo, Doyen},
  urldate    = {2024-11-12},
  date       = {2024-10-14},
  eprinttype = {arxiv},
  eprint     = {2410.10469},
  keywords   = {Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\TIXXA84G\\Liu 等 - 2024 - Moirai-MoE Empowering Time Series Foundation Models with Sparse Mixture of Experts.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\Y6V22IDH\\2410.html:text/html}
}

@misc{liu_picture_2024,
  title      = {A Picture is Worth A Thousand Numbers: Enabling {LLMs} Reason about Time Series via Visualization},
  url        = {http://arxiv.org/abs/2411.06018},
  doi        = {10.48550/arXiv.2411.06018},
  shorttitle = {A Picture is Worth A Thousand Numbers},
  abstract   = {Large language models ({LLMs}), with demonstrated reasoning abilities across multiple domains, are largely underexplored for time-series reasoning ({TsR}), which is ubiquitous in the real world. In this work, we propose {TimerBed}, the first comprehensive testbed for evaluating {LLMs}' {TsR} performance. Specifically, {TimerBed} includes stratified reasoning patterns with real-world tasks, comprehensive combinations of {LLMs} and reasoning strategies, and various supervised models as comparison anchors. We perform extensive experiments with {TimerBed}, test multiple current beliefs, and verify the initial failures of {LLMs} in {TsR}, evidenced by the ineffectiveness of zero shot ({ZST}) and performance degradation of few shot in-context learning ({ICL}). Further, we identify one possible root cause: the numerical modeling of data. To address this, we propose a prompt-based solution {VL}-Time, using visualization-modeled data and language-guided reasoning. Experimental results demonstrate that Vl-Time enables multimodal {LLMs} to be non-trivial {ZST} and powerful {ICL} reasoners for time series, achieving about 140\% average performance improvement and 99\% average token costs reduction.},
  number     = {{arXiv}:2411.06018},
  publisher  = {{arXiv}},
  author     = {Liu, Haoxin and Liu, Chenghao and Prakash, B. Aditya},
  urldate    = {2025-03-30},
  date       = {2024-11-09},
  eprinttype = {arxiv},
  eprint     = {2411.06018 [cs]},
  note       = {{TLDR}: A prompt-based solution {VL}-Time is proposed, using visualization-modeled data and language-guided reasoning that enables multimodal {LLMs} to be non-trivial {ZST} and powerful {ICL} reasoners for time series, achieving about 140\% average performance improvement and 99\% average token costs reduction.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\NWD4ZMM7\\Liu 等 - 2024 - A Picture is Worth A Thousand Numbers Enabling LLMs Reason about Time Series via Visualization.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UMKXTDR9\\2411.html:text/html}
}

@misc{liu_retrieval-augmented_2024,
  title      = {Retrieval-Augmented Diffusion Models for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2410.18712},
  doi        = {10.48550/arXiv.2410.18712},
  abstract   = {While time series diffusion models have received considerable focus from many recent works, the performance of existing models remains highly unstable. Factors limiting time series diffusion models include insufficient time series datasets and the absence of guidance. To address these limitations, we propose a Retrieval- Augmented Time series Diffusion model ({RATD}). The framework of {RATD} consists of two parts: an embedding-based retrieval process and a reference-guided diffusion model. In the first part, {RATD} retrieves the time series that are most relevant to historical time series from the database as references. The references are utilized to guide the denoising process in the second part. Our approach allows leveraging meaningful samples within the database to aid in sampling, thus maximizing the utilization of datasets. Meanwhile, this reference-guided mechanism also compensates for the deficiencies of existing time series diffusion models in terms of guidance. Experiments and visualizations on multiple datasets demonstrate the effectiveness of our approach, particularly in complicated prediction tasks.},
  number     = {{arXiv}:2410.18712},
  publisher  = {{arXiv}},
  author     = {Liu, Jingwei and Yang, Ling and Li, Hongyan and Hong, Shenda},
  urldate    = {2024-11-12},
  date       = {2024-10-24},
  eprinttype = {arxiv},
  eprint     = {2410.18712},
  keywords   = {Computer Science - Machine Learning, ⭐⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\5UGW4JQ4\\Liu 等 - 2024 - Retrieval-Augmented Diffusion Models for Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\634HTTEP\\2410.html:text/html}
}

@misc{liu_spatial-temporal_2024,
  title      = {Spatial-Temporal Large Language Model for Traffic Prediction},
  url        = {http://arxiv.org/abs/2401.10134},
  doi        = {10.48550/arXiv.2401.10134},
  abstract   = {Traffic prediction, a critical component for intelligent transportation systems, endeavors to foresee future traffic at specific locations using historical data. Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not seen improvements accordingly. Recently, Large Language Models ({LLMs}) have shown outstanding capabilities in time series analysis. Differing from existing models, {LLMs} progress mainly through parameter expansion and extensive pre-training while maintaining their fundamental structures. In this paper, we propose a Spatial-Temporal Large Language Model ({ST}-{LLM}) for traffic prediction. Specifically, {ST}-{LLM} redefines the timesteps at each location as tokens and incorporates a spatial-temporal embedding module to learn the spatial location and global temporal representations of tokens. Then these representations are fused to provide each token with unified spatial and temporal information. Furthermore, we propose a novel partially frozen attention strategy of the {LLM}, which is designed to capture spatial-temporal dependencies for traffic prediction. Comprehensive experiments on real traffic datasets offer evidence that {ST}-{LLM} outperforms state-of-the-art models. Notably, the {ST}-{LLM} also exhibits robust performance in both few-shot and zero-shot prediction scenarios.},
  number     = {{arXiv}:2401.10134},
  publisher  = {{arXiv}},
  author     = {Liu, Chenxi and Yang, Sun and Xu, Qianxiong and Li, Zhishuai and Long, Cheng and Li, Ziyue and Zhao, Rui},
  urldate    = {2024-01-22},
  date       = {2024-01-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.10134 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {arXiv Fulltext PDF:C\:\\Users\\yanha\\Zotero\\storage\\KDX4Z5DA\\Liu 等 - 2024 - Spatial-Temporal Large Language Model for Traffic .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\PL5VMQJR\\2401.html:text/html}
}

@misc{liu_taming_2024,
  title      = {Taming Pre-trained {LLMs} for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation},
  url        = {http://arxiv.org/abs/2403.07300},
  doi        = {10.48550/arXiv.2403.07300},
  abstract   = {Multivariate time series forecasting has recently gained great success with the rapid growth of deep learning models. However, existing approaches usually train models from scratch using limited temporal data, preventing their generalization. Recently, with the surge of the Large Language Models ({LLMs}), several works have attempted to introduce {LLMs} into time series forecasting. Despite promising results, these methods directly take time series as the input to {LLMs}, ignoring the inherent modality gap between temporal and text data. In this work, we propose a novel Large Language Models and time series alignment framework, dubbed {LLaTA}, to fully unleash the potentials of {LLMs} in the time series forecasting challenge. Based on cross-modal knowledge distillation, the proposed method exploits both input-agnostic static knowledge and input-dependent dynamic knowledge in pre-trained {LLMs}. In this way, it empowers the forecasting model with favorable performance as well as strong generalization abilities. Extensive experiments demonstrate the proposed method establishes a new state of the art for both long- and short-term forecasting. Code is available at {\textbackslash}url\{https://github.com/Hank0626/{LLaTA}\}.},
  number     = {{arXiv}:2403.07300},
  publisher  = {{arXiv}},
  author     = {Liu, Peiyuan and Guo, Hang and Dai, Tao and Li, Naiqi and Bao, Jigang and Ren, Xudong and Jiang, Yong and Xia, Shu-Tao},
  urldate    = {2024-03-19},
  date       = {2024-03-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.07300 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CKMD9N4M\\2024_Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\H6SWI6BP\\2403.html:text/html}
}

@misc{liu_time-mmd_2024,
  title      = {Time-{MMD}: A New Multi-Domain Multimodal Dataset for Time Series Analysis},
  url        = {http://arxiv.org/abs/2406.08627},
  doi        = {10.48550/arXiv.2406.08627},
  shorttitle = {Time-{MMD}},
  abstract   = {Time series data are ubiquitous across a wide range of real-world domains. While real-world time series analysis ({TSA}) requires human experts to integrate numerical series data with multimodal domain-specific knowledge, most existing {TSA} models rely solely on numerical data, overlooking the significance of information beyond numerical series. This oversight is due to the untapped potential of textual series data and the absence of a comprehensive, high-quality multimodal dataset. To overcome this obstacle, we introduce Time-{MMD}, the first multi-domain, multimodal time series dataset covering 9 primary data domains. Time-{MMD} ensures fine-grained modality alignment, eliminates data contamination, and provides high usability. Additionally, we develop {MM}-{TSFlib}, the first multimodal time-series forecasting ({TSF}) library, seamlessly pipelining multimodal {TSF} evaluations based on Time-{MMD} for in-depth analyses. Extensive experiments conducted on Time-{MMD} through {MM}-{TSFlib} demonstrate significant performance enhancements by extending unimodal {TSF} to multimodality, evidenced by over 15\% mean squared error reduction in general, and up to 40\% in domains with rich textual data. More importantly, our datasets and library revolutionize broader applications, impacts, research topics to advance {TSA}. The dataset and library are available at https://github.com/{AdityaLab}/Time-{MMD} and https://github.com/{AdityaLab}/{MM}-{TSFlib}.},
  number     = {{arXiv}:2406.08627},
  publisher  = {{arXiv}},
  author     = {Liu, Haoxin and Xu, Shangqing and Zhao, Zhiyuan and Kong, Lingkai and Kamarthi, Harshavardhan and Sasanur, Aditya B. and Sharma, Megha and Cui, Jiaming and Wen, Qingsong and Zhang, Chao and Prakash, B. Aditya},
  urldate    = {2024-07-26},
  date       = {2024-06-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.08627 [cs]},
  note       = {{TLDR}: Time-{MMD} is introduced, the first multi-domain, multimodal time series dataset covering 9 primary data domains, and {MM}-{TSFlib}, the first multimodal time-series forecasting ({TSF}) library, seamlessly pipelining multimodal {TSF} evaluations based on Time-{MMD} for in-depth analyses.},
  keywords   = {/reading, Computer Science - Computation and Language, Computer Science - Machine Learning},
  file       = {2024_Time-MMD_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\IF3JIIJ4\\2024_Time-MMD_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\MX9D5JUE\\2406.html:text/html}
}

@misc{liu_timecma_2024,
  title      = {{TimeCMA}: Towards {LLM}-Empowered Time Series Forecasting via Cross-Modality Alignment},
  url        = {http://arxiv.org/abs/2406.01638},
  shorttitle = {{TimeCMA}},
  abstract   = {The widespread adoption of scalable mobile sensing has led to large amounts of time series data for real-world applications. A fundamental application is multivariate time series forecasting ({MTSF}), which aims to predict future time series values based on historical observations. Existing {MTSF} methods suffer from limited parameterization and small-scale training data. Recently, Large language models ({LLMs}) have been introduced in time series, which achieve promising forecasting performance but incur heavy computational costs. To solve these challenges, we propose {TimeCMA}, an {LLM}-empowered framework for time series forecasting with cross-modality alignment. We design a dual-modality encoding module with two branches, where the time series encoding branch extracts relatively low-quality yet pure embeddings of time series through an inverted Transformer. In addition, the {LLM}-empowered encoding branch wraps the same time series as prompts to obtain high-quality yet entangled prompt embeddings via a Pre-trained {LLM}. Then, we design a cross-modality alignment module to retrieve high-quality and pure time series embeddings from the prompt embeddings. Moreover, we develop a time series forecasting module to decode the aligned embeddings while capturing dependencies among multiple variables for forecasting. Notably, we tailor the prompt to encode sufficient temporal information into a last token and design the last token embedding storage to reduce computational costs. Extensive experiments on real data offer insight into the accuracy and efficiency of the proposed framework.},
  number     = {{arXiv}:2406.01638},
  publisher  = {{arXiv}},
  author     = {Liu, Chenxi and Xu, Qianxiong and Miao, Hao and Yang, Sun and Zhang, Lingzheng and Long, Cheng and Li, Ziyue and Zhao, Rui},
  urldate    = {2024-06-13},
  date       = {2024-06-02},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.01638 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Liu 等 - 2024 - TimeCMA Towards LLM-Empowered Time Series Forecas.pdf:C\:\\Users\\yanha\\Zotero\\storage\\VISQGDIG\\Liu 等 - 2024 - TimeCMA Towards LLM-Empowered Time Series Forecas.pdf:application/pdf}
}

@misc{liu_we_2023,
  title      = {Do We Really Need Graph Neural Networks for Traffic Forecasting?},
  url        = {http://arxiv.org/abs/2301.12603},
  doi        = {10.48550/arXiv.2301.12603},
  abstract   = {Spatio-temporal graph neural networks ({STGNN}) have become the most popular solution to traffic forecasting. While successful, they rely on the message passing scheme of {GNNs} to establish spatial dependencies between nodes, and thus inevitably inherit {GNNs}' notorious inefficiency. Given these facts, in this paper, we propose an embarrassingly simple yet remarkably effective spatio-temporal learning approach, entitled {SimST}. Specifically, {SimST} approximates the efficacies of {GNNs} by two spatial learning techniques, which respectively model local and global spatial correlations. Moreover, {SimST} can be used alongside various temporal models and involves a tailored training strategy. We conduct experiments on five traffic benchmarks to assess the capability of {SimST} in terms of efficiency and effectiveness. Empirical results show that {SimST} improves the prediction throughput by up to 39 times compared to more sophisticated {STGNNs} while attaining comparable performance, which indicates that {GNNs} are not the only option for spatial modeling in traffic forecasting.},
  number     = {{arXiv}:2301.12603},
  publisher  = {{arXiv}},
  author     = {Liu, Xu and Liang, Yuxuan and Huang, Chao and Hu, Hengchang and Cao, Yushi and Hooi, Bryan and Zimmermann, Roger},
  urldate    = {2024-01-05},
  date       = {2023-01-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2301.12603 [cs]},
  note       = {{TLDR}: Empirical results show that {SimST} improves the prediction throughput by up to 39 times compared to more sophisticated {STGNNs} while attaining comparable performance, which indicates that {GNNs} are not the only option for spatial modeling in traffic forecasting.},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Social and Information Networks},
  file       = {2023_Do We Really Need Graph Neural Networks for Traffic Forecasting_Liu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GQK8JCLA\\2023_Do We Really Need Graph Neural Networks for Traffic Forecasting_Liu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\WUHI9X5X\\2301.html:text/html}
}

@article{luo_clusterst_2023,
  title        = {{ClusterST}: Clustering Spatial–Temporal Network for Traffic Forecasting},
  volume       = {24},
  issn         = {1524-9050, 1558-0016},
  url          = {https://ieeexplore.ieee.org/document/9954322/},
  doi          = {10.1109/TITS.2022.3215703},
  shorttitle   = {{ClusterST}},
  pages        = {706--717},
  number       = {1},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  shortjournal = {{IEEE} Trans. Intell. Transport. Syst.},
  author       = {Luo, Guiyang and Zhang, Hui and Yuan, Quan and Li, Jinglin and Wang, Fei-Yue},
  urldate      = {2023-07-25},
  date         = {2023-01},
  langid       = {english},
  keywords     = {/unread},
  file         = {2023_ClusterST_Luo et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\3ZD7ZDP5\\2023_ClusterST_Luo et al.pdf:application/pdf}
}

@misc{luo_openomni_2025,
  title      = {{OpenOmni}: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis},
  url        = {http://arxiv.org/abs/2501.04561},
  doi        = {10.48550/arXiv.2501.04561},
  shorttitle = {{OpenOmni}},
  abstract   = {Recent advancements in omnimodal learning have been achieved in understanding and generation across images, text, and speech, though mainly within proprietary models. Limited omnimodal datasets and the inherent challenges associated with real-time emotional speech generation have hindered open-source progress. To address these issues, we propose openomni, a two-stage training method combining omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model. In the alignment phase, a pre-trained speech model is further trained on text-image tasks to generalize from vision to speech in a (near) zero-shot manner, outperforming models trained on tri-modal datasets. In the speech generation phase, a lightweight decoder facilitates real-time emotional speech through training on speech tasks and preference learning. Experiments demonstrate that openomni consistently improves across omnimodal, vision-language, and speech-language evaluations, enabling natural, emotion-rich dialogues and real-time emotional speech generation.},
  number     = {{arXiv}:2501.04561},
  publisher  = {{arXiv}},
  author     = {Luo, Run and Lin, Ting-En and Zhang, Haonan and Wu, Yuchuan and Liu, Xiong and Yang, Min and Li, Yongbin and Chen, Longze and Li, Jiaming and Zhang, Lei and Chen, Yangyi and Alinejad-Rokny, Hamid and Huang, Fei},
  urldate    = {2025-02-17},
  date       = {2025-01-23},
  eprinttype = {arxiv},
  eprint     = {2501.04561 [cs]},
  note       = {{TLDR}: Openomni, a two-stage training method combining omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model, is proposed, enabling natural, emotion-rich dialogues and real-time emotional speech generation.},
  keywords   = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\4XYSWDPH\\Luo 等 - 2025 - OpenOmni Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time S.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\PXDX28CA\\2501.html:text/html}
}

@article{ma_forecasting_2021,
  title        = {Forecasting Transportation Network Speed Using Deep Capsule Networks With Nested {LSTM} Models},
  volume       = {22},
  issn         = {1558-0016},
  url          = {https://ieeexplore.ieee.org/document/9069477},
  doi          = {10.1109/TITS.2020.2984813},
  abstract     = {Accurate and reliable traffic forecasting for complicated transportation networks is of vital importance to modern transportation management. The complicated spatial dependencies of roadway links and the dynamic temporal patterns of traffic states make it particularly challenging. To address these challenges, we propose a new capsule network ({CapsNet}) to extract the spatial features of traffic networks and utilize a nested {LSTM} ({NLSTM}) structure to capture the hierarchical temporal dependencies in traffic sequence data. A framework for network-level traffic forecasting is also proposed by sequentially connecting {CapsNet} and {NLSTM}. On the basis of literature review, our study is the first to adopt {CapsNet} and {NLSTM} in the field of traffic forecasting. An experiment on a Beijing transportation network with 278 links shows that the proposed framework with the capability of capturing complicated spatiotemporal traffic patterns outperforms multiple state-of-the-art traffic forecasting baseline models. The superiority and feasibility of {CapsNet} and {NLSTM} are also demonstrated, respectively, by visualizing and quantitatively evaluating the experimental results.},
  pages        = {4813--4824},
  number       = {8},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  author       = {Ma, Xiaolei and Zhong, Houyue and Li, Yi and Ma, Junyan and Cui, Zhiyong and Wang, Yinhai},
  urldate      = {2024-06-14},
  date         = {2021-08},
  langid       = {english},
  note         = {Conference Name: {IEEE} Transactions on Intelligent Transportation Systems},
  keywords     = {/unread, Artificial neural networks, Capsule network, Feature extraction, Forecasting, {LSTM}, Machine learning, Predictive models, Roads, spatial and temporal dependency, traffic prediction, transportation network},
  file         = {2021_Forecasting Transportation Network Speed Using Deep Capsule Networks With_Ma et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\ZM46HV5M\\2021_Forecasting Transportation Network Speed Using Deep Capsule Networks With_Ma et al.pdf:application/pdf}
}

@article{ma_long_2015,
  title        = {Long short-term memory neural network for traffic speed prediction using remote microwave sensor data},
  volume       = {54},
  issn         = {0968-090X},
  doi          = {10.1016/j.trc.2015.03.014},
  pages        = {187--197},
  journaltitle = {Transportation Research Part C: Emerging Technologies},
  shortjournal = {Transportation Research Part C: Emerging Technologies},
  author       = {Ma, Xiaolei and Tao, Zhimin and Wang, Yinhai and Yu, Haiyang and Wang, Yunpeng},
  date         = {2015},
  note         = {Publisher: Elsevier},
  keywords     = {/unread}
}

@book{mai_opportunities_2023,
  title    = {On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence},
  abstract = {Large pre-trained models, also known as foundation models ({FMs}), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence ({GeoAI}). In this work, we explore the promises and challenges of developing multimodal foundation models for {GeoAI}. We first investigate the potential of many existing {FMs} by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and {US} state-level/county-level dementia time series forecasting, these task-agnostic {LLMs} can outperform task-specific fully-supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., {POI}-based urban function classification, street view image-based urban noise intensity classification, and remote sensing image scene classification), existing foundation models still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing a {FM} for {GeoAI} is to address the multimodality nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal foundation model which can reason over various types of geospatial data through geospatial alignments. We conclude this paper by discussing the unique risks and challenges to develop such a model for {GeoAI}.},
  author   = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
  date     = {2023-04-13},
  langid   = {english},
  keywords = {/reading, /unread},
  file     = {2023_On the Opportunities and Challenges of Foundation Models for Geospatial_Mai et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GXQI3JVU\\2023_On the Opportunities and Challenges of Foundation Models for Geospatial_Mai et al.pdf:application/pdf}
}

@article{mai_review_2022,
  title        = {A review of location encoding for {GeoAI}: methods and applications},
  volume       = {36},
  issn         = {1365-8816},
  url          = {https://doi.org/10.1080/13658816.2021.2004602},
  doi          = {10.1080/13658816.2021.2004602},
  shorttitle   = {A review of location encoding for {GeoAI}},
  abstract     = {A common need for artificial intelligence models in the broader geoscience is to encode various types of spatial data, such as points, polylines, polygons, graphs, or rasters, in a hidden embedding space so that they can be readily incorporated into deep learning models. One fundamental step is to encode a single point location into an embedding space, such that this embedding is learning-friendly for downstream machine learning models. We call this process location encoding. However, there lacks a systematic review on location encoding, its potential applications, and key challenges that need to be addressed. This paper aims to fill this gap. We first provide a formal definition of location encoding, and discuss the necessity of it for {GeoAI} research. Next, we provide a comprehensive survey about the current landscape of location encoding research. We classify location encoding models into different categories based on their inputs and encoding methods, and compare them based on whether they are parametric, multi-scale, distance preserving, and direction aware. We demonstrate that existing location encoders can be unified under one formulation framework. We also discuss the application of location encoding. Finally, we point out several challenges that need to be solved in the future.},
  pages        = {639--673},
  number       = {4},
  journaltitle = {International Journal of Geographical Information Science},
  author       = {Mai, Gengchen and Janowicz, Krzysztof and Hu, Yingjie and Gao, Song and Yan, Bo and Zhu, Rui and Cai, Ling and Lao, Ni},
  urldate      = {2023-12-21},
  date         = {2022-04-03},
  langid       = {english},
  note         = {Publisher: Taylor \& Francis
                  \_eprint: https://doi.org/10.1080/13658816.2021.2004602},
  keywords     = {/unread, {GeoAI}, Location encoding, representation learning, spatially explicit machine learning},
  file         = {2022_A review of location encoding for GeoAI_Mai et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\LKDXNFDY\\2022_A review of location encoding for GeoAI_Mai et al.pdf:application/pdf}
}

@misc{merrill_language_2024,
  title      = {Language Models Still Struggle to Zero-shot Reason about Time Series},
  url        = {http://arxiv.org/abs/2404.11757},
  doi        = {10.48550/arXiv.2404.11757},
  abstract   = {Time series are critical for decision-making in fields like finance and healthcare. Their importance has driven a recent influx of works passing time series into language models, leading to non-trivial forecasting on some datasets. But it remains unknown whether non-trivial forecasting implies that language models can reason about time series. To address this gap, we generate a first-of-its-kind evaluation framework for time series reasoning, including formal tasks and a corresponding dataset of multi-scale time series paired with text captions across ten domains. Using these data, we probe whether language models achieve three forms of reasoning: (1) Etiological Reasoning - given an input time series, can the language model identify the scenario that most likely created it? (2) Question Answering - can a language model answer factual questions about time series? (3) Context-Aided Forecasting - does highly relevant textual context improve a language model's time series forecasts? We find that otherwise highly-capable language models demonstrate surprisingly limited time series reasoning: they score marginally above random on etiological and question answering tasks (up to 30 percentage points worse than humans) and show modest success in using context to improve forecasting. These weakness showcase that time series reasoning is an impactful, yet deeply underdeveloped direction for language model research. We also make our datasets and code public at to support further research in this direction at https://github.com/behavioral-data/{TSandLanguage}},
  number     = {{arXiv}:2404.11757},
  publisher  = {{arXiv}},
  author     = {Merrill, Mike A. and Tan, Mingtian and Gupta, Vinayak and Hartvigsen, Tom and Althoff, Tim},
  urldate    = {2024-10-28},
  date       = {2024-04-17},
  eprinttype = {arxiv},
  eprint     = {2404.11757},
  keywords   = {/reading, Computer Science - Computation and Language},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\89EL9WXU\\2404.html:text/html;Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\RY5BT4X4\\Merrill 等 - 2024 - Language Models Still Struggle to Zero-shot Reason about Time Series.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\BCG9T53J\\2404.html:text/html}
}

@misc{moghadas_strada-llm_2024,
  title      = {Strada-{LLM}: Graph {LLM} for traffic prediction},
  url        = {http://arxiv.org/abs/2410.20856},
  doi        = {10.48550/arXiv.2410.20856},
  shorttitle = {Strada-{LLM}},
  abstract   = {Traffic prediction is a vital component of intelligent transportation systems. By reasoning about traffic patterns in both the spatial and temporal dimensions, accurate and interpretable predictions can be provided. A considerable challenge in traffic prediction lies in handling the diverse data distributions caused by vastly different traffic conditions occurring at different locations. {LLMs} have been a dominant solution due to their remarkable capacity to adapt to new datasets with very few labeled data samples, i.e., few-shot adaptability. However, existing forecasting techniques mainly focus on extracting local graph information and forming a text-like prompt, leaving {LLM}- based traffic prediction an open problem. This work presents a probabilistic {LLM} for traffic forecasting with three highlights. We propose a graph-aware {LLM} for traffic prediction that considers proximal traffic information. Specifically, by considering the traffic of neighboring nodes as covariates, our model outperforms the corresponding time-series {LLM}. Furthermore, we adopt a lightweight approach for efficient domain adaptation when facing new data distributions in few-shot fashion. The comparative experiment demonstrates the proposed method outperforms the state-of-the-art {LLM}-based methods and the traditional {GNN}- based supervised approaches. Furthermore, Strada-{LLM} can be easily adapted to different {LLM} backbones without a noticeable performance drop.},
  number     = {{arXiv}:2410.20856},
  publisher  = {{arXiv}},
  author     = {Moghadas, Seyed Mohamad and Lyu, Yangxintong and Cornelis, Bruno and Alahi, Alexandre and Munteanu, Adrian},
  urldate    = {2024-11-12},
  date       = {2024-10-28},
  eprinttype = {arxiv},
  eprint     = {2410.20856},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\NARZ7G7M\\Moghadas 等 - 2024 - Strada-LLM Graph LLM for traffic prediction.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LUBAJ9Z9\\2410.html:text/html}
}

@article{mou_deep_2025,
  title        = {Deep Learning for Predicting Biomolecular Binding Sites of Proteins},
  volume       = {8},
  url          = {https://spj.science.org/doi/10.34133/research.0615},
  doi          = {10.34133/research.0615},
  abstract     = {The rapid evolution of deep learning has markedly enhanced protein–biomolecule binding site prediction, offering insights essential for drug discovery, mutation analysis, and molecular biology. Advancements in both sequence-based and structure-based methods demonstrate their distinct strengths and limitations. Sequence-based approaches offer efficiency and adaptability, while structure-based techniques provide spatial precision but require high-quality structural data. Emerging trends in hybrid models that combine multimodal data, such as integrating sequence and structural information, along with innovations in geometric deep learning, present promising directions for improving prediction accuracy. This perspective summarizes challenges such as computational demands and dynamic modeling and proposes strategies for future research. The ultimate goal is the development of computationally efficient and flexible models capable of capturing the complexity of real-world biomolecular interactions, thereby broadening the scope and applicability of binding site predictions across a wide range of biomedical contexts.},
  pages        = {0615},
  journaltitle = {Research},
  author       = {Mou, Minjie and Zhang, Zhichao and Pan, Ziqi and Zhu, Feng},
  urldate      = {2025-04-15},
  date         = {2025-02-24},
  note         = {Publisher: American Association for the Advancement of Science
                  {TLDR}: The ultimate goal is the development of computationally efficient and flexible models capable of capturing the complexity of real-world biomolecular interactions, thereby broadening the scope and applicability of binding site predictions across a wide range of biomedical contexts.},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\HCV7TYEH\\Mou 等 - 2025 - Deep Learning for Predicting Biomolecular Binding Sites of Proteins.pdf:application/pdf}
}

@article{mou_transformer-based_2023,
  title        = {A Transformer-Based Ensemble Framework for the Prediction of Protein–Protein Interaction Sites},
  rights       = {Copyright © 2023 Minjie Mou et al.},
  url          = {https://spj.science.org/doi/10.34133/research.0240},
  doi          = {10.34133/research.0240},
  abstract     = {The identification of protein–protein interaction ({PPI}) sites is essential in the research of protein function and the discovery of new drugs. So far, a variety of computational tools based on machine learning have been developed to accelerate the ...},
  journaltitle = {Research},
  author       = {Mou, Minjie and Pan, Ziqi and Zhou, Zhimeng and Zheng, Lingyan and Zhang, Hanyu and Shi, Shuiyang and Li, Fengcheng and Sun, Xiuna and Zhu, Feng},
  urldate      = {2025-04-15},
  date         = {2023-09-27},
  note         = {Publisher: {AAAS}
                  {TLDR}: A novel ensemble framework for {PPI} sites prediction, {EnsemPPIS}, was proposed based on transformer and gated convolutional networks that was unique in extracting residue interactions from protein sequences with transformer and further integrating global and local sequential features with the ensemble learning strategy.},
  file         = {PubMed Central Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\V2X6ZHVS\\Mou 等 - 2023 - A Transformer-Based Ensemble Framework for the Prediction of Protein–Protein Interaction Sites.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\8RVGQM2S\\research.html:text/html}
}

@misc{munkhdalai_leave_2024,
  title      = {Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention},
  url        = {http://arxiv.org/abs/2404.07143},
  shorttitle = {Leave No Context Behind},
  abstract   = {This work introduces an efficient method to scale Transformer-based Large Language Models ({LLMs}) to infinitely long inputs with bounded memory and computation. A key component in our proposed approach is a new attention technique dubbed Infini-attention. The Infini-attention incorporates a compressive memory into the vanilla attention mechanism and builds in both masked local attention and long-term linear attention mechanisms in a single Transformer block. We demonstrate the effectiveness of our approach on long-context language modeling benchmarks, 1M sequence length passkey context block retrieval and 500K length book summarization tasks with 1B and 8B {LLMs}. Our approach introduces minimal bounded memory parameters and enables fast streaming inference for {LLMs}.},
  number     = {{arXiv}:2404.07143},
  publisher  = {{arXiv}},
  author     = {Munkhdalai, Tsendsuren and Faruqui, Manaal and Gopal, Siddharth},
  urldate    = {2024-04-12},
  date       = {2024-04-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.07143 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
  file       = {2024_Leave No Context Behind_Munkhdalai et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\G7YD3DDI\\2024_Leave No Context Behind_Munkhdalai et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\Q6CGSCYW\\2404.html:text/html}
}

@misc{ni_mixture--linear-experts_2024,
  title      = {Mixture-of-Linear-Experts for Long-term Time Series Forecasting},
  url        = {http://arxiv.org/abs/2312.06786},
  doi        = {10.48550/arXiv.2312.06786},
  abstract   = {Long-term time series forecasting ({LTSF}) aims to predict future values of a time series given the past values. The current state-of-the-art ({SOTA}) on this problem is attained in some cases by linear-centric models, which primarily feature a linear mapping layer. However, due to their inherent simplicity, they are not able to adapt their prediction rules to periodic changes in time series patterns. To address this challenge, we propose a Mixture-of-Experts-style augmentation for linear-centric models and propose Mixture-of-Linear-Experts ({MoLE}). Instead of training a single model, {MoLE} trains multiple linear-centric models (i.e., experts) and a router model that weighs and mixes their outputs. While the entire framework is trained end-to-end, each expert learns to specialize in a specific temporal pattern, and the router model learns to compose the experts adaptively. Experiments show that {MoLE} reduces forecasting error of linear-centric models, including {DLinear}, {RLinear}, and {RMLP}, in over 78\% of the datasets and settings we evaluated. By using {MoLE} existing linear-centric models can achieve {SOTA} {LTSF} results in 68\% of the experiments that {PatchTST} reports and we compare to, whereas existing single-head linear-centric models achieve {SOTA} results in only 25\% of cases. Additionally, {MoLE} models achieve {SOTA} in all settings for the newly released Weather2K datasets.},
  number     = {{arXiv}:2312.06786},
  publisher  = {{arXiv}},
  author     = {Ni, Ronghao and Lin, Zinan and Wang, Shuaiqi and Fanti, Giulia},
  urldate    = {2024-02-06},
  date       = {2024-01-07},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2312.06786 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RYUUVMVV\\2312.html:text/html;Ni et al_2024_Mixture-of-Linear-Experts for Long-term Time Series Forecasting.pdf:C\:\\Users\\yanha\\Zotero\\storage\\379TSPT5\\Ni et al_2024_Mixture-of-Linear-Experts for Long-term Time Series Forecasting.pdf:application/pdf}
}

@misc{nie_time_2023,
  title      = {A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  url        = {http://arxiv.org/abs/2211.14730},
  shorttitle = {A Time Series is Worth 64 Words},
  abstract   = {We propose an efficient design of Transformer-based models for multivariate time series forecasting and self-supervised representation learning. It is based on two key components: (i) segmentation of time series into subseries-level patches which are served as input tokens to Transformer; (ii) channel-independence where each channel contains a single univariate time series that shares the same embedding and Transformer weights across all the series. Patching design naturally has three-fold benefit: local semantic information is retained in the embedding; computation and memory usage of the attention maps are quadratically reduced given the same look-back window; and the model can attend longer history. Our channel-independent patch time series Transformer ({PatchTST}) can improve the long-term forecasting accuracy significantly when compared with that of {SOTA} Transformer-based models. We also apply our model to self-supervised pre-training tasks and attain excellent fine-tuning performance, which outperforms supervised training on large datasets. Transferring of masked pre-trained representation on one dataset to others also produces {SOTA} forecasting accuracy. Code is available at: https://github.com/yuqinie98/{PatchTST}.},
  number     = {{arXiv}:2211.14730},
  publisher  = {{arXiv}},
  author     = {Nie, Yuqi and Nguyen, Nam H. and Sinthong, Phanwadee and Kalagnanam, Jayant},
  urldate    = {2023-12-15},
  date       = {2023-03-05},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2211.14730 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2023_A Time Series is Worth 64 Words_Nie et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\A6VY9QB8\\2023_A Time Series is Worth 64 Words_Nie et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\BENMC6KN\\2211.html:text/html}
}

@misc{ning_elucidating_2024,
  title      = {Elucidating the Exposure Bias in Diffusion Models},
  url        = {http://arxiv.org/abs/2308.15321},
  doi        = {10.48550/arXiv.2308.15321},
  abstract   = {Diffusion models have demonstrated impressive generative capabilities, but their {\textbackslash}textit\{exposure bias\} problem, described as the input mismatch between training and sampling, lacks in-depth exploration. In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue. Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it. Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias. We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output, mitigating the input mismatch between training and sampling. Experiments on various diffusion frameworks ({ADM}, {DDIM}, {EDM}, {LDM}, {DiT}, {PFGM}++) verify the effectiveness of our method. Remarkably, our {ADM}-{ES}, as a state-of-the-art stochastic sampler, obtains 2.17 {FID} on {CIFAR}-10 under 100-step unconditional generation. The code is available at {\textbackslash}url\{https://github.com/forever208/{ADM}-{ES}\} and {\textbackslash}url\{https://github.com/forever208/{EDM}-{ES}\}.},
  number     = {{arXiv}:2308.15321},
  publisher  = {{arXiv}},
  author     = {Ning, Mang and Li, Mingxiao and Su, Jianlin and Salah, Albert Ali and Ertugrul, Itir Onal},
  urldate    = {2024-04-22},
  date       = {2024-04-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2308.15321 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, ⭐⭐⭐⭐},
  file       = {2024_Elucidating the Exposure Bias in Diffusion Models_Ning et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\KZUX5QX7\\2024_Elucidating the Exposure Bias in Diffusion Models_Ning et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\CYSG6WME\\2308.html:text/html}
}

@online{noauthor_guidelines_nodate,
  title      = {Guidelines for Authors},
  url        = {https://spj.science.org/page/research/for-authors?doi=10.34133%2Fresearch&publicationCode=research},
  titleaddon = {Research},
  urldate    = {2025-04-15},
  langid     = {english},
  file       = {Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RPSQK8NS\\for-authors.html:text/html}
}

@inproceedings{noauthor_revitalizing_2023,
  title      = {Revitalizing Channel-dimension Fourier Transform for Image Enhancement},
  url        = {https://openreview.net/forum?id=3tjTJeXyA7},
  abstract   = {Exploring the global representations of Fourier transform for image enhancement has become an alternative and made significant advancements. However, previous works only operate in the spatial dimensional, overlooking the potential of the channel dimension that inherently possesses discriminative features. In this work, we propose a fresh perspective, channel-dimension Fourier transform, for image enhancement. Our designs are simple yet effective and comprise three straightforward steps: applying the Fourier transform to the channel dimension to obtain channel-wise Fourier domain features, performing a channel-wise transformation on both its amplitude and phase components, and then reverting back to the spatial domain. Following the above rules, we offer three alternative implementation formats of the channel transform in different operational spaces, performing operations in 1) the global vector with higher orders; 2) the global vector with channel groups; and 3) the Fourier features derived from spatial-based Fourier transform. The above core designs, as general operators, can be seamlessly integrated with enhancement networks, achieving remarkable gains and building efficient models. Through extensive experiments on multiple image enhancement tasks, like low-light image enhancement, exposure correction, {SDR}2HDR translation, and underwater image enhancement, our designs exhibit consistent performance gains. The code will be publicly available.},
  eventtitle = {The Twelfth International Conference on Learning Representations},
  urldate    = {2024-01-10},
  date       = {2023-10-13},
  langid     = {english},
  keywords   = {/unread},
  file       = {2023_Revitalizing Channel-dimension Fourier Transform for Image Enhancement_.pdf:C\:\\Users\\yanha\\Zotero\\storage\\Z9XXCGMD\\2023_Revitalizing Channel-dimension Fourier Transform for Image Enhancement_.pdf:application/pdf}
}

@inproceedings{noauthor_timemixer_2023,
  title      = {{TimeMixer}: Decomposable Multiscale Mixing for Time Series Forecasting},
  url        = {https://openreview.net/forum?id=7oLshfEIC2},
  shorttitle = {{TimeMixer}},
  abstract   = {Time series forecasting is widely used in extensive applications, such as traffic planning and weather forecasting. However, real-world time series usually present intricate temporal variations, making forecasting extremely challenging. Going beyond the mainstream paradigms of plain decomposition and multiperiodicity analysis, we analyze temporal variations in a novel view of multiscale-mixing, where time series present distinct patterns in different sampling scales. Specifically, the microscopic and the macroscopic information are reflected in fine and coarse scales, respectively, and thereby complex variations are inherently disentangled. Based on this observation, we propose {TimeMixer} as a fully {MLP}-based architecture with Past-Decomposable-Mixing ({PDM}) and Future-Multipredictor-Mixing ({FMM}) blocks to take full advantage of disentangled multiscale series in both past extraction and future prediction phases. Concretely, {PDM} applies the decomposition to multiscale series and further mixes the decomposed seasonal and trend components in fine-to-coarse and coarse-to-fine directions separately, which successively aggregates the microscopic seasonal and macroscopic trend information. {FMM} further ensembles multiple predictors to utilize complementary forecasting capabilities in multiscale observations. Consequently, our proposed {TimeMixer} is able to achieve consistent state-of-the-art performances in both long-term and short-term forecasting tasks with favorable run-time efficiency.},
  eventtitle = {The Twelfth International Conference on Learning Representations},
  urldate    = {2024-01-26},
  date       = {2023-10-13},
  langid     = {english},
  keywords   = {/reading},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\53FQUI6D\\2023 - TimeMixer Decomposable Multiscale Mixing for Time.pdf:application/pdf}
}

@misc{pan_textbfs2ip-llm_2024,
  title      = {\${\textbackslash}textbf\{S\}{\textasciicircum}2\${IP}-{LLM}: Semantic Space Informed Prompt Learning with {LLM} for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2403.05798},
  doi        = {10.48550/arXiv.2403.05798},
  shorttitle = {\${\textbackslash}textbf\{S\}{\textasciicircum}2\${IP}-{LLM}},
  abstract   = {Recently, there has been a growing interest in leveraging pre-trained large language models ({LLMs}) for various time series applications. However, the semantic space of {LLMs}, established through the pre-training, is still underexplored and may help yield more distinctive and informative representations to facilitate time series forecasting. To this end, we propose Semantic Space Informed Prompt learning with {LLM} (\$S{\textasciicircum}2\${IP}-{LLM}) to align the pre-trained semantic space with time series embeddings space and perform time series forecasting based on learned prompts from the joint space. We first design a tokenization module tailored for cross-modality alignment, which explicitly concatenates patches of decomposed time series components to create embeddings that effectively encode the temporal dynamics. Next, we leverage the pre-trained word token embeddings to derive semantic anchors and align selected anchors with time series embeddings by maximizing the cosine similarity in the joint space. This way, \$S{\textasciicircum}2\${IP}-{LLM} can retrieve relevant semantic anchors as prompts to provide strong indicators (context) for time series that exhibit different temporal dynamics. With thorough empirical studies on multiple benchmark datasets, we demonstrate that the proposed \$S{\textasciicircum}2\${IP}-{LLM} can achieve superior forecasting performance over state-of-the-art baselines. Furthermore, our ablation studies and visualizations verify the necessity of prompt learning informed by semantic space.},
  number     = {{arXiv}:2403.05798},
  publisher  = {{arXiv}},
  author     = {Pan, Zijie and Jiang, Yushan and Garg, Sahil and Schneider, Anderson and Nevmyvaka, Yuriy and Song, Dongjin},
  urldate    = {2024-03-18},
  date       = {2024-03-09},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.05798 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_\$-textbf S ^2\$IP-LLM_Pan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GQLR6NNB\\2024_\$-textbf S ^2\$IP-LLM_Pan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JHG6SN3D\\2403.html:text/html}
}

@misc{peng_lc-llm_2024,
  title      = {{LC}-{LLM}: Explainable Lane-Change Intention and Trajectory Predictions with Large Language Models},
  url        = {http://arxiv.org/abs/2403.18344},
  doi        = {10.48550/arXiv.2403.18344},
  shorttitle = {{LC}-{LLM}},
  abstract   = {To ensure safe driving in dynamic environments, autonomous vehicles should possess the capability to accurately predict the lane change intentions of surrounding vehicles in advance and forecast their future trajectories. Existing motion prediction approaches have ample room for improvement, particularly in terms of long-term prediction accuracy and interpretability. In this paper, we address these challenges by proposing {LC}-{LLM}, an explainable lane change prediction model that leverages the strong reasoning capabilities and self-explanation abilities of Large Language Models ({LLMs}). Essentially, we reformulate the lane change prediction task as a language modeling problem, processing heterogeneous driving scenario information in natural language as prompts for input into the {LLM} and employing a supervised fine-tuning technique to tailor the {LLM} specifically for our lane change prediction task. This allows us to utilize the {LLM}'s powerful common sense reasoning abilities to understand complex interactive information, thereby improving the accuracy of long-term predictions. Furthermore, we incorporate explanatory requirements into the prompts in the inference stage. Therefore, our {LC}-{LLM} model not only can predict lane change intentions and trajectories but also provides explanations for its predictions, enhancing the interpretability. Extensive experiments on the large-scale {highD} dataset demonstrate the superior performance and interpretability of our {LC}-{LLM} in lane change prediction task. To the best of our knowledge, this is the first attempt to utilize {LLMs} for predicting lane change behavior. Our study shows that {LLMs} can encode comprehensive interaction information for driving behavior understanding.},
  number     = {{arXiv}:2403.18344},
  publisher  = {{arXiv}},
  author     = {Peng, Mingxing and Guo, Xusen and Chen, Xianda and Zhu, Meixin and Chen, Kehua and Hao and Yang and Wang, Xuesong and Wang, Yinhai},
  urldate    = {2024-04-09},
  date       = {2024-03-27},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.18344 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence},
  file       = {2024_LC-LLM_Peng et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\FRCNBS7Y\\2024_LC-LLM_Peng et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\VQ2EQCPD\\2403.html:text/html}
}

@article{raffel2020exploring,
  title   = {Exploring the limits of transfer learning with a unified text-to-text transformer},
  author  = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal = {Journal of machine learning research},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  year    = {2020}
}

@misc{rasul_lag-llama_2023,
  title      = {Lag-Llama: Towards Foundation Models for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2310.08278},
  doi        = {10.48550/arXiv.2310.08278},
  shorttitle = {Lag-Llama},
  abstract   = {Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama, a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen "out-of-distribution" time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws to fit and predict model scaling behavior. The open source code is made available at https://github.com/kashif/pytorch-transformer-ts.},
  number     = {{arXiv}:2310.08278},
  publisher  = {{arXiv}},
  author     = {Rasul, Kashif and Ashok, Arjun and Williams, Andrew Robert and Khorasani, Arian and Adamopoulos, George and Bhagwatkar, Rishika and Biloš, Marin and Ghonia, Hena and Hassen, Nadhir Vincent and Schneider, Anderson and Garg, Sahil and Drouin, Alexandre and Chapados, Nicolas and Nevmyvaka, Yuriy and Rish, Irina},
  urldate    = {2023-10-18},
  date       = {2023-10-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.08278 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2023_Lag-Llama_Rasul et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Lag-Llama_Rasul et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UVBBESQW\\2310.html:text/html}
}

@article{runge_inferring_2019,
  title        = {Inferring causation from time series in Earth system sciences},
  volume       = {10},
  rights       = {2019 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-019-10105-3},
  doi          = {10.1038/s41467-019-10105-3},
  abstract     = {The heart of the scientific enterprise is a rational effort to understand the causes behind the phenomena we observe. In large-scale complex dynamical systems such as the Earth system, real experiments are rarely feasible. However, a rapidly increasing amount of observational and simulated data opens up the use of novel data-driven causal methods beyond the commonly adopted correlation techniques. Here, we give an overview of causal inference frameworks and identify promising generic application cases common in Earth system sciences and beyond. We discuss challenges and initiate the benchmark platform causeme.netto close the gap between method users and developers.},
  pages        = {2553},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Runge, Jakob and Bathiany, Sebastian and Bollt, Erik and Camps-Valls, Gustau and Coumou, Dim and Deyle, Ethan and Glymour, Clark and Kretschmer, Marlene and Mahecha, Miguel D. and Muñoz-Marí, Jordi and van Nes, Egbert H. and Peters, Jonas and Quax, Rick and Reichstein, Markus and Scheffer, Marten and Schölkopf, Bernhard and Spirtes, Peter and Sugihara, George and Sun, Jie and Zhang, Kun and Zscheischler, Jakob},
  urldate      = {2024-05-23},
  date         = {2019-06-14},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group},
  keywords     = {/reading, Computational science, Climate sciences, Databases, Environmental sciences, Statistical physics, thermodynamics and nonlinear dynamics},
  file         = {2019_Inferring causation from time series in Earth system sciences_Runge et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\ZDJK69TR\\2019_Inferring causation from time series in Earth system sciences_Runge et al.pdf:application/pdf}
}

@misc{ruswurm_geographic_2023,
  title      = {Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks},
  url        = {http://arxiv.org/abs/2310.06743},
  doi        = {10.48550/arXiv.2310.06743},
  abstract   = {Learning feature representations of geographical space is vital for any machine learning model that integrates geolocated data, spanning application domains such as remote sensing, ecology, or epidemiology. Recent work mostly embeds coordinates using sine and cosine projections based on Double Fourier Sphere ({DFS}) features -- these embeddings assume a rectangular data domain even on global data, which can lead to artifacts, especially at the poles. At the same time, relatively little attention has been paid to the exact design of the neural network architectures these functional embeddings are combined with. This work proposes a novel location encoder for globally distributed geographic data that combines spherical harmonic basis functions, natively defined on spherical surfaces, with sinusoidal representation networks ({SirenNets}) that can be interpreted as learned Double Fourier Sphere embedding. We systematically evaluate the cross-product of positional embeddings and neural network architectures across various classification and regression benchmarks and synthetic evaluation datasets. In contrast to previous approaches that require the combination of both positional encoding and neural networks to learn meaningful representations, we show that both spherical harmonics and sinusoidal representation networks are competitive on their own but set state-of-the-art performances across tasks when combined. We provide source code at www.github.com/marccoru/locationencoder},
  number     = {{arXiv}:2310.06743},
  publisher  = {{arXiv}},
  author     = {Rußwurm, Marc and Klemmer, Konstantin and Rolf, Esther and Zbinden, Robin and Tuia, Devis},
  urldate    = {2023-12-21},
  date       = {2023-10-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.06743 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2023_Geographic Location Encoding with Spherical Harmonics and Sinusoidal_Rußwurm et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\6ARQ6R8S\\2023_Geographic Location Encoding with Spherical Harmonics and Sinusoidal_Rußwurm et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\X2FXJZYN\\2310.html:text/html}
}

@inproceedings{shao_pre-training_2022,
  title      = {Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2206.09113},
  doi        = {10.1145/3534678.3539396},
  abstract   = {Multivariate Time Series ({MTS}) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks ({STGNNs}) have become increasingly popular {MTS} forecasting methods. {STGNNs} jointly model the spatial and temporal patterns of {MTS} through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most {STGNNs} only consider short-term historical {MTS} data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical {MTS} data. To address this issue, we propose a novel framework, in which {STGNN} is Enhanced by a scalable time series Pre-training model ({STEP}). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to {STGNNs} and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream {STGNNs}, and our pre-training model aptly captures temporal patterns.},
  pages      = {1567--1577},
  booktitle  = {Proceedings of the 28th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
  author     = {Shao, Zezhi and Zhang, Zhao and Wang, Fei and Xu, Yongjun},
  urldate    = {2023-10-24},
  date       = {2022-08-14},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2206.09113 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, /unread},
  file       = {2022_Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate_Shao et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2022_Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate_Shao et al.pdf:application/pdf;2022_Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate_Shao et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\9JC4NRMS\\2022_Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate_Shao et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4ZFLGJA8\\2206.html:text/html}
}

@misc{shao_spatial-temporal_2022,
  title      = {Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2208.05233},
  doi        = {10.48550/arXiv.2208.05233},
  shorttitle = {Spatial-Temporal Identity},
  abstract   = {Multivariate Time Series ({MTS}) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks ({STGNNs}) have become increasingly popular {MTS} forecasting methods due to their state-of-the-art performance. However, recent works are becoming more sophisticated with limited performance improvements. This phenomenon motivates us to explore the critical factors of {MTS} forecasting and design a model that is as powerful as {STGNNs}, but more concise and efficient. In this paper, we identify the indistinguishability of samples in both spatial and temporal dimensions as a key bottleneck, and propose a simple yet effective baseline for {MTS} forecasting by attaching Spatial and Temporal {IDentity} information ({STID}), which achieves the best performance and efficiency simultaneously based on simple Multi-Layer Perceptrons ({MLPs}). These results suggest that we can design efficient and effective models as long as they solve the indistinguishability of samples, without being limited to {STGNNs}.},
  number     = {{arXiv}:2208.05233},
  publisher  = {{arXiv}},
  author     = {Shao, Zezhi and Zhang, Zhao and Wang, Fei and Wei, Wei and Xu, Yongjun},
  urldate    = {2024-01-08},
  date       = {2022-08-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2208.05233 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, ⭐⭐⭐⭐⭐},
  file       = {2022_Spatial-Temporal Identity_Shao et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\6ITA9H55\\2022_Spatial-Temporal Identity_Shao et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LD2TC943\\2208.html:text/html}
}

@misc{shen_non-autoregressive_2023,
  title      = {Non-autoregressive Conditional Diffusion Models for Time Series Prediction},
  url        = {http://arxiv.org/abs/2306.05043},
  doi        = {10.48550/arXiv.2306.05043},
  abstract   = {Recently, denoising diffusion models have led to significant breakthroughs in the generation of images, audio and text. However, it is still an open question on how to adapt their strong modeling ability to model time series. In this paper, we propose {TimeDiff}, a non-autoregressive diffusion model that achieves high-quality time series prediction with the introduction of two novel conditioning mechanisms: future mixup and autoregressive initialization. Similar to teacher forcing, future mixup allows parts of the ground-truth future predictions for conditioning, while autoregressive initialization helps better initialize the model with basic time series patterns such as short-term trends. Extensive experiments are performed on nine real-world datasets. Results show that {TimeDiff} consistently outperforms existing time series diffusion models, and also achieves the best overall performance across a variety of the existing strong baselines (including transformers and {FiLM}).},
  number     = {{arXiv}:2306.05043},
  publisher  = {{arXiv}},
  author     = {Shen, Lifeng and Kwok, James},
  urldate    = {2024-05-09},
  date       = {2023-06-08},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2306.05043 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2023_Non-autoregressive Conditional Diffusion Models for Time Series Prediction_Shen_Kwok.pdf:C\:\\Users\\yanha\\Zotero\\storage\\ER7N58FW\\2023_Non-autoregressive Conditional Diffusion Models for Time Series Prediction_Shen_Kwok.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LSCW49FU\\2306.html:text/html}
}

@inproceedings{shi_open-transmind_2023,
  title      = {Open-{TransMind}: A New Baseline and Benchmark for 1st Foundation Model Challenge of Intelligent Transportation},
  url        = {https://ieeexplore.ieee.org/document/10208883},
  doi        = {10.1109/CVPRW59228.2023.00673},
  shorttitle = {Open-{TransMind}},
  abstract   = {With the continuous improvement of computing power and deep learning algorithms in recent years, the foundation model has grown in popularity. Because of its powerful capabilities and excellent performance, this technology is being adopted and applied by an increasing number of industries. In the intelligent transportation industry, artificial intelligence faces the following typical challenges: few shots, poor generalization, and a lack of multi-modal techniques. Foundation model technology can significantly alleviate the aforementioned issues. To address these, we designed the 1st Foundation Model Challenge, with the goal of increasing the popularity of foundation model technology in traffic scenarios and promoting the rapid development of the intelligent transportation industry. The challenge is divided into two tracks: all-in-one and cross-modal image retrieval. Furthermore, we provide a new baseline and benchmark for the two tracks, called Open-{TransMind}. According to our knowledge, Open-{TransMind} is the first open-source transportation foundation model with multitask and multi-modal capabilities. Simultaneously, Open-{TransMind} can achieve state-of-the-art performance on detection, classification, and segmentation datasets of traffic scenarios. Our source code is available at https://github.com/Traffic-X/Open-{TransMind}.},
  eventtitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
  pages      = {6328--6335},
  booktitle  = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
  author     = {Shi, Yifeng and Lv, Feng and Wang, Xinliang and Xia, Chunlong and Li, Shaojie and Yang, Shujie and Xi, Teng and Zhang, Gang},
  urldate    = {2023-12-08},
  date       = {2023-06},
  langid     = {english},
  note       = {{ISSN}: 2160-7516},
  keywords   = {/reading, /unread},
  file       = {2023_Open-TransMind_Shi et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Open-TransMind_Shi et al.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\yanha\\Zotero\\storage\\U8QSZWYA\\10208883.html:text/html}
}

@article{singh_augmenting_2023,
  title        = {Augmenting interpretable models with large language models during training},
  volume       = {14},
  rights       = {2023 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-023-43713-1},
  doi          = {10.1038/s41467-023-43713-1},
  abstract     = {Recent large language models ({LLMs}), such as {ChatGPT}, have demonstrated remarkable prediction performance for a growing array of tasks. However, their proliferation into high-stakes domains and compute-limited settings has created a burgeoning need for interpretability and efficiency. We address this need by proposing Aug-imodels, a framework for leveraging the knowledge learned by {LLMs} to build extremely efficient and interpretable prediction models. Aug-imodels use {LLMs} during fitting but not during inference, allowing complete transparency and often a speed/memory improvement of greater than 1000x for inference compared to {LLMs}. We explore two instantiations of Aug-imodels in natural-language processing: Aug-Linear, which augments a linear model with decoupled embeddings from an {LLM} and Aug-Tree, which augments a decision tree with {LLM} feature expansions. Across a variety of text-classification datasets, both outperform their non-augmented, interpretable counterparts. Aug-Linear can even outperform much larger models, e.g. a 6-billion parameter {GPT}-J model, despite having 10,000x fewer parameters and being fully transparent. We further explore Aug-imodels in a natural-language {fMRI} study, where they generate interesting interpretations from scientific data.},
  pages        = {7913},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Singh, Chandan and Askari, Armin and Caruana, Rich and Gao, Jianfeng},
  urldate      = {2024-04-09},
  date         = {2023-11-30},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group},
  keywords     = {/reading, Machine learning, Neural encoding, Statistical methods},
  file         = {2023_Augmenting interpretable models with large language models during training_Singh et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\JKVIHIZG\\2023_Augmenting interpretable models with large language models during training_Singh et al.pdf:application/pdf}
}

@misc{spathis_first_2023,
  title      = {The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models},
  url        = {http://arxiv.org/abs/2309.06236},
  doi        = {10.48550/arXiv.2309.06236},
  shorttitle = {The first step is the hardest},
  abstract   = {Large Language Models ({LLMs}) have demonstrated remarkable generalization across diverse tasks, leading individuals to increasingly use them as personal assistants and universal computing engines. Nevertheless, a notable obstacle emerges when feeding numerical/temporal data into these models, such as data sourced from wearables or electronic health records. {LLMs} employ tokenizers in their input that break down text into smaller units. However, tokenizers are not designed to represent numerical values and might struggle to understand repetitive patterns and context, treating consecutive values as separate tokens and disregarding their temporal relationships. Here, we discuss recent works that employ {LLMs} for human-centric tasks such as in mobile health sensing and present a case study showing that popular {LLMs} tokenize temporal data incorrectly. To address that, we highlight potential solutions such as prompt tuning with lightweight embedding layers as well as multimodal adapters, that can help bridge this "modality gap". While the capability of language models to generalize to other modalities with minimal or no finetuning is exciting, this paper underscores the fact that their outputs cannot be meaningful if they stumble over input nuances.},
  number     = {{arXiv}:2309.06236},
  publisher  = {{arXiv}},
  author     = {Spathis, Dimitris and Kawsar, Fahim},
  urldate    = {2023-10-25},
  date       = {2023-09-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2309.06236 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning, Computer Science - Computation and Language, /unread},
  file       = {2023_The first step is the hardest_Spathis_Kawsar.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_The first step is the hardest_Spathis_Kawsar.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JJCKEJJA\\2309.html:text/html}
}

@misc{su_large_2024,
  title      = {Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review},
  url        = {http://arxiv.org/abs/2402.10350},
  doi        = {10.48550/arXiv.2402.10350},
  shorttitle = {Large Language Models for Forecasting and Anomaly Detection},
  abstract   = {This systematic literature review comprehensively examines the application of Large Language Models ({LLMs}) in forecasting and anomaly detection, highlighting the current state of research, inherent challenges, and prospective future directions. {LLMs} have demonstrated significant potential in parsing and analyzing extensive datasets to identify patterns, predict future events, and detect anomalous behavior across various domains. However, this review identifies several critical challenges that impede their broader adoption and effectiveness, including the reliance on vast historical datasets, issues with generalizability across different contexts, the phenomenon of model hallucinations, limitations within the models' knowledge boundaries, and the substantial computational resources required. Through detailed analysis, this review discusses potential solutions and strategies to overcome these obstacles, such as integrating multimodal data, advancements in learning methodologies, and emphasizing model explainability and computational efficiency. Moreover, this review outlines critical trends that are likely to shape the evolution of {LLMs} in these fields, including the push toward real-time processing, the importance of sustainable modeling practices, and the value of interdisciplinary collaboration. Conclusively, this review underscores the transformative impact {LLMs} could have on forecasting and anomaly detection while emphasizing the need for continuous innovation, ethical considerations, and practical solutions to realize their full potential.},
  number     = {{arXiv}:2402.10350},
  publisher  = {{arXiv}},
  author     = {Su, Jing and Jiang, Chufeng and Jin, Xin and Qiao, Yuxin and Xiao, Tingsong and Ma, Hongda and Wei, Rong and Jing, Zhi and Xu, Jiajun and Lin, Junhong},
  urldate    = {2024-04-02},
  date       = {2024-02-15},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.10350 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2024_Large Language Models for Forecasting and Anomaly Detection_Su et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\EKMDRP4P\\2024_Large Language Models for Forecasting and Anomaly Detection_Su et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\WDARU4WR\\2402.html:text/html}
}

@misc{su_tablegpt2_2024,
  title      = {{TableGPT}2: A Large Multimodal Model with Tabular Data Integration},
  url        = {http://arxiv.org/abs/2411.02059},
  doi        = {10.48550/arXiv.2411.02059},
  shorttitle = {{TableGPT}2},
  abstract   = {The emergence of models like {GPTs}, Claude, {LLaMA}, and Qwen has reshaped {AI} applications, presenting vast new opportunities across industries. Yet, the integration of tabular data remains notably underdeveloped, despite its foundational role in numerous real-world domains. This gap is critical for three main reasons. First, database or data warehouse data integration is essential for advanced applications; second, the vast and largely untapped resource of tabular data offers immense potential for analysis; and third, the business intelligence domain specifically demands adaptable, precise solutions that many current {LLMs} may struggle to provide. In response, we introduce {TableGPT}2, a model rigorously pre-trained and fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output tuples, a scale of table-related data unprecedented in prior research. This extensive training enables {TableGPT}2 to excel in table-centric tasks while maintaining strong general language and coding abilities. One of {TableGPT}2's key innovations is its novel table encoder, specifically designed to capture schema-level and cell-level information. This encoder strengthens the model's ability to handle ambiguous queries, missing column names, and irregular tables commonly encountered in real-world applications. Similar to visual language models, this pioneering approach integrates with the decoder to form a robust large multimodal model. We believe the results are compelling: over 23 benchmarking metrics, {TableGPT}2 achieves an average performance improvement of 35.20\% in the 7B model and 49.32\% in the 72B model over prior benchmark-neutral {LLMs}, with robust general-purpose capabilities intact.},
  number     = {{arXiv}:2411.02059},
  publisher  = {{arXiv}},
  author     = {Su, Aofeng and Wang, Aowen and Ye, Chao and Zhou, Chen and Zhang, Ga and Chen, Gang and Zhu, Guangcheng and Wang, Haobo and Xu, Haokai and Chen, Hao and Li, Haoze and Lan, Haoxuan and Tian, Jiaming and Yuan, Jing and Zhao, Junbo and Zhou, Junlin and Shou, Kaizhe and Zha, Liangyu and Long, Lin and Li, Liyao and Wu, Pengzuo and Zhang, Qi and Huang, Qingyi and Yang, Saisai and Zhang, Tao and Ye, Wentao and Zhu, Wufang and Hu, Xiaomeng and Gu, Xijun and Sun, Xinjie and Li, Xiang and Yang, Yuhang and Xiao, Zhiqing},
  urldate    = {2025-02-24},
  date       = {2024-11-07},
  eprinttype = {arxiv},
  eprint     = {2411.02059 [cs]},
  note       = {{TLDR}: This work introduces {TableGPT}2, a model rigorously pre-trained and fine-tuned with over 593.8K tables and 2.36M high-quality query-table-output tuples, a scale of table-related data unprecedented in prior research, which enables {TableGPT}2 to excel in table-centric tasks while maintaining strong general language and coding abilities.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Databases},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\XM8WSBP6\\Su 等 - 2024 - TableGPT2 A Large Multimodal Model with Tabular Data Integration.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\76GQWF3F\\2411.html:text/html}
}

@misc{sun_test_2023,
  title      = {{TEST}: Text Prototype Aligned Embedding to Activate {LLM}'s Ability for Time Series},
  url        = {http://arxiv.org/abs/2308.08241},
  doi        = {10.48550/arXiv.2308.08241},
  shorttitle = {{TEST}},
  abstract   = {This work summarizes two strategies for completing time-series ({TS}) tasks using today's language model ({LLM}): {LLM}-for-{TS}, design and train a fundamental large model for {TS} data; {TS}-for-{LLM}, enable the pre-trained {LLM} to handle {TS} data. Considering the insufficient data accumulation, limited resources, and semantic context requirements, this work focuses on {TS}-for-{LLM} methods, where we aim to activate {LLM}'s ability for {TS} data by designing a {TS} embedding method suitable for {LLM}. The proposed method is named {TEST}. It first tokenizes {TS}, builds an encoder to embed them by instance-wise, feature-wise, and text-prototype-aligned contrast, and then creates prompts to make {LLM} more open to embeddings, and finally implements {TS} tasks. Experiments are carried out on {TS} classification and forecasting tasks using 8 {LLMs} with different structures and sizes. Although its results cannot significantly outperform the current {SOTA} models customized for {TS} tasks, by treating {LLM} as the pattern machine, it can endow {LLM}'s ability to process {TS} data without compromising the language ability. This paper is intended to serve as a foundational work that will inspire further research.},
  number     = {{arXiv}:2308.08241},
  publisher  = {{arXiv}},
  author     = {Sun, Chenxi and Li, Yaliang and Li, Hongyan and Hong, Shenda},
  urldate    = {2023-10-25},
  date       = {2023-08-16},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2308.08241 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, /unread},
  file       = {2023_TEST_Sun et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_TEST_Sun et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\G3MBT5Y5\\2308.html:text/html}
}

@misc{talukder_totem_2024,
  title      = {{TOTEM}: {TOkenized} Time Series {EMbeddings} for General Time Series Analysis},
  url        = {http://arxiv.org/abs/2402.16412},
  doi        = {10.48550/arXiv.2402.16412},
  shorttitle = {{TOTEM}},
  abstract   = {The field of general time series analysis has recently begun to explore unified modeling, where a common architectural backbone can be retrained on a specific task for a specific dataset. In this work, we approach unification from a complementary vantage point: unification across tasks and domains. To this end, we explore the impact of discrete, learnt, time series data representations that enable generalist, cross-domain training. Our method, {TOTEM}, or {TOkenized} Time Series {EMbeddings}, proposes a simple tokenizer architecture that embeds time series data from varying domains using a discrete vectorized representation learned in a self-supervised manner. {TOTEM} works across multiple tasks and domains with minimal to no tuning. We study the efficacy of {TOTEM} with an extensive evaluation on 17 real world time series datasets across 3 tasks. We evaluate both the specialist (i.e., training a model on each domain) and generalist (i.e., training a single model on many domains) settings, and show that {TOTEM} matches or outperforms previous best methods on several popular benchmarks. The code can be found at: https://github.com/{SaberaTalukder}/{TOTEM}.},
  number     = {{arXiv}:2402.16412},
  publisher  = {{arXiv}},
  author     = {Talukder, Sabera and Yue, Yisong and Gkioxari, Georgia},
  urldate    = {2024-04-12},
  date       = {2024-02-26},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.16412 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_TOTEM_Talukder et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\MCPT4RY2\\2024_TOTEM_Talukder et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\7I2RXSIR\\2402.html:text/html}
}

@misc{tan_are_2024,
  title      = {Are Language Models Actually Useful for Time Series Forecasting?},
  url        = {http://arxiv.org/abs/2406.16964},
  doi        = {10.48550/arXiv.2406.16964},
  abstract   = {Large language models ({LLMs}) are being applied to time series tasks, particularly time series forecasting. However, are language models actually useful for time series? After a series of ablation studies on three recent and popular {LLM}-based time series forecasting methods, we find that removing the {LLM} component or replacing it with a basic attention layer does not degrade the forecasting results -- in most cases the results even improved. We also find that despite their significant computational cost, pretrained {LLMs} do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and reveal that patching and attention structures perform similarly to state-of-the-art {LLM}-based forecasters.},
  number     = {{arXiv}:2406.16964},
  publisher  = {{arXiv}},
  author     = {Tan, Mingtian and Merrill, Mike A. and Gupta, Vinayak and Althoff, Tim and Hartvigsen, Thomas},
  urldate    = {2024-08-06},
  date       = {2024-06-21},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.16964 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_Are Language Models Actually Useful for Time Series Forecasting_Tan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\B4Y5ZJ2W\\2024_Are Language Models Actually Useful for Time Series Forecasting_Tan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LQSM5UIY\\2406.html:text/html}
}

@misc{tan_openstl_2023,
  title      = {{OpenSTL}: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning},
  url        = {http://arxiv.org/abs/2306.11249},
  doi        = {10.48550/arXiv.2306.11249},
  shorttitle = {{OpenSTL}},
  abstract   = {Spatio-temporal predictive learning is a learning paradigm that enables models to learn spatial and temporal patterns by predicting future frames from given past frames in an unsupervised manner. Despite remarkable progress in recent years, a lack of systematic understanding persists due to the diverse settings, complex implementation, and difficult reproducibility. Without standardization, comparisons can be unfair and insights inconclusive. To address this dilemma, we propose {OpenSTL}, a comprehensive benchmark for spatio-temporal predictive learning that categorizes prevalent approaches into recurrent-based and recurrent-free models. {OpenSTL} provides a modular and extensible framework implementing various state-of-the-art methods. We conduct standard evaluations on datasets across various domains, including synthetic moving object trajectory, human motion, driving scenes, traffic flow and weather forecasting. Based on our observations, we provide a detailed analysis of how model architecture and dataset properties affect spatio-temporal predictive learning performance. Surprisingly, we find that recurrent-free models achieve a good balance between efficiency and performance than recurrent models. Thus, we further extend the common {MetaFormers} to boost recurrent-free spatial-temporal predictive learning. We open-source the code and models at https://github.com/chengtan9907/{OpenSTL}.},
  number     = {{arXiv}:2306.11249},
  publisher  = {{arXiv}},
  author     = {Tan, Cheng and Li, Siyuan and Gao, Zhangyang and Guan, Wenfei and Wang, Zedong and Liu, Zicheng and Wu, Lirong and Li, Stan Z.},
  urldate    = {2024-04-16},
  date       = {2023-10-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2306.11249 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, /unread, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2023_OpenSTL_Tan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\KHCQDV2G\\2023_OpenSTL_Tan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\INJ7X6D9\\2306.html:text/html}
}

@misc{tan_revisiting_2023,
  title      = {Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A Unified View},
  url        = {http://arxiv.org/abs/2310.05829},
  abstract   = {Spatio-temporal predictive learning plays a crucial role in self-supervised learning, with wide-ranging applications across a diverse range of fields. Previous approaches for temporal modeling fall into two categories: recurrent-based and recurrent-free methods. The former, while meticulously processing frames one by one, neglect short-term spatio-temporal information redundancies, leading to inefficiencies. The latter naively stack frames sequentially, overlooking the inherent temporal dependencies. In this paper, we re-examine the two dominant temporal modeling approaches within the realm of spatio-temporal predictive learning, offering a unified perspective. Building upon this analysis, we introduce {USTEP} (Unified Spatio-{TEmporal} Predictive learning), an innovative framework that reconciles the recurrent-based and recurrent-free methods by integrating both micro-temporal and macro-temporal scales. Extensive experiments on a wide range of spatio-temporal predictive learning demonstrate that {USTEP} achieves significant improvements over existing temporal modeling approaches, thereby establishing it as a robust solution for a wide range of spatio-temporal applications.},
  number     = {{arXiv}:2310.05829},
  publisher  = {{arXiv}},
  author     = {Tan, Cheng and Wang, Jue and Gao, Zhangyang and Li, Siyuan and Wu, Lirong and Xia, Jun and Li, Stan Z.},
  urldate    = {2023-12-13},
  date       = {2023-10-09},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.05829 [cs]},
  keywords   = {/reading, /unread, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2023_Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A_Tan et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Revisiting the Temporal Modeling in Spatio-Temporal Predictive Learning under A_Tan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\INZQD3JN\\2310.html:text/html}
}

@misc{tang_graphgpt_2023,
  title      = {{GraphGPT}: Graph Instruction Tuning for Large Language Models},
  url        = {http://arxiv.org/abs/2310.13023},
  doi        = {10.48550/arXiv.2310.13023},
  shorttitle = {{GraphGPT}},
  abstract   = {Graph Neural Networks ({GNNs}) have advanced graph structure understanding via recursive information exchange and aggregation among graph nodes. To improve model robustness, self-supervised learning ({SSL}) has emerged as a promising approach for data augmentation. However, existing methods for generating pre-trained graph embeddings often rely on fine-tuning with specific downstream task labels, which limits their usability in scenarios where labeled data is scarce or unavailable. To address this, our research focuses on advancing the generalization capabilities of graph models in challenging zero-shot learning scenarios. Inspired by the success of large language models ({LLMs}), we aim to develop a graph-oriented {LLM} that can achieve high generalization across diverse downstream datasets and tasks, even without any information available from the downstream graph data. In this work, we present the {GraphGPT} framework that aligns {LLMs} with graph structural knowledge with a graph instruction tuning paradigm. Our framework incorporates a text-graph grounding component to establish a connection between textual information and graph structures. Additionally, we propose a dual-stage instruction tuning paradigm, accompanied by a lightweight graph-text alignment projector. This paradigm explores self-supervised graph structural signals and task-specific graph instructions, to guide {LLMs} in understanding complex graph structures and improving their adaptability across different downstream tasks. Our framework is evaluated on supervised and zero-shot graph learning tasks, demonstrating superior generalization and outperforming state-of-the-art baselines.},
  number     = {{arXiv}:2310.13023},
  publisher  = {{arXiv}},
  author     = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  urldate    = {2024-05-07},
  date       = {2023-12-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.13023 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {2023_GraphGPT_Tang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\ZKJVNW8P\\2023_GraphGPT_Tang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\6359PK2S\\2310.html:text/html}
}

@misc{tang_llm-ps_2025,
  title      = {{LLM}-{PS}: Empowering Large Language Models for Time Series Forecasting with Temporal Patterns and Semantics},
  url        = {http://arxiv.org/abs/2503.09656},
  doi        = {10.48550/arXiv.2503.09656},
  shorttitle = {{LLM}-{PS}},
  abstract   = {Time Series Forecasting ({TSF}) is critical in many real-world domains like financial planning and health monitoring. Recent studies have revealed that Large Language Models ({LLMs}), with their powerful in-contextual modeling capabilities, hold significant potential for {TSF}. However, existing {LLM}-based methods usually perform suboptimally because they neglect the inherent characteristics of time series data. Unlike the textual data used in {LLM} pre-training, the time series data is semantically sparse and comprises distinctive temporal patterns. To address this problem, we propose {LLM}-{PS} to empower the {LLM} for {TSF} by learning the fundamental {\textbackslash}textit\{Patterns\} and meaningful {\textbackslash}textit\{Semantics\} from time series data. Our {LLM}-{PS} incorporates a new multi-scale convolutional neural network adept at capturing both short-term fluctuations and long-term trends within the time series. Meanwhile, we introduce a time-to-text module for extracting valuable semantics across continuous time intervals rather than isolated time points. By integrating these patterns and semantics, {LLM}-{PS} effectively models temporal dependencies, enabling a deep comprehension of time series and delivering accurate forecasts. Intensive experimental results demonstrate that {LLM}-{PS} achieves state-of-the-art performance in both short- and long-term forecasting tasks, as well as in few- and zero-shot settings.},
  number     = {{arXiv}:2503.09656},
  publisher  = {{arXiv}},
  author     = {Tang, Jialiang and Chen, Shuo and Gong, Chen and Zhang, Jing and Tao, Dacheng},
  urldate    = {2025-03-25},
  date       = {2025-03-12},
  eprinttype = {arxiv},
  eprint     = {2503.09656 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\XQRD86AQ\\Tang 等 - 2025 - LLM-PS Empowering Large Language Models for Time Series Forecasting with Temporal Patterns and Sema.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\VZGYBHJI\\2503.html:text/html}
}

@misc{trabelsi_time_2025,
  title      = {Time Series Language Model for Descriptive Caption Generation},
  url        = {http://arxiv.org/abs/2501.01832},
  doi        = {10.48550/arXiv.2501.01832},
  abstract   = {The automatic generation of representative natural language descriptions for observable patterns in time series data enhances interpretability, simplifies analysis and increases cross-domain utility of temporal data. While pre-trained foundation models have made considerable progress in natural language processing ({NLP}) and computer vision ({CV}), their application to time series analysis has been hindered by data scarcity. Although several large language model ({LLM})-based methods have been proposed for time series forecasting, time series captioning is under-explored in the context of {LLMs}. In this paper, we introduce {TSLM}, a novel time series language model designed specifically for time series captioning. {TSLM} operates as an encoder-decoder model, leveraging both text prompts and time series data representations to capture subtle temporal patterns across multiple phases and generate precise textual descriptions of time series inputs. {TSLM} addresses the data scarcity problem in time series captioning by first leveraging an in-context prompting synthetic data generation, and second denoising the generated data via a novel cross-modal dense retrieval scoring applied to time series-caption pairs. Experimental findings on various time series captioning datasets demonstrate that {TSLM} outperforms existing state-of-the-art approaches from multiple data modalities by a significant margin.},
  number     = {{arXiv}:2501.01832},
  publisher  = {{arXiv}},
  author     = {Trabelsi, Mohamed and Boyd, Aidan and Cao, Jin and Uzunalioglu, Huseyin},
  urldate    = {2025-03-30},
  date       = {2025-01-03},
  eprinttype = {arxiv},
  eprint     = {2501.01832 [cs]},
  note       = {{TLDR}: Experimental findings on various time series captioning datasets demonstrate that {TSLM} outperforms existing state-of-the-art approaches from multiple data modalities by a significant margin.},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language, ⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\49UBFUYV\\Trabelsi 等 - 2025 - Time Series Language Model for Descriptive Caption Generation.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4H9Z8V9V\\2501.html:text/html}
}

@misc{trockman_patches_2022,
  title      = {Patches Are All You Need?},
  url        = {http://arxiv.org/abs/2201.09792},
  doi        = {10.48550/arXiv.2201.09792},
  abstract   = {Although convolutional networks have been the dominant architecture for vision tasks for many years, recent experiments have shown that Transformer-based models, most notably the Vision Transformer ({ViT}), may exceed their performance in some settings. However, due to the quadratic runtime of the self-attention layers in Transformers, {ViTs} require the use of patch embeddings, which group together small regions of the image into single input features, in order to be applied to larger image sizes. This raises a question: Is the performance of {ViTs} due to the inherently-more-powerful Transformer architecture, or is it at least partly due to using patches as the input representation? In this paper, we present some evidence for the latter: specifically, we propose the {ConvMixer}, an extremely simple model that is similar in spirit to the {ViT} and the even-more-basic {MLP}-Mixer in that it operates directly on patches as input, separates the mixing of spatial and channel dimensions, and maintains equal size and resolution throughout the network. In contrast, however, the {ConvMixer} uses only standard convolutions to achieve the mixing steps. Despite its simplicity, we show that the {ConvMixer} outperforms the {ViT}, {MLP}-Mixer, and some of their variants for similar parameter counts and data set sizes, in addition to outperforming classical vision models such as the {ResNet}. Our code is available at https://github.com/locuslab/convmixer.},
  number     = {{arXiv}:2201.09792},
  publisher  = {{arXiv}},
  author     = {Trockman, Asher and Kolter, J. Zico},
  urldate    = {2024-01-17},
  date       = {2022-01-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2201.09792 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2022_Patches Are All You Need_Trockman_Kolter.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GW9UUG4P\\2022_Patches Are All You Need_Trockman_Kolter.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\8WYCLYB2\\2201.html:text/html}
}

@misc{turtel_llms_2025,
  title      = {{LLMs} Can Teach Themselves to Better Predict the Future},
  url        = {http://arxiv.org/abs/2502.05253},
  doi        = {10.48550/arXiv.2502.05253},
  abstract   = {We present an outcome-driven fine-tuning framework that enhances the forecasting capabilities of large language models ({LLMs}) without relying on human-curated reasoning samples. Our method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date. We then rank pairs of these reasoning traces by their distance to the actual outcomes before fine-tuning the model via Direct Preference Optimization ({DPO}). On a separate test set, our approach increases prediction accuracy of Phi-4 14B and {DeepSeek}-R1 14B by between 7--10{\textbackslash}\% over a base model and a {DPO} fine-tuned control model with randomized labels, bringing them on par with forecasting capabilities of much larger frontier models like {GPT}-4o.},
  number     = {{arXiv}:2502.05253},
  publisher  = {{arXiv}},
  author     = {Turtel, Benjamin and Franklin, Danny and Schoenegger, Philipp},
  urldate    = {2025-02-25},
  date       = {2025-02-07},
  eprinttype = {arxiv},
  eprint     = {2502.05253 [cs]},
  note       = {{TLDR}: This method leverages model self-play to generate pairs of diverse reasoning trajectories and probabilistic forecasts for a set of diverse questions that resolve after the models' knowledge cutoff date, bringing them on par with forecasting capabilities of much larger frontier models like {GPT}-4o.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\GXZGMQHR\\Turtel 等 - 2025 - LLMs Can Teach Themselves to Better Predict the Future.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\QYK78LNW\\2502.html:text/html}
}

@article{urfan_deep_2024,
  title        = {The Deep Learning-Crop Platform ({DL}-{CRoP}): For Species-Level Identification and Nutrient Status of Agricultural Crops},
  volume       = {7},
  url          = {https://spj.science.org/doi/10.34133/research.0491},
  doi          = {10.34133/research.0491},
  shorttitle   = {The Deep Learning-Crop Platform ({DL}-{CRoP})},
  abstract     = {Precise and timely detection of a crop’s nutrient requirement will play a crucial role in assuring optimum plant growth and crop yield. The present study introduces a reliable deep learning platform called “Deep Learning-Crop Platform” ({DL}-{CRoP}) for the identification of some commercially grown plants and their nutrient requirements using leaf, stem, and root images using a convolutional neural network ({CNN}). It extracts intrinsic feature patterns through hierarchical mapping and provides remarkable outcomes in identification tasks. The {DL}-{CRoP} platform is trained on the plant image dataset, namely, Jammu University-Botany Image Database ({JU}-{BID}), available at https://github.com/urfanbutt. The findings demonstrate implementation of {DL}-{CRoP}—cases A (uses shoot images) and B (uses leaf images) for species identification for Solanum lycopersicum (tomato), Vigna radiata (Vigna), and Zea mays (maize), and cases C (uses leaf images) and D (uses root images) for diagnosis of nitrogen deficiency in maize. The platform achieved a higher rate of accuracy at 80–20, 70–30, and 60–40 splits for all the case studies, compared with established algorithms such as random forest, K-nearest neighbor, support vector machine, {AdaBoost}, and naïve Bayes. It provides a higher accuracy rate in classification parameters like recall, precision, and F1 score for cases A (90.45\%), B (100\%), and C (93.21), while a medium-level accuracy of 68.54\% for case D. To further improve the accuracy of the platform in case study C, the {CNN} was modified including a multi-head attention ({MHA}) block. It resulted in the enhancement of the accuracy of classifying the nitrogen deficiency above 95\%. The platform could play an important role in evaluating the health status of crop plants along with a role in precise identification of species. It may be used as a better module for precision crop cultivation under limited nutrient conditions.},
  pages        = {0491},
  journaltitle = {Research},
  author       = {Urfan, Mohammad and Rajput, Prakriti and Mahajan, Palak and Sharma, Shubham and Hakla, Haroon Rashid and Kour, Verasis and Khajuria, Bhubneshwari and Chowdhary, Rehana and Lehana, Parveen Kumar and Karlupia, Namrata and Abrol, Pawanesh and Tran, Lam Son Phan and Choudhary, Sikander {PAL}},
  urldate      = {2025-04-15},
  date         = {2024-10-04},
  note         = {Publisher: American Association for the Advancement of Science
                  {TLDR}: The {DL}-{CRoP} platform could play an important role in evaluating the health status of crop plants along with a role in precise identification of species and may be used as a better module for precision crop cultivation under limited nutrient conditions.},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\6KL38LH4\\Urfan 等 - 2024 - The Deep Learning-Crop Platform (DL-CRoP) For Species-Level Identification and Nutrient Status of A.pdf:application/pdf}
}

@misc{wang_building_2023,
  title      = {Building Transportation Foundation Model via Generative Graph Transformer},
  url        = {http://arxiv.org/abs/2305.14826},
  abstract   = {Efficient traffic management is crucial for maintaining urban mobility, especially in densely populated areas where congestion, accidents, and delays can lead to frustrating and expensive commutes. However, existing prediction methods face challenges in terms of optimizing a single objective and understanding the complex composition of the transportation system. Moreover, they lack the ability to understand the macroscopic system and cannot efficiently utilize big data. In this paper, we propose a novel approach, Transportation Foundation Model ({TFM}), which integrates the principles of traffic simulation into traffic prediction. {TFM} uses graph structures and dynamic graph generation algorithms to capture the participatory behavior and interaction of transportation system actors. This data-driven and model-free simulation method addresses the challenges faced by traditional systems in terms of structural complexity and model accuracy and provides a foundation for solving complex transportation problems with real data. The proposed approach shows promising results in accurately predicting traffic outcomes in an urban transportation setting.},
  number     = {{arXiv}:2305.14826},
  publisher  = {{arXiv}},
  author     = {Wang, Xuhong and Wang, Ding and Chen, Liang and Lin, Yilun},
  urldate    = {2023-10-30},
  date       = {2023-05-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2305.14826 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {2023_Building Transportation Foundation Model via Generative Graph Transformer_Wang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Building Transportation Foundation Model via Generative Graph Transformer_Wang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\EFQLCFV9\\2305.html:text/html}
}

@misc{wang_chattime_2024,
  title      = {{ChatTime}: A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data},
  url        = {http://arxiv.org/abs/2412.11376},
  doi        = {10.48550/arXiv.2412.11376},
  shorttitle = {{ChatTime}},
  abstract   = {Human experts typically integrate numerical and textual multimodal information to analyze time series. However, most traditional deep learning predictors rely solely on unimodal numerical data, using a fixed-length window for training and prediction on a single dataset, and cannot adapt to different scenarios. The powered pre-trained large language model has introduced new opportunities for time series analysis. Yet, existing methods are either inefficient in training, incapable of handling textual information, or lack zero-shot forecasting capability. In this paper, we innovatively model time series as a foreign language and construct {ChatTime}, a unified framework for time series and text processing. As an out-of-the-box multimodal time series foundation model, {ChatTime} provides zero-shot forecasting capability and supports bimodal input/output for both time series and text. We design a series of experiments to verify the superior performance of {ChatTime} across multiple tasks and scenarios, and create four multimodal datasets to address data gaps. The experimental results demonstrate the potential and utility of {ChatTime}.},
  number     = {{arXiv}:2412.11376},
  publisher  = {{arXiv}},
  author     = {Wang, Chengsen and Qi, Qi and Wang, Jingyu and Sun, Haifeng and Zhuang, Zirui and Wu, Jinming and Zhang, Lei and Liao, Jianxin},
  urldate    = {2024-12-19},
  date       = {2024-12-16},
  eprinttype = {arxiv},
  eprint     = {2412.11376 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\4N7C7SFW\\Wang 等 - 2024 - ChatTime A Unified Multimodal Time Series Foundation Model Bridging Numerical and Textual Data.pdf:application/pdf}
}

@article{wang_easy_2023,
  title        = {Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with {ST}-Curriculum Dropout},
  volume       = {37},
  rights       = {Copyright (c) 2023 Association for the Advancement of Artificial Intelligence},
  issn         = {2374-3468},
  url          = {https://ojs.aaai.org/index.php/AAAI/article/view/25590},
  doi          = {10.1609/aaai.v37i4.25590},
  shorttitle   = {Easy Begun Is Half Done},
  abstract     = {Spatial-temporal ({ST}) graph modeling, such as traffic speed forecasting and taxi demand prediction, is an important task in deep learning area.
                  However, for the nodes in the graph, their {ST} patterns can vary greatly in difficulties for modeling, owning to the heterogeneous nature of {ST} data. We argue that unveiling the nodes to the model in a meaningful order, from easy to complex, can provide performance improvements over traditional training procedure. The idea has its root in Curriculum Learning, which suggests in the early stage of training models can be sensitive to noise and difficult samples. In this paper, we propose {ST}-Curriculum Dropout, a novel and easy-to-implement strategy for spatial-temporal graph modeling. Specifically, we evaluate the learning difficulty of each node in high-level feature space and drop those difficult ones out to ensure the model only needs to handle fundamental {ST} relations at the beginning, before gradually moving to hard ones. Our strategy can be applied to any canonical deep learning architecture without extra trainable parameters, and extensive experiments on a wide range of datasets are conducted to illustrate that, by controlling the difficulty level of {ST} relations as the training progresses, the model is able to capture better representation of the data and thus yields better generalization.},
  pages        = {4668--4675},
  number       = {4},
  journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
  author       = {Wang, Hongjun and Chen, Jiyuan and Pan, Tong and Fan, Zipei and Song, Xuan and Jiang, Renhe and Zhang, Lingyu and Xie, Yi and Wang, Zhongyi and Zhang, Boyuan},
  urldate      = {2023-08-15},
  date         = {2023-06-26},
  langid       = {english},
  note         = {Number: 4},
  keywords     = {/unread, {APP}: Transportation},
  file         = {2023_Easy Begun Is Half Done_Wang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Easy Begun Is Half Done_Wang et al.pdf:application/pdf}
}

@misc{wang_llmfactor_2024,
  title      = {{LLMFactor}: Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction},
  url        = {http://arxiv.org/abs/2406.10811},
  doi        = {10.48550/arXiv.2406.10811},
  shorttitle = {{LLMFactor}},
  abstract   = {Recently, Large Language Models ({LLMs}) have attracted significant attention for their exceptional performance across a broad range of tasks, particularly in text analysis. However, the finance sector presents a distinct challenge due to its dependence on time-series data for complex forecasting tasks. In this study, we introduce a novel framework called {LLMFactor}, which employs Sequential Knowledge-Guided Prompting ({SKGP}) to identify factors that influence stock movements using {LLMs}. Unlike previous methods that relied on keyphrases or sentiment analysis, this approach focuses on extracting factors more directly related to stock market dynamics, providing clear explanations for complex temporal changes. Our framework directs the {LLMs} to create background knowledge through a fill-in-the-blank strategy and then discerns potential factors affecting stock prices from related news. Guided by background knowledge and identified factors, we leverage historical stock prices in textual format to predict stock movement. An extensive evaluation of the {LLMFactor} framework across four benchmark datasets from both the U.S. and Chinese stock markets demonstrates its superiority over existing state-of-the-art methods and its effectiveness in financial time-series forecasting.},
  number     = {{arXiv}:2406.10811},
  publisher  = {{arXiv}},
  author     = {Wang, Meiyun and Izumi, Kiyoshi and Sakaji, Hiroki},
  urldate    = {2025-03-27},
  date       = {2024-06-16},
  eprinttype = {arxiv},
  eprint     = {2406.10811 [cs]},
  note       = {{TLDR}: A novel framework called {LLMFactor}, which employs Sequential Knowledge-Guided Prompting ({SKGP}) to identify factors that influence stock movements using {LLMs}, and demonstrates its superiority over existing state-of-the-art methods and its effectiveness in financial time-series forecasting.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computational Engineering, Finance, and Science},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\URM4PG6L\\Wang 等 - 2024 - LLMFactor Extracting Profitable Factors through Prompts for Explainable Stock Movement Prediction.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LVY49IRQ\\2406.html:text/html}
}

@misc{wang_news_2024,
  title      = {From News to Forecast: Integrating Event Analysis in {LLM}-Based Time Series Forecasting with Reflection},
  url        = {http://arxiv.org/abs/2409.17515},
  doi        = {10.48550/arXiv.2409.17515},
  shorttitle = {From News to Forecast},
  abstract   = {This paper introduces a novel approach that leverages Large Language Models ({LLMs}) and Generative Agents to enhance time series forecasting by reasoning across both text and time series data. With language as a medium, our method adaptively integrates social events into forecasting models, aligning news content with time series fluctuations to provide richer insights. Specifically, we utilize {LLM}-based agents to iteratively filter out irrelevant news and employ human-like reasoning to evaluate predictions. This enables the model to analyze complex events, such as unexpected incidents and shifts in social behavior, and continuously refine the selection logic of news and the robustness of the agent's output. By integrating selected news events with time series data, we fine-tune a pre-trained {LLM} to predict sequences of digits in time series. The results demonstrate significant improvements in forecasting accuracy, suggesting a potential paradigm shift in time series forecasting through the effective utilization of unstructured news data.},
  number     = {{arXiv}:2409.17515},
  publisher  = {{arXiv}},
  author     = {Wang, Xinlei and Feng, Maike and Qiu, Jing and Gu, Jinjin and Zhao, Junhua},
  urldate    = {2025-02-28},
  date       = {2024-10-30},
  eprinttype = {arxiv},
  eprint     = {2409.17515 [cs]},
  note       = {{TLDR}: This paper utilizes {LLM}-based agents to iteratively filter out irrelevant news and employ human-like reasoning to evaluate predictions, which enables the model to analyze complex events, such as unexpected incidents and shifts in social behavior.},
  keywords   = {Computer Science - Artificial Intelligence},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\GVY59KS2\\Wang 等 - 2024 - From News to Forecast Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflecti.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\2RLYAC9X\\2409.html:text/html}
}

@misc{wang_rethinking_2024,
  title      = {Rethinking the Power of Timestamps for Robust Time Series Forecasting: A Global-Local Fusion Perspective},
  url        = {http://arxiv.org/abs/2409.18696},
  doi        = {10.48550/arXiv.2409.18696},
  shorttitle = {Rethinking the Power of Timestamps for Robust Time Series Forecasting},
  abstract   = {Time series forecasting has played a pivotal role across various industries, including finance, transportation, energy, healthcare, and climate. Due to the abundant seasonal information they contain, timestamps possess the potential to offer robust global guidance for forecasting techniques. However, existing works primarily focus on local observations, with timestamps being treated merely as an optional supplement that remains underutilized. When data gathered from the real world is polluted, the absence of global information will damage the robust prediction capability of these algorithms. To address these problems, we propose a novel framework named {GLAFF}. Within this framework, the timestamps are modeled individually to capture the global dependencies. Working as a plugin, {GLAFF} adaptively adjusts the combined weights for global and local information, enabling seamless collaboration with any time series forecasting backbone. Extensive experiments conducted on nine real-world datasets demonstrate that {GLAFF} significantly enhances the average performance of widely used mainstream forecasting models by 12.5\%, surpassing the previous state-of-the-art method by 5.5\%.},
  number     = {{arXiv}:2409.18696},
  publisher  = {{arXiv}},
  author     = {Wang, Chengsen and Qi, Qi and Wang, Jingyu and Sun, Haifeng and Zhuang, Zirui and Wu, Jinming and Liao, Jianxin},
  urldate    = {2024-12-12},
  date       = {2024-11-20},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2409.18696 [cs]},
  note       = {{TLDR}: {GLAFF} adaptively adjusts the combined weights for global and local information, enabling seamless collaboration with any time series forecasting backbone, and significantly enhances the average performance of widely used mainstream forecasting models.},
  keywords   = {Computer Science - Machine Learning, ⭐⭐⭐},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\WNX4RCU9\\Wang 等 - 2024 - Rethinking the Power of Timestamps for Robust Time Series Forecasting A Global-Local Fusion Perspec.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\Q73UUMK2\\2409.html:text/html}
}

@misc{wang_st-mlp_2023,
  title      = {{ST}-{MLP}: A Cascaded Spatio-Temporal Linear Framework with Channel-Independence Strategy for Traffic Forecasting},
  url        = {http://arxiv.org/abs/2308.07496},
  doi        = {10.48550/arXiv.2308.07496},
  shorttitle = {{ST}-{MLP}},
  abstract   = {The criticality of prompt and precise traffic forecasting in optimizing traffic flow management in Intelligent Transportation Systems ({ITS}) has drawn substantial scholarly focus. Spatio-Temporal Graph Neural Networks ({STGNNs}) have been lauded for their adaptability to road graph structures. Yet, current research on {STGNNs} architectures often prioritizes complex designs, leading to elevated computational burdens with only minor enhancements in accuracy. To address this issue, we propose {ST}-{MLP}, a concise spatio-temporal model solely based on cascaded Multi-Layer Perceptron ({MLP}) modules and linear layers. Specifically, we incorporate temporal information, spatial information and predefined graph structure with a successful implementation of the channel-independence strategy - an effective technique in time series forecasting. Empirical results demonstrate that {ST}-{MLP} outperforms state-of-the-art {STGNNs} and other models in terms of accuracy and computational efficiency. Our finding encourages further exploration of more concise and effective neural network architectures in the field of traffic forecasting.},
  number     = {{arXiv}:2308.07496},
  publisher  = {{arXiv}},
  author     = {Wang, Zepu and Nie, Yuqi and Sun, Peng and Nguyen, Nam H. and Mulvey, John and Poor, H. Vincent},
  urldate    = {2024-01-05},
  date       = {2023-08-14},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2308.07496 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2023_ST-MLP_Wang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\QVU2HQ45\\2023_ST-MLP_Wang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\QMS6IAGY\\2308.html:text/html}
}

@misc{wang_tabletime_2025,
  title      = {{TableTime}: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models},
  url        = {http://arxiv.org/abs/2411.15737},
  doi        = {10.48550/arXiv.2411.15737},
  shorttitle = {{TableTime}},
  abstract   = {Large language models ({LLMs}) have demonstrated their effectiveness in multivariate time series classification ({MTSC}). Effective adaptation of {LLMs} for {MTSC} necessitates informative data representations. Existing {LLM}-based methods directly encode embeddings for time series within the latent space of {LLMs} from scratch to align with semantic space of {LLMs}. Despite their effectiveness, we reveal that these methods conceal three inherent bottlenecks: (1) they struggle to encode temporal and channel-specific information in a lossless manner, both of which are critical components of multivariate time series; (2) it is much difficult to align the learned representation space with the semantic space of the {LLMs}; (3) they require task-specific retraining, which is both computationally expensive and labor-intensive. To bridge these gaps, we propose {TableTime}, which reformulates {MTSC} as a table understanding task. Specifically, {TableTime} introduces the following strategies: (1) convert multivariate time series into a tabular form, thus minimizing information loss to the greatest extent; (2) represent tabular time series in text format to achieve natural alignment with the semantic space of {LLMs}; (3) design a reasoning framework that integrates contextual text information, neighborhood assistance, multi-path inference and problem decomposition to enhance the reasoning ability of {LLMs} and realize zero-shot classification. Extensive experiments performed on 10 publicly representative datasets from {UEA} archive verify the superiorities of the {TableTime}.},
  number     = {{arXiv}:2411.15737},
  publisher  = {{arXiv}},
  author     = {Wang, Jiahao and Cheng, Mingyue and Mao, Qingyang and Zhou, Yitong and Xu, Feiyang and Li, Xin},
  urldate    = {2025-03-06},
  date       = {2025-02-16},
  eprinttype = {arxiv},
  eprint     = {2411.15737 [cs]},
  note       = {{TLDR}: {TableTime} introduces the following strategies: convert multivariate time series into a tabular form, thus minimizing information loss to the greatest extent, and design a reasoning framework that integrates contextual text information, neighborhood assistance, multi-path inference and problem decomposition to enhance the reasoning ability of {LLMs} and realize zero-shot classification.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\PM5Y3AXK\\Wang 等 - 2025 - TableTime Reformulating Time Series Classification as Training-Free Table Understanding with Large.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JC57AZGT\\2411.html:text/html}
}

@misc{wang_timexer_2024,
  title      = {{TimeXer}: Empowering Transformers for Time Series Forecasting with Exogenous Variables},
  url        = {http://arxiv.org/abs/2402.19072},
  doi        = {10.48550/arXiv.2402.19072},
  shorttitle = {{TimeXer}},
  abstract   = {Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, {TimeXer}, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, {TimeXer} empowers the canonical Transformer architecture with the ability to reconcile endogenous and exogenous information, where patch-wise self-attention and variate-wise cross-attention are employed. Moreover, a global endogenous variate token is adopted to effectively bridge the exogenous series into endogenous temporal patches. Experimentally, {TimeXer} significantly improves time series forecasting with exogenous variables and achieves consistent state-of-the-art performance in twelve real-world forecasting benchmarks.},
  number     = {{arXiv}:2402.19072},
  publisher  = {{arXiv}},
  author     = {Wang, Yuxuan and Wu, Haixu and Dong, Jiaxiang and Liu, Yong and Qiu, Yunzhong and Zhang, Haoran and Wang, Jianmin and Long, Mingsheng},
  urldate    = {2024-03-18},
  date       = {2024-02-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.19072 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2024_TimeXer_Wang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\UP5XUCM6\\2024_TimeXer_Wang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\GD33M8E9\\2402.html:text/html}
}

@misc{wang_where_2023,
  title      = {Where Would I Go Next? Large Language Models as Human Mobility Predictors},
  url        = {http://arxiv.org/abs/2308.15197},
  doi        = {10.48550/arXiv.2308.15197},
  shorttitle = {Where Would I Go Next?},
  abstract   = {Accurate human mobility prediction underpins many important applications across a variety of domains, including epidemic modelling, transport planning, and emergency responses. Due to the sparsity of mobility data and the stochastic nature of people's daily activities, achieving precise predictions of people's locations remains a challenge. While recently developed large language models ({LLMs}) have demonstrated superior performance across numerous language-related tasks, their applicability to human mobility studies remains unexplored. Addressing this gap, this article delves into the potential of {LLMs} for human mobility prediction tasks. We introduce a novel method, {LLM}-Mob, which leverages the language understanding and reasoning capabilities of {LLMs} for analysing human mobility data. We present concepts of historical stays and context stays to capture both long-term and short-term dependencies in human movement and enable time-aware prediction by using time information of the prediction target. Additionally, we design context-inclusive prompts that enable {LLMs} to generate more accurate predictions. Comprehensive evaluations of our method reveal that {LLM}-Mob excels in providing accurate and interpretable predictions, highlighting the untapped potential of {LLMs} in advancing human mobility prediction techniques. We posit that our research marks a significant paradigm shift in human mobility modelling, transitioning from building complex domain-specific models to harnessing general-purpose {LLMs} that yield accurate predictions through language instructions. The code for this work is available at https://github.com/xlwang233/{LLM}-Mob.},
  number     = {{arXiv}:2308.15197},
  publisher  = {{arXiv}},
  author     = {Wang, Xinglei and Fang, Meng and Zeng, Zichao and Cheng, Tao},
  urldate    = {2023-10-30},
  date       = {2023-08-29},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2308.15197 [physics]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Social and Information Networks, /unread, Physics - Physics and Society},
  file       = {2023_Where Would I Go Next_Wang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Where Would I Go Next_Wang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\9QUEFV8Z\\2308.html:text/html}
}

@article{wang2024tssurvey,
  title     = {Deep Time Series Models: A Comprehensive Survey and Benchmark},
  author    = {Yuxuan Wang and Haixu Wu and Jiaxiang Dong and Yong Liu and Mingsheng Long and Jianmin Wang},
  booktitle = {arXiv preprint arXiv:2407.13278},
  year      = {2024}
}

@misc{williams_context_2024,
  title      = {Context is Key: A Benchmark for Forecasting with Essential Textual Information},
  url        = {http://arxiv.org/abs/2410.18959},
  doi        = {10.48550/arXiv.2410.18959},
  shorttitle = {Context is Key},
  abstract   = {Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce "Context is Key" ({CiK}), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models, and {LLM}-based forecasters, and propose a simple yet effective {LLM} prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using {LLM}-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://servicenow.github.io/context-is-key-forecasting/v0/ .},
  number     = {{arXiv}:2410.18959},
  publisher  = {{arXiv}},
  author     = {Williams, Andrew Robert and Ashok, Arjun and Marcotte, Étienne and Zantedeschi, Valentina and Subramanian, Jithendaraa and Riachi, Roland and Requeima, James and Lacoste, Alexandre and Rish, Irina and Chapados, Nicolas and Drouin, Alexandre},
  urldate    = {2025-01-08},
  date       = {2024-10-24},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2410.18959 [cs]},
  note       = {{TLDR}: A time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities, and a simple yet effective {LLM} prompting method that outperforms all other tested methods on this benchmark.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\ME2EI285\\Williams 等 - 2024 - Context is Key A Benchmark for Forecasting with Essential Textual Information.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\DAWLBUNQ\\2410.html:text/html}
}

@article{wu_big-data_2025,
  title        = {Big-data empowered traffic signal control could reduce urban carbon emission},
  volume       = {16},
  rights       = {2025 The Author(s)},
  issn         = {2041-1723},
  url          = {https://www.nature.com/articles/s41467-025-56701-4},
  doi          = {10.1038/s41467-025-56701-4},
  abstract     = {Urban congestion is a pressing challenge, driving up emissions and compromising transport efficiency. Advances in big-data collection and processing now enable adaptive traffic signals, offering a promising strategy for congestion mitigation. In our study of China’s 100 most congested cities, big-data empowered adaptive traffic signals reduced peak-hour trip times by 11\% and off-peak by 8\%, yielding an estimated annual {CO}₂ reduction of 31.73 million tonnes. Despite an annual implementation cost of {US}\$1.48 billion, societal benefits—including {CO}₂ reduction, time savings, and fuel efficiency—amount to {US}\$31.82 billion. Widespread adoption will require enhanced data collection and processing systems, underscoring the need for policy and technological development. Our findings highlight the transformative potential of big-data-driven adaptive systems to alleviate congestion and promote urban sustainability.},
  pages        = {2013},
  number       = {1},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  author       = {Wu, Kan and Ding, Jianrong and Lin, Jingli and Zheng, Guanjie and Sun, Yi and Fang, Jie and Xu, Tu and Zhu, Yongdong and Gu, Baojing},
  urldate      = {2025-04-18},
  date         = {2025-02-27},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group},
  keywords     = {Climate-change mitigation, Energy and society, Environmental impact},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\4NX4C6ZR\\Wu 等 - 2025 - Big-data empowered traffic signal control could reduce urban carbon emission.pdf:application/pdf}
}

@article{wu_interpretable_2023,
  title        = {Interpretable weather forecasting for worldwide stations with a unified deep model},
  volume       = {5},
  rights       = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
  issn         = {2522-5839},
  url          = {https://www.nature.com/articles/s42256-023-00667-9},
  doi          = {10.1038/s42256-023-00667-9},
  abstract     = {Automatic weather stations are essential for fine-grained weather forecasting; they can be built almost anywhere around the world and are much cheaper than radars and satellites. However, these scattered stations only provide partial observations governed by the continuous space–time global weather system, thus introducing thorny challenges to worldwide forecasting. Here we present the Corrformer model with a novel multi-correlation mechanism, which unifies spatial cross-correlation and temporal auto-correlation into a learned multi-scale tree structure to capture worldwide spatiotemporal correlations. Corrformer reduces the canonical double quadratic complexity of spatiotemporal modelling to linear in spatial modelling and log-linear in temporal modelling, achieving collaborative forecasts for tens of thousands of stations within a unified deep model. Our model can generate interpretable predictions based on inferred propagation directions of weather processes, facilitating a fully data-driven artificial intelligence paradigm for discovering insights for meteorological science. Corrformer yields state-of-the-art forecasts on global, regional and citywide datasets with high confidence and provided skilful weather services for the 2022 Winter Olympics.},
  pages        = {602--611},
  number       = {6},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  author       = {Wu, Haixu and Zhou, Hang and Long, Mingsheng and Wang, Jianmin},
  urldate      = {2023-12-21},
  date         = {2023-06},
  langid       = {english},
  note         = {Number: 6
                  Publisher: Nature Publishing Group},
  keywords     = {/unread, Atmospheric science, Computer science}
}

@misc{wu_reft_2024,
  title      = {{ReFT}: Representation Finetuning for Language Models},
  url        = {http://arxiv.org/abs/2404.03592},
  doi        = {10.48550/arXiv.2404.03592},
  shorttitle = {{ReFT}},
  abstract   = {Parameter-efficient fine-tuning ({PEFT}) methods seek to adapt large models via updates to a small number of weights. However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative. Here, we pursue this hypothesis by developing a family of \${\textbackslash}textbf\{Representation Finetuning ({ReFT})\}\$ methods. {ReFT} methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the {ReFT} family, Low-rank Linear Subspace {ReFT} ({LoReFT}). {LoReFT} is a drop-in replacement for existing {PEFTs} and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art {PEFTs}. We showcase {LoReFT} on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and {GLUE}. In all these evaluations, {LoReFT} delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art {PEFTs}. We release a generic {ReFT} training library publicly at https://github.com/stanfordnlp/pyreft.},
  number     = {{arXiv}:2404.03592},
  publisher  = {{arXiv}},
  author     = {Wu, Zhengxuan and Arora, Aryaman and Wang, Zheng and Geiger, Atticus and Jurafsky, Dan and Manning, Christopher D. and Potts, Christopher},
  urldate    = {2024-04-12},
  date       = {2024-04-07},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2404.03592 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {2024_ReFT_Wu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\ELEH7E7S\\2024_ReFT_Wu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\4SAD5YIQ\\2404.html:text/html}
}

@article{wu_timesnet_2023,
  title    = {{TIMESNET}: {TEMPORAL} 2D-{VARIATION} {MODELING} {FOR} {GENERAL} {TIME} {SERIES} {ANALYSIS}},
  abstract = {Time series analysis is of immense importance in extensive applications, such as weather forecasting, anomaly detection, and action recognition. This paper focuses on temporal variation modeling, which is the common key problem of extensive analysis tasks. Previous methods attempt to accomplish this directly from the 1D time series, which is extremely challenging due to the intricate temporal patterns. Based on the observation of multi-periodicity in time series, we ravel out the complex temporal variations into the multiple intraperiod- and interperiod-variations. To tackle the limitations of 1D time series in representation capability, we extend the analysis of temporal variations into the 2D space by transforming the 1D time series into a set of 2D tensors based on multiple periods. This transformation can embed the intraperiod- and interperiod-variations into the columns and rows of the 2D tensors respectively, making the 2D-variations to be easily modeled by 2D kernels. Technically, we propose the {TimesNet} with {TimesBlock} as a task-general backbone for time series analysis. {TimesBlock} can discover the multi-periodicity adaptively and extract the complex temporal variations from transformed 2D tensors by a parameter-efficient inception block. Our proposed {TimesNet} achieves consistent state-of-the-art in five mainstream time series analysis tasks, including short- and long-term forecasting, imputation, classification, and anomaly detection. Code is available at this repository: https://github.com/thuml/{TimesNet}.},
  author   = {Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  date     = {2023},
  langid   = {english},
  keywords = {/unread, ⛔ No {DOI} found},
  file     = {2023_TIMESNET_Wu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\XU3TMIVD\\2023_TIMESNET_Wu et al.pdf:application/pdf}
}

@misc{wu_timesnet_2023-1,
  title      = {{TimesNet}: Temporal 2D-Variation Modeling for General Time Series Analysis},
  url        = {http://arxiv.org/abs/2210.02186},
  doi        = {10.48550/arXiv.2210.02186},
  shorttitle = {{TimesNet}},
  abstract   = {Time series analysis is of immense importance in extensive applications, such as weather forecasting, anomaly detection, and action recognition. This paper focuses on temporal variation modeling, which is the common key problem of extensive analysis tasks. Previous methods attempt to accomplish this directly from the 1D time series, which is extremely challenging due to the intricate temporal patterns. Based on the observation of multi-periodicity in time series, we ravel out the complex temporal variations into the multiple intraperiod- and interperiod-variations. To tackle the limitations of 1D time series in representation capability, we extend the analysis of temporal variations into the 2D space by transforming the 1D time series into a set of 2D tensors based on multiple periods. This transformation can embed the intraperiod- and interperiod-variations into the columns and rows of the 2D tensors respectively, making the 2D-variations to be easily modeled by 2D kernels. Technically, we propose the {TimesNet} with {TimesBlock} as a task-general backbone for time series analysis. {TimesBlock} can discover the multi-periodicity adaptively and extract the complex temporal variations from transformed 2D tensors by a parameter-efficient inception block. Our proposed {TimesNet} achieves consistent state-of-the-art in five mainstream time series analysis tasks, including short- and long-term forecasting, imputation, classification, and anomaly detection. Code is available at this repository: https://github.com/thuml/{TimesNet}.},
  number     = {{arXiv}:2210.02186},
  publisher  = {{arXiv}},
  author     = {Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  urldate    = {2023-10-24},
  date       = {2023-04-11},
  eprinttype = {arxiv},
  eprint     = {2210.02186 [cs]},
  keywords   = {Computer Science - Machine Learning, /unread},
  file       = {2023_TimesNet_Wu et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_TimesNet_Wu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZAWL4BN7\\2210.html:text/html}
}

@inproceedings{wu2023timesnet,
  title     = {TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis},
  author    = {Haixu Wu and Tengge Hu and Yong Liu and Hang Zhou and Jianmin Wang and Mingsheng Long},
  booktitle = {International Conference on Learning Representations},
  year      = {2023}
}

@misc{xiang_pandora_2024,
  title      = {Pandora: Towards General World Model with Natural Language Actions and Video States},
  url        = {http://arxiv.org/abs/2406.09455},
  doi        = {10.48550/arXiv.2406.09455},
  shorttitle = {Pandora},
  abstract   = {World models simulate future states of the world in response to different actions. They facilitate interactive content creation and provides a foundation for grounded, long-horizon reasoning. Current foundation models do not fully meet the capabilities of general world models: large language models ({LLMs}) are constrained by their reliance on language modality and their limited understanding of the physical world, while video models lack interactive action control over the world simulations. This paper makes a step towards building a general world model by introducing Pandora, a hybrid autoregressive-diffusion model that simulates world states by generating videos and allows real-time control with free-text actions. Pandora achieves domain generality, video consistency, and controllability through large-scale pretraining and instruction tuning. Crucially, Pandora bypasses the cost of training-from-scratch by integrating a pretrained {LLM} (7B) and a pretrained video model, requiring only additional lightweight finetuning. We illustrate extensive outputs by Pandora across diverse domains (indoor/outdoor, natural/urban, human/robot, 2D/3D, etc.). The results indicate great potential of building stronger general world models with larger-scale training.},
  number     = {{arXiv}:2406.09455},
  publisher  = {{arXiv}},
  author     = {Xiang, Jiannan and Liu, Guangyi and Gu, Yi and Gao, Qiyue and Ning, Yuting and Zha, Yuheng and Feng, Zeyu and Tao, Tianhua and Hao, Shibo and Shi, Yemin and Liu, Zhengzhong and Xing, Eric P. and Hu, Zhiting},
  urldate    = {2024-06-20},
  date       = {2024-06-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.09455 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2024_Pandora_Xiang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\GJIFWE6E\\2024_Pandora_Xiang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\SHMBS8QW\\2406.html:text/html}
}

@misc{xiao_enhancing_2025,
  title      = {Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models},
  url        = {http://arxiv.org/abs/2502.05878},
  doi        = {10.48550/arXiv.2502.05878},
  abstract   = {Stock movement prediction, a critical task in financial time-series forecasting, relies on identifying and retrieving key influencing factors from vast and complex datasets. However, traditional text-trained or numeric similarity-based retrieval methods often struggle to handle the intricacies of financial data. To address this, we propose the first retrieval-augmented generation ({RAG}) framework specifically designed for financial time-series forecasting. Our framework incorporates three key innovations: a fine-tuned 1B large language model ({StockLLM}) as its backbone, a novel candidate selection method enhanced by {LLM} feedback, and a training objective that maximizes the similarity between queries and historically significant sequences. These advancements enable our retriever, {FinSeer}, to uncover meaningful patterns while effectively minimizing noise in complex financial datasets. To support robust evaluation, we also construct new datasets that integrate financial indicators and historical stock prices. Experimental results demonstrate that our {RAG} framework outperforms both the baseline {StockLLM} and random retrieval methods, showcasing its effectiveness. {FinSeer}, as the retriever, achieves an 8\% higher accuracy on the {BIGDATA}22 benchmark and retrieves more impactful sequences compared to existing retrieval methods. This work highlights the importance of tailored retrieval models in financial forecasting and provides a novel, scalable framework for future research in the field.},
  number     = {{arXiv}:2502.05878},
  publisher  = {{arXiv}},
  author     = {Xiao, Mengxi and Jiang, Zihao and Qian, Lingfei and Chen, Zhengyu and He, Yueru and Xu, Yijing and Jiang, Yuecheng and Li, Dong and Weng, Ruey-Ling and Peng, Min and Huang, Jimin and Ananiadou, Sophia and Xie, Qianqian},
  urldate    = {2025-02-24},
  date       = {2025-02-11},
  eprinttype = {arxiv},
  eprint     = {2502.05878 [cs]},
  note       = {{TLDR}: The first retrieval-augmented generation ({RAG}) framework specifically designed for financial time-series forecasting is proposed, incorporating a fine-tuned 1B large language model ({StockLLM}) as its backbone, and provides a novel, scalable framework for future research in the field.},
  keywords   = {Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\YWWEPRVM\\Xiao 等 - 2025 - Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\M2RBHGXI\\2502.html:text/html}
}

@misc{xiao_enhancing_2025-1,
  title      = {Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models},
  url        = {http://arxiv.org/abs/2502.05878},
  doi        = {10.48550/arXiv.2502.05878},
  abstract   = {Stock movement prediction, a critical task in financial time-series forecasting, relies on identifying and retrieving key influencing factors from vast and complex datasets. However, traditional text-trained or numeric similarity-based retrieval methods often struggle to handle the intricacies of financial data. To address this, we propose the first retrieval-augmented generation ({RAG}) framework specifically designed for financial time-series forecasting. Our framework incorporates three key innovations: a fine-tuned 1B large language model ({StockLLM}) as its backbone, a novel candidate selection method enhanced by {LLM} feedback, and a training objective that maximizes the similarity between queries and historically significant sequences. These advancements enable our retriever, {FinSeer}, to uncover meaningful patterns while effectively minimizing noise in complex financial datasets. To support robust evaluation, we also construct new datasets that integrate financial indicators and historical stock prices. Experimental results demonstrate that our {RAG} framework outperforms both the baseline {StockLLM} and random retrieval methods, showcasing its effectiveness. {FinSeer}, as the retriever, achieves an 8\% higher accuracy on the {BIGDATA}22 benchmark and retrieves more impactful sequences compared to existing retrieval methods. This work highlights the importance of tailored retrieval models in financial forecasting and provides a novel, scalable framework for future research in the field.},
  number     = {{arXiv}:2502.05878},
  publisher  = {{arXiv}},
  author     = {Xiao, Mengxi and Jiang, Zihao and Qian, Lingfei and Chen, Zhengyu and He, Yueru and Xu, Yijing and Jiang, Yuecheng and Li, Dong and Weng, Ruey-Ling and Peng, Min and Huang, Jimin and Ananiadou, Sophia and Xie, Qianqian},
  urldate    = {2025-02-28},
  date       = {2025-02-11},
  eprinttype = {arxiv},
  eprint     = {2502.05878 [cs]},
  keywords   = {Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\A2RIEGPI\\Xiao 等 - 2025 - Enhancing Financial Time-Series Forecasting with Retrieval-Augmented Large Language Models.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\IJRW3RWF\\2502.html:text/html}
}

@misc{xie_chatts_2024,
  title      = {{ChatTS}: Aligning Time Series with {LLMs} via Synthetic Data for Enhanced Understanding and Reasoning},
  url        = {http://arxiv.org/abs/2412.03104},
  doi        = {10.48550/arXiv.2412.03104},
  shorttitle = {{ChatTS}},
  abstract   = {Understanding time series is crucial for its application in real-world scenarios. Recently, large language models ({LLMs}) have been increasingly applied to time series tasks, leveraging their strong language capabilities to enhance various applications. However, research on multimodal {LLMs} ({MLLMs}) for time series understanding and reasoning remains limited, primarily due to the scarcity of high-quality datasets that align time series with textual information. This paper introduces {ChatTS}, a novel {MLLM} designed for time series analysis. {ChatTS} treats time series as a modality, similar to how vision {MLLMs} process images, enabling it to perform both understanding and reasoning with time series. To address the scarcity of training data, we propose an attribute-based method for generating synthetic time series with detailed attribute descriptions. We further introduce Time Series Evol-Instruct, a novel approach that generates diverse time series Q\&As, enhancing the model's reasoning capabilities. To the best of our knowledge, {ChatTS} is the first {MLLM} that takes multivariate time series as input, which is fine-tuned exclusively on synthetic datasets. We evaluate its performance using benchmark datasets with real-world data, including six alignment tasks and four reasoning tasks. Our results show that {ChatTS} significantly outperforms existing vision-based {MLLMs} (e.g., {GPT}-4o) and text/agent-based {LLMs}, achieving a 46.0\% improvement in alignment tasks and a 25.8\% improvement in reasoning tasks.},
  number     = {{arXiv}:2412.03104},
  publisher  = {{arXiv}},
  author     = {Xie, Zhe and Li, Zeyan and He, Xiao and Xu, Longlong and Wen, Xidao and Zhang, Tieying and Chen, Jianjun and Shi, Rui and Pei, Dan},
  urldate    = {2024-12-19},
  date       = {2024-12-04},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2412.03104 [cs]},
  note       = {{TLDR}: {ChatTS} is the first {TS}-{MLLM} that takes multivariate time series as input for understanding and reasoning, which is fine-tuned exclusively on synthetic datasets, and introduces Time Series Evol-Instruct, a novel approach that generates diverse time series Q\&As, enhancing the model's reasoning capabilities.},
  keywords   = {Computer Science - Artificial Intelligence},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\ZFVKEYNT\\Xie 等 - 2024 - ChatTS Aligning Time Series with LLMs via Synthetic Data for Enhanced Understanding and Reasoning.pdf:application/pdf}
}

@misc{xu_beyond_2024,
  title      = {Beyond Trend and Periodicity: Guiding Time Series Forecasting with Textual Cues},
  url        = {http://arxiv.org/abs/2405.13522},
  shorttitle = {Beyond Trend and Periodicity},
  abstract   = {This work introduces a novel Text-Guided Time Series Forecasting ({TGTSF}) task. By integrating textual cues, such as channel descriptions and dynamic news, {TGTSF} addresses the critical limitations of traditional methods that rely purely on historical data. To support this task, we propose {TGForecaster}, a robust baseline model that fuses textual cues and time series data using cross-attention mechanisms. We then present four meticulously curated benchmark datasets to validate the proposed task, ranging from simple periodic data to complex, event-driven fluctuations. Our comprehensive evaluations demonstrate that {TGForecaster} consistently achieves state-of-the-art performance, highlighting the transformative potential of incorporating textual information into time series forecasting. This work not only pioneers a novel forecasting task but also establishes a new benchmark for future research, driving advancements in multimodal data integration for time series models.},
  number     = {{arXiv}:2405.13522},
  publisher  = {{arXiv}},
  author     = {Xu, Zhijian and Bian, Yuxuan and Zhong, Jianyuan and Wen, Xiangyu and Xu, Qiang},
  urldate    = {2024-05-31},
  date       = {2024-05-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2405.13522 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Xu 等 - 2024 - Beyond Trend and Periodicity Guiding Time Series .pdf:C\:\\Users\\yanha\\Zotero\\storage\\WLRC69TG\\Xu 等 - 2024 - Beyond Trend and Periodicity Guiding Time Series .pdf:application/pdf}
}

@misc{xu_fits_2024,
  title      = {{FITS}: Modeling Time Series with \$10k\$ Parameters},
  url        = {http://arxiv.org/abs/2307.03756},
  doi        = {10.48550/arXiv.2307.03756},
  shorttitle = {{FITS}},
  abstract   = {In this paper, we introduce {FITS}, a lightweight yet powerful model for time series analysis. Unlike existing models that directly process raw time-domain data, {FITS} operates on the principle that time series can be manipulated through interpolation in the complex frequency domain. By discarding high-frequency components with negligible impact on time series data, {FITS} achieves performance comparable to state-of-the-art models for time series forecasting and anomaly detection tasks, while having a remarkably compact size of only approximately \$10k\$ parameters. Such a lightweight model can be easily trained and deployed in edge devices, creating opportunities for various applications. The code is available in: {\textbackslash}url\{https://github.com/{VEWOXIC}/{FITS}\}},
  number     = {{arXiv}:2307.03756},
  publisher  = {{arXiv}},
  author     = {Xu, Zhijian and Zeng, Ailing and Xu, Qiang},
  urldate    = {2024-01-29},
  date       = {2024-01-05},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2307.03756 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_FITS_Xu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\TFM4R4FC\\2024_FITS_Xu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\U8GH2UTI\\2307.html:text/html}
}

@inproceedings{xu_social-cvae_2024,
  location   = {Singapore},
  title      = {Social-{CVAE}: Pedestrian Trajectory Prediction Using Conditional Variational Auto-Encoder},
  isbn       = {978-981-99-8132-8},
  doi        = {10.1007/978-981-99-8132-8_36},
  series     = {Communications in Computer and Information Science},
  shorttitle = {Social-{CVAE}},
  abstract   = {Pedestrian trajectory prediction is a fundamental task in applications such as autonomous driving, robot navigation, and advanced video surveillance. Since human motion behavior is inherently unpredictable, resembling a process of decision-making and intrinsic motivation, it naturally exhibits multimodality and uncertainty. Therefore, predicting multi-modal future trajectories in a reasonable manner poses challenges. The goal of multi-modal pedestrian trajectory prediction is to forecast multiple socially plausible future motion paths based on the historical motion paths of agents. In this paper, we propose a multi-modal pedestrian trajectory prediction method based on conditional variational auto-encoder. Specifically, the core of the proposed model is a conditional variational auto-encoder architecture that learns the distribution of future trajectories of agents by leveraging random latent variables conditioned on observed past trajectories. The encoder models the channel and temporal dimensions of historical agent trajectories sequentially, incorporating channel attention and self-attention to dynamically extract spatio-temporal features of observed past trajectories. The decoder is bidirectional, first estimating the future trajectory endpoints of the agents and then using the estimated trajectory endpoints as the starting position for the backward decoder to predict future trajectories from both directions, reducing cumulative errors over longer prediction ranges. The proposed model is evaluated on the widely used {ETH}/{UCY} pedestrian trajectory prediction benchmark and achieves state-of-the-art performance.},
  pages      = {476--489},
  booktitle  = {Neural Information Processing},
  publisher  = {Springer Nature},
  author     = {Xu, Baowen and Wang, Xuelei and Li, Shuo and Li, Jingwei and Liu, Chengbao},
  editor     = {Luo, Biao and Cheng, Long and Wu, Zheng-Guang and Li, Hongyi and Li, Chaojie},
  date       = {2024},
  langid     = {english},
  keywords   = {/reading, /unread, Attention, Conditional Variational Auto-Encoder, Pedestrian trajectory prediction, {RNN}, {RWKV}},
  file       = {2024_Social-CVAE_Xu et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2024_Social-CVAE_Xu et al.pdf:application/pdf}
}

@misc{xue_promptcast_2023,
  title      = {{PromptCast}: A New Prompt-based Learning Paradigm for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2210.08964},
  doi        = {10.48550/arXiv.2210.08964},
  shorttitle = {{PromptCast}},
  abstract   = {This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing {SOTA} models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting ({PromptCast}). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset ({PISA}) that includes three real-world forecasting scenarios. We evaluate different {SOTA} numerical-based forecasting methods and language generation models. The benchmark results with various forecasting settings demonstrate the proposed {PromptCast} with language generation models is a promising research direction. Additionally, in comparison to conventional numerical-based forecasting, {PromptCast} shows a much better generalization ability under the zero-shot setting.},
  number     = {{arXiv}:2210.08964},
  publisher  = {{arXiv}},
  author     = {Xue, Hao and Salim, Flora D.},
  urldate    = {2024-01-17},
  date       = {2023-12-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2210.08964 [cs, math, stat]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Mathematics - Statistics Theory, Statistics - Methodology},
  file       = {2023_PromptCast_Xue_Salim.pdf:C\:\\Users\\yanha\\Zotero\\storage\\8VMMPH7Z\\2023_PromptCast_Xue_Salim.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UYPQSVJ7\\2210.html:text/html}
}

@misc{yalavarthi_marginalization_2024,
  title      = {Marginalization Consistent Mixture of Separable Flows for Probabilistic Irregular Time Series Forecasting},
  url        = {http://arxiv.org/abs/2406.07246},
  doi        = {10.48550/arXiv.2406.07246},
  abstract   = {Probabilistic forecasting models for joint distributions of targets in irregular time series are a heavily under-researched area in machine learning with, to the best of our knowledge, only three models researched so far: {GPR}, the Gaussian Process Regression model{\textasciitilde}{\textbackslash}citep\{Durichen2015.Multitask\}, {TACTiS}, the Transformer-Attentional Copulas for Time Series{\textasciitilde}{\textbackslash}cite\{Drouin2022.Tactis, ashok2024tactis\} and {ProFITi} {\textbackslash}citep\{Yalavarthi2024.Probabilistica\}, a multivariate normalizing flow model based on invertible attention layers. While {ProFITi}, thanks to using multivariate normalizing flows, is the more expressive model with better predictive performance, we will show that it suffers from marginalization inconsistency: it does not guarantee that the marginal distributions of a subset of variables in its predictive distributions coincide with the directly predicted distributions of these variables. Also, {TACTiS} does not provide any guarantees for marginalization consistency. We develop a novel probabilistic irregular time series forecasting model, Marginalization Consistent Mixtures of Separable Flows (moses), that mixes several normalizing flows with (i) Gaussian Processes with full covariance matrix as source distributions and (ii) a separable invertible transformation, aiming to combine the expressivity of normalizing flows with the marginalization consistency of Gaussians. In experiments on four different datasets we show that moses outperforms other state-of-the-art marginalization consistent models, performs on par with {ProFITi}, but different from {ProFITi}, guarantee marginalization consistency.},
  number     = {{arXiv}:2406.07246},
  publisher  = {{arXiv}},
  author     = {Yalavarthi, Vijaya Krishna and Scholz, Randolf and Madhusudhanan, Kiran and Born, Stefan and Schmidt-Thieme, Lars},
  urldate    = {2024-08-06},
  date       = {2024-06-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.07246 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_Marginalization Consistent Mixture of Separable Flows for Probabilistic_Yalavarthi et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\H3ENBKKV\\2024_Marginalization Consistent Mixture of Separable Flows for Probabilistic_Yalavarthi et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\2PCY6UHY\\2406.html:text/html}
}

@article{yan_learning_2022,
  title        = {Learning Dynamic and Hierarchical Traffic Spatiotemporal Features With Transformer},
  volume       = {23},
  issn         = {1558-0016},
  url          = {https://ieeexplore.ieee.org/document/9520129},
  doi          = {10.1109/TITS.2021.3102983},
  abstract     = {Traffic forecasting has attracted considerable attention due to its importance in proactive urban traffic control and management. Scholars and engineers have exerted considerable efforts in improving the performance of traffic forecasting algorithms in terms of accuracy, reliability, and efficiency. Spatial feature representation of traffic flow is a core component that greatly influences traffic forecasting performance. In previous studies, several spatial attributes of traffic flow are ignored due to the following issues: a) traffic flow propagation does not comply with the road network, b) the spatial pattern of traffic flow varies over time, and c) single adjacent matrix cannot handle the complex and hierarchical urban traffic flow. To address the abovementioned issues, this study proposes a novel traffic forecasting algorithm called traffic transformer, which achieves great success in natural language processing. The multihead attention mechanism and stacking layers enable the transformer to learn dynamic and hierarchical features in sequential data. Two components, namely, global encoder and global–local decoder, are proposed to extract and fuse the spatial patterns globally and locally. Experimental results indicate that the proposed traffic transformer outperforms state-of-the-art methods. The learned dynamic and hierarchical features of traffic flow can help achieve a better understanding of spatial dependency of traffic flow for effective and efficient traffic control and management strategies.},
  pages        = {22386--22399},
  number       = {11},
  journaltitle = {{IEEE} Transactions on Intelligent Transportation Systems},
  author       = {Yan, Haoyang and Ma, Xiaolei and Pu, Ziyuan},
  urldate      = {2024-03-17},
  date         = {2022-11},
  langid       = {english},
  note         = {Conference Name: {IEEE} Transactions on Intelligent Transportation Systems},
  keywords     = {/reading, Feature extraction, Forecasting, Predictive models, Roads, Traffic forecasting, Deep learning, graph-based model, Heuristic algorithms, network modeling, spatial representation, Spatiotemporal phenomena, transformer},
  file         = {2022_Learning Dynamic and Hierarchical Traffic Spatiotemporal Features With_Yan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\776F2G2K\\2022_Learning Dynamic and Hierarchical Traffic Spatiotemporal Features With_Yan et al.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\yanha\\Zotero\\storage\\VPMUANI8\\9520129.html:text/html}
}

@misc{yang_advancing_2024,
  title      = {Advancing Real-time Pandemic Forecasting Using Large Language Models: A {COVID}-19 Case Study},
  url        = {https://www.researchsquare.com/article/rs-4244182/v1},
  doi        = {10.21203/rs.3.rs-4244182/v1},
  shorttitle = {Advancing Real-time Pandemic Forecasting Using Large Language Models},
  abstract   = {Forecasting the short-term spread of an ongoing disease outbreak is a formidable challenge due to the complexity of contributing factors, some of which can be characterized through interlinked, multi-modality variables such as epidemiological time series data, viral biology, population demographics, and the intersection of public policy and human behavior. Existing forecasting model frameworks struggle with the multifaceted nature of relevant data and robust results translation, which hinders their performances and the provision of actionable insights for public health decision-makers. Our work introduces {PandemicLLM}, a novel framework with multi-modal Large Language Models ({LLMs}) that reformulates real-time forecasting of disease spread as a text reasoning problem, with the ability to incorporate real-time, complex, non-numerical information -- such as textual policies and genomic surveillance data -- previously unattainable in traditional forecasting models. This approach, through a unique {AI}-human cooperative prompt design and time series representation learning, encodes multi-modal data for {LLMs}. By redefining the forecasting process as an ordinal classification task, {PandemicLLM} yields more robust and trustworthy predictions, facilitating public health decision-making. The model is applied to the {COVID}-19 pandemic, and trained to utilize textual public health policies, genomic surveillance, spatial, and epidemiological time series data, and is subsequently tested across all 50 states of the U.S. for a duration of 16 weeks. Empirically, {PandemicLLM} is shown to be a high-performing pandemic forecasting framework that effectively captures the impact of emerging variants and can provide timely and accurate predictions. The proposed {PandemicLLM} opens avenues for incorporating various pandemic-related data in heterogeneous formats and exhibits performance benefits over existing models. This study illuminates the potential of adapting {LLMs} and representation learning to enhance pandemic forecasting, illustrating how {AI} innovations can strengthen pandemic responses and crisis management in the future.},
  publisher  = {Research Square},
  author     = {Yang, Hao Frank and Du, Hongru and Zhao, Jianan and Zhao, Yang and Xu, Shaochong and Lin, Xihong and Chen, Yiran and Gardner, Lauren},
  urldate    = {2024-11-26},
  date       = {2024-05-03},
  note       = {{ISSN}: 2693-5015},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\8CPCS9HG\\Yang 等 - 2024 - Advancing Real-time Pandemic Forecasting Using Large Language Models A COVID-19 Case Study.pdf:application/pdf;Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\J4YHB6V8\\Du 等 - 2024 - Advancing Real-time Pandemic Forecasting Using Large Language Models A COVID-19 Case Study.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\CWAKH6HG\\2404.html:text/html}
}

@misc{yang_generative_2024,
  title      = {Generative Pre-Trained Diffusion Paradigm for Zero-Shot Time Series Forecasting},
  url        = {http://arxiv.org/abs/2406.02212},
  doi        = {10.48550/arXiv.2406.02212},
  abstract   = {In recent years, generative pre-trained paradigms such as Large Language Models ({LLMs}) and Large Vision Models ({LVMs}) have achieved revolutionary advancements and widespread real-world applications. Particularly, the emergence of pre-trained {LLMs}-based temporal works, compared to previous deep model approaches, has demonstrated superior generalization and robustness, showcasing the potential of generative pre-trained paradigms as foundation models for time series. However, those {LLMs}-based works mainly focus on cross-modal research, i.e., leveraging the language capabilities of {LLMs} in time series contexts. Although they have achieved impressive performance, there still exist the issues of concept drift caused by differences in data distribution and inflexibility caused by misalignment of dimensions. To this end, inspired by recent work on {LVMs}, we reconsider the paradigm of time series modeling. In this paper, we comprehensively explore, for the first time, the effectiveness and superiority of the Generative Pre-trained Diffusion ({GPD}) paradigm in real-world multivariate time series forecasting ({TSF}). Specifically, to mitigate performance bias introduced by sophisticated networks, we propose a straightforward {MLP} diffusion network for unconditional modeling of time series. Then we employ a zero-shot and tuning-free method to predict (generate) future data using historical data as prompts. The {GPD} paradigm is established on the time series modality, effectively preventing the phenomenon of concept drift, and enabling flexible forecasting of arbitrary lengths. We demonstrate that the {GPD} paradigm achieves comprehensive performance and generalization comparable to current {SOTA} {LLM}-based and deep model paradigms on mainstream benchmarks and various {TSF} tasks. Extensive experiments validate the potential of the {GPD} paradigm and its assistance in future related research.},
  number     = {{arXiv}:2406.02212},
  publisher  = {{arXiv}},
  author     = {Yang, Jiarui and Dai, Tao and Li, Naiqi and Wu, Junxi and Liu, Peiyuan and Li, Jinmin and Bao, Jigang and Zhang, Haigang and Xia, Shutao},
  urldate    = {2024-08-06},
  date       = {2024-06-04},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.02212 [cs]},
  keywords   = {/reading, Computer Science - Computational Engineering, Finance, and Science, ⭐⭐⭐⭐},
  file       = {2024_Generative Pre-Trained Diffusion Paradigm for Zero-Shot Time Series Forecasting_Yang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\96ASLU72\\2024_Generative Pre-Trained Diffusion Paradigm for Zero-Shot Time Series Forecasting_Yang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\5HG98DV6\\2406.html:text/html}
}

@misc{yang_mastering_2024,
  title      = {Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal {LLMs}},
  url        = {http://arxiv.org/abs/2401.11708},
  shorttitle = {Mastering Text-to-Image Diffusion},
  abstract   = {Diffusion models have exhibit exceptional performance in text-to-image generation and editing. However, existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships. In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate ({RPG}), harnessing the powerful chain-of-thought reasoning ability of multimodal {LLMs} to enhance the compositionality of text-to-image diffusion models. Our approach employs the {MLLM} as a global planner to decompose the process of generating complex images into multiple simpler generation tasks within subregions. We propose complementary regional diffusion to enable region-wise compositional generation. Furthermore, we integrate text-guided image generation and editing within the proposed {RPG} in a closed-loop fashion, thereby enhancing generalization ability. Extensive experiments demonstrate our {RPG} outperforms state-of-the-art text-to-image diffusion models, including {DALL}-E 3 and {SDXL}, particularly in multi-category object composition and text-image semantic alignment. Notably, our {RPG} framework exhibits wide compatibility with various {MLLM} architectures (e.g., {MiniGPT}-4) and diffusion backbones (e.g., {ControlNet}). Our code is available at: https://github.com/{YangLing}0818/{RPG}-{DiffusionMaster}},
  number     = {{arXiv}:2401.11708},
  publisher  = {{arXiv}},
  author     = {Yang, Ling and Yu, Zhaochen and Meng, Chenlin and Xu, Minkai and Ermon, Stefano and Cui, Bin},
  urldate    = {2024-07-26},
  date       = {2024-05-05},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2401.11708 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
  file       = {Yang 等 - 2024 - Mastering Text-to-Image Diffusion Recaptioning, P.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CHJQES8D\\Yang 等 - 2024 - Mastering Text-to-Image Diffusion Recaptioning, P.pdf:application/pdf}
}

@misc{yang_vitime_2024,
  title      = {{ViTime}: A Visual Intelligence-Based Foundation Model for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2407.07311},
  doi        = {10.48550/arXiv.2407.07311},
  shorttitle = {{ViTime}},
  abstract   = {The success of large pretrained models in natural language processing ({NLP}) and computer vision ({CV}) has opened new avenues for constructing foundation models for time series forecasting ({TSF}). Traditional {TSF} foundation models rely heavily on numerical data fitting. In contrast, the human brain is inherently skilled at processing visual information, prefer predicting future trends by observing visualized sequences. From a biomimetic perspective, utilizing models to directly process numerical sequences might not be the most effective route to achieving Artificial General Intelligence ({AGI}). This paper proposes {ViTime}, a novel Visual Intelligence-based foundation model for {TSF}. {ViTime} overcomes the limitations of numerical time series data fitting by utilizing visual data processing paradigms and employs a innovative data synthesis method during training, called Real Time Series ({RealTS}). Experiments on a diverse set of previously unseen forecasting datasets demonstrate that {ViTime} achieves state-of-the-art zero-shot performance, even surpassing the best individually trained supervised models in some situations. These findings suggest that visual intelligence can significantly enhance time series analysis and forecasting, paving the way for more advanced and versatile models in the field. The code for our framework is accessible at https://github.com/{IkeYang}/{ViTime}.},
  number     = {{arXiv}:2407.07311},
  publisher  = {{arXiv}},
  author     = {Yang, Luoxiao and Wang, Yun and Fan, Xinqi and Cohen, Israel and Zhao, Yue and Zhang, Zijun},
  urldate    = {2024-07-26},
  date       = {2024-07-09},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2407.07311 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2024_ViTime_Yang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\HP9GGBF9\\2024_ViTime_Yang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\J87FL3BF\\2407.html:text/html}
}

@inproceedings{yao_determine-then-ensemble_2024,
  title      = {Determine-Then-Ensemble: Necessity of Top-k Union for Large Language Model Ensembling},
  url        = {https://openreview.net/forum?id=FDnZFpHmU4},
  shorttitle = {Determine-Then-Ensemble},
  abstract   = {Large language models ({LLMs}) exhibit varying strengths and weaknesses across different tasks, prompting recent studies to explore the benefits of ensembling models to leverage their complementary advantages. However, existing {LLM} ensembling methods often overlook model compatibility and struggle with inefficient alignment of probabilities across the entire vocabulary. In this study, we empirically investigate the factors influencing ensemble performance, identifying model performance, vocabulary size, and response style as key determinants, revealing that compatibility among models is essential for effective ensembling. This analysis leads to the development of a simple yet effective model selection strategy that identifies compatible models. Additionally, we introduce the {\textbackslash}textsc\{Uni\}on {\textbackslash}textsc\{T\}op-\$k\$ {\textbackslash}textsc\{E\}nsembling ({\textbackslash}textsc\{{UniTE}\}), a novel approach that efficiently combines models by focusing on the union of the top-k tokens from each model, thereby avoiding the need for full vocabulary alignment and reducing computational overhead. Extensive evaluations across multiple benchmarks demonstrate that {\textbackslash}textsc\{{UniTE}\} significantly enhances performance compared to existing methods, offering a more efficient framework for {LLM} ensembling.},
  eventtitle = {The Thirteenth International Conference on Learning Representations},
  author     = {Yao, Yuxuan and Wu, Han and Liu, Mingyang and Luo, Sichun and Han, Xiongwei and Liu, Jie and Guo, Zhijiang and Song, Linqi},
  urldate    = {2025-03-06},
  date       = {2024-10-04},
  langid     = {english},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\MRAUBM4H\\Yao 等 - 2024 - Determine-Then-Ensemble Necessity of Top-k Union for Large Language Model Ensembling.pdf:application/pdf}
}

@article{yao_thyroid_2024,
  title        = {Thyroid Cancer Central Lymph Node Metastasis Risk Stratification Based on Homogeneous Positioning Deep Learning},
  volume       = {7},
  url          = {https://spj.science.org/doi/10.34133/research.0432},
  doi          = {10.34133/research.0432},
  abstract     = {Due to the absence of definitive diagnostic criteria, there remains a lack of consensus regarding the risk assessment of central lymph node metastasis ({CLNM}) and the necessity for prophylactic lymph node surgery in ultrasound-diagnosed thyroid cancer. The localization of thyroid nodules is a recognized predictor of {CLNM}; however, quantifying this relationship is challenging due to variable measurements. In this study, we developed a differential isomorphism-based alignment method combined with a graph transformer to accurately extract localization and morphological information of thyroid nodules, thereby predicting {CLNM}. We collected 88,796 ultrasound images from 48,969 patients who underwent central lymph node ({CLN}) surgery and utilized these images to train our predictive model, {ACE}-Net. Furthermore, we employed an interpretable methodology to explore the factors influencing {CLNM} and generated a risk heatmap to visually represent the distribution of {CLNM} risk across different thyroid regions. {ACE}-Net demonstrated superior performance in 6 external multicenter tests ({AUC} = 0.826), surpassing the predictive accuracy of human experts (accuracy = 0.561). The risk heatmap enabled the identification of high-risk areas for {CLNM}, likely correlating with lymphatic metastatic pathways. Additionally, it was observed that the likelihood of metastasis exceeded 80\% when the nodal margin’s minimum distance from the thyroid capsule was less than 1.25 mm. {ACE}-Net’s capacity to effectively predict {CLNM} and provide interpretable disease-related insights can importantly reduce unnecessary lymph node dissections by 37.9\%, without missing positive cases, thus offering a valuable tool for clinical decision-making.},
  pages        = {0432},
  journaltitle = {Research},
  author       = {Yao, Siqiong and Shen, Pengcheng and Dai, Fang and Deng, Luojia and Qiu, Xiangjun and Zhao, Yanna and Gao, Ming and Zhang, Huan and Zheng, Xiangqian and Yu, Xiaoqiang and Bao, Hongjing and Wang, Maofeng and Wang, Yun and Yi, Dandan and Wang, Xiaolei and Zhang, Yuening and Sang, Jianfeng and Fei, Jian and Zhang, Weituo and Qian, Biyun and Lu, Hui},
  urldate      = {2025-04-15},
  date         = {2024-08-20},
  note         = {Publisher: American Association for the Advancement of Science
                  {TLDR}: {ACE}-Net’s capacity to effectively predict {CLNM} and provide interpretable disease-related insights can importantly reduce unnecessary lymph node dissections by 37.9\%, without missing positive cases, thus offering a valuable tool for clinical decision-making.},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\EKEIGXJV\\Yao 等 - 2024 - Thyroid Cancer Central Lymph Node Metastasis Risk Stratification Based on Homogeneous Positioning De.pdf:application/pdf}
}

@misc{yi_fouriergnn_2023,
  title      = {{FourierGNN}: Rethinking Multivariate Time Series Forecasting from a Pure Graph Perspective},
  url        = {http://arxiv.org/abs/2311.06190},
  doi        = {10.48550/arXiv.2311.06190},
  shorttitle = {{FourierGNN}},
  abstract   = {Multivariate time series ({MTS}) forecasting has shown great importance in numerous industries. Current state-of-the-art graph neural network ({GNN})-based forecasting methods usually require both graph networks (e.g., {GCN}) and temporal networks (e.g., {LSTM}) to capture inter-series (spatial) dynamics and intra-series (temporal) dependencies, respectively. However, the uncertain compatibility of the two networks puts an extra burden on handcrafted model designs. Moreover, the separate spatial and temporal modeling naturally violates the unified spatiotemporal inter-dependencies in real world, which largely hinders the forecasting performance. To overcome these problems, we explore an interesting direction of directly applying graph networks and rethink {MTS} forecasting from a pure graph perspective. We first define a novel data structure, hypervariate graph, which regards each series value (regardless of variates or timestamps) as a graph node, and represents sliding windows as space-time fully-connected graphs. This perspective considers spatiotemporal dynamics unitedly and reformulates classic {MTS} forecasting into the predictions on hypervariate graphs. Then, we propose a novel architecture Fourier Graph Neural Network ({FourierGNN}) by stacking our proposed Fourier Graph Operator ({FGO}) to perform matrix multiplications in Fourier space. {FourierGNN} accommodates adequate expressiveness and achieves much lower complexity, which can effectively and efficiently accomplish the forecasting. Besides, our theoretical analysis reveals {FGO}'s equivalence to graph convolutions in the time domain, which further verifies the validity of {FourierGNN}. Extensive experiments on seven datasets have demonstrated our superior performance with higher efficiency and fewer parameters compared with state-of-the-art methods.},
  number     = {{arXiv}:2311.06190},
  publisher  = {{arXiv}},
  author     = {Yi, Kun and Zhang, Qi and Fan, Wei and He, Hui and Hu, Liang and Wang, Pengyang and An, Ning and Cao, Longbing and Niu, Zhendong},
  urldate    = {2024-02-06},
  date       = {2023-11-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.06190 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\YPX9GXYK\\2311.html:text/html;Yi et al_2023_FourierGNN.pdf:C\:\\Users\\yanha\\Zotero\\storage\\D7ZD4ICF\\Yi et al_2023_FourierGNN.pdf:application/pdf}
}

@misc{yi_frequency-domain_2023,
  title      = {Frequency-domain {MLPs} are More Effective Learners in Time Series Forecasting},
  url        = {http://arxiv.org/abs/2311.06184},
  doi        = {10.48550/arXiv.2311.06184},
  abstract   = {Time series forecasting has played the key role in different industrial, including finance, traffic, energy, and healthcare domains. While existing literatures have designed many sophisticated architectures based on {RNNs}, {GNNs}, or Transformers, another kind of approaches based on multi-layer perceptrons ({MLPs}) are proposed with simple structure, low complexity, and \{superior performance\}. However, most {MLP}-based forecasting methods suffer from the point-wise mappings and information bottleneck, which largely hinders the forecasting performance. To overcome this problem, we explore a novel direction of applying {MLPs} in the frequency domain for time series forecasting. We investigate the learned patterns of frequency-domain {MLPs} and discover their two inherent characteristic benefiting forecasting, (i) global view: frequency spectrum makes {MLPs} own a complete view for signals and learn global dependencies more easily, and (ii) energy compaction: frequency-domain {MLPs} concentrate on smaller key part of frequency components with compact signal energy. Then, we propose {FreTS}, a simple yet effective architecture built upon Frequency-domain {MLPs} for Time Series forecasting. {FreTS} mainly involves two stages, (i) Domain Conversion, that transforms time-domain signals into complex numbers of frequency domain; (ii) Frequency Learning, that performs our redesigned {MLPs} for the learning of real and imaginary part of frequency components. The above stages operated on both inter-series and intra-series scales further contribute to channel-wise and time-wise dependency learning. Extensive experiments on 13 real-world benchmarks (including 7 benchmarks for short-term forecasting and 6 benchmarks for long-term forecasting) demonstrate our consistent superiority over state-of-the-art methods.},
  number     = {{arXiv}:2311.06184},
  publisher  = {{arXiv}},
  author     = {Yi, Kun and Zhang, Qi and Fan, Wei and Wang, Shoujin and Wang, Pengyang and He, Hui and Lian, Defu and An, Ning and Cao, Longbing and Niu, Zhendong},
  urldate    = {2024-02-06},
  date       = {2023-11-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.06184 [cs]},
  note       = {{TLDR}: This work explores a novel direction of applying {MLPs} in the frequency domain for time series forecasting, and proposes {FreTS}, a simple yet effective architecture built upon Frequency-domain {MLPs} for Time Series forecasting.},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread},
  file       = {arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UJXMEFMP\\2311.html:text/html;Yi et al_2023_Frequency-domain MLPs are More Effective Learners in Time Series Forecasting.pdf:C\:\\Users\\yanha\\Zotero\\storage\\EVQEMZUP\\Yi et al_2023_Frequency-domain MLPs are More Effective Learners in Time Series Forecasting.pdf:application/pdf}
}

@misc{yin_apollo-forecast_2024,
  title      = {Apollo-Forecast: Overcoming Aliasing and Inference Speed Challenges in Language Models for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2412.12226},
  doi        = {10.48550/arXiv.2412.12226},
  shorttitle = {Apollo-Forecast},
  abstract   = {Encoding time series into tokens and using language models for processing has been shown to substantially augment the models' ability to generalize to unseen tasks. However, existing language models for time series forecasting encounter several obstacles, including aliasing distortion and prolonged inference times, primarily due to the limitations of quantization processes and the computational demands of large models. This paper introduces Apollo-Forecast, a novel framework that tackles these challenges with two key innovations: the Anti-Aliasing Quantization Module ({AAQM}) and the Race Decoding ({RD}) technique. {AAQM} adeptly encodes sequences into tokens while mitigating high-frequency noise in the original signals, thus enhancing both signal fidelity and overall quantization efficiency. {RD} employs a draft model to enable parallel processing and results integration, which markedly accelerates the inference speed for long-term predictions, particularly in large-scale models. Extensive experiments on various real-world datasets show that Apollo-Forecast outperforms state-of-the-art methods by 35.41{\textbackslash}\% and 18.99{\textbackslash}\% in {WQL} and {MASE} metrics, respectively, in zero-shot scenarios. Furthermore, our method achieves a 1.9X-2.7X acceleration in inference speed over baseline methods.},
  number     = {{arXiv}:2412.12226},
  publisher  = {{arXiv}},
  author     = {Yin, Tianyi and Wang, Jingwei and Ma, Yunlong and Wang, Han and Wang, Chenze and Zhao, Yukai and Liu, Min and Shen, Weiming and Chen, Yufeng},
  urldate    = {2024-12-19},
  date       = {2024-12-16},
  eprinttype = {arxiv},
  eprint     = {2412.12226 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\P25TR8QS\\Yin 等 - 2024 - Apollo-Forecast Overcoming Aliasing and Inference Speed Challenges in Language Models for Time Seri.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\LGDPJG5U\\2412.html:text/html}
}

@misc{yu_temporal_2023,
  title      = {Temporal Data Meets {LLM} -- Explainable Financial Time Series Forecasting},
  url        = {http://arxiv.org/abs/2306.11025},
  doi        = {10.48550/arXiv.2306.11025},
  abstract   = {This paper presents a novel study on harnessing Large Language Models' ({LLMs}) outstanding knowledge and reasoning abilities for explainable financial time series forecasting. The application of machine learning models to financial time series comes with several challenges, including the difficulty in cross-sequence reasoning and inference, the hurdle of incorporating multi-modal signals from historical news, financial knowledge graphs, etc., and the issue of interpreting and explaining the model results. In this paper, we focus on {NASDAQ}-100 stocks, making use of publicly accessible historical stock price data, company metadata, and historical economic/financial news. We conduct experiments to illustrate the potential of {LLMs} in offering a unified solution to the aforementioned challenges. Our experiments include trying zero-shot/few-shot inference with {GPT}-4 and instruction-based fine-tuning with a public {LLM} model Open {LLaMA}. We demonstrate our approach outperforms a few baselines, including the widely applied classic {ARMA}-{GARCH} model and a gradient-boosting tree model. Through the performance comparison results and a few examples, we find {LLMs} can make a well-thought decision by reasoning over information from both textual news and price time series and extracting insights, leveraging cross-sequence information, and utilizing the inherent knowledge embedded within the {LLM}. Additionally, we show that a publicly available {LLM} such as Open-{LLaMA}, after fine-tuning, can comprehend the instruction to generate explainable forecasts and achieve reasonable performance, albeit relatively inferior in comparison to {GPT}-4.},
  number     = {{arXiv}:2306.11025},
  publisher  = {{arXiv}},
  author     = {Yu, Xinli and Chen, Zheng and Ling, Yuan and Dong, Shujing and Liu, Zongyi and Lu, Yanbin},
  urldate    = {2023-10-25},
  date       = {2023-06-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2306.11025 [cs, q-fin]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, /unread, F.2.2, I.2.1, I.2.7, Quantitative Finance - Statistical Finance},
  file       = {2023_Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting_Yu et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting_Yu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\ZQI43AZ7\\2306.html:text/html}
}

@inproceedings{yuan_diffusion-ts_2023,
  title      = {Diffusion-{TS}: Interpretable Diffusion for General Time Series Generation},
  url        = {https://openreview.net/forum?id=4h1apFjO99},
  shorttitle = {Diffusion-{TS}},
  abstract   = {Denoising diffusion probabilistic models ({DDPMs}) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-{TS}, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-{TS} to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-{TS} is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-{TS} can be easily extended to conditional generation tasks, such as forecasting and imputation, without any model changes. This also motivates us to further explore the performance of Diffusion-{TS} under irregular settings. Finally, through qualitative and quantitative experiments, results show that Diffusion-{TS} achieves the state-of-the-art results on various realistic analyses of time series.},
  eventtitle = {The Twelfth International Conference on Learning Representations},
  author     = {Yuan, Xinyu and Qiao, Yan},
  urldate    = {2024-12-13},
  date       = {2023-10-13},
  langid     = {english},
  keywords   = {/reading, ⭐⭐⭐⭐⭐},
  file       = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\94ZF629A\\Yuan和Qiao - 2023 - Diffusion-TS Interpretable Diffusion for General Time Series Generation.pdf:application/pdf}
}

@misc{yuan_unist_2024,
  title      = {{UniST}: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction},
  url        = {http://arxiv.org/abs/2402.11838},
  doi        = {10.1145/3637528.3671662},
  shorttitle = {{UniST}},
  abstract   = {Urban spatio-temporal prediction is crucial for informed decision-making, such as traffic management, resource optimization, and emergence response. Despite remarkable breakthroughs in pretrained natural language models that enable one model to handle diverse tasks, a universal solution for spatio-temporal prediction remains challenging Existing prediction approaches are typically tailored for specific spatio-temporal scenarios, requiring task-specific model designs and extensive domain-specific training data. In this study, we introduce {UniST}, a universal model designed for general urban spatio-temporal prediction across a wide range of scenarios. Inspired by large language models, {UniST} achieves success through: (i) utilizing diverse spatio-temporal data from different scenarios, (ii) effective pre-training to capture complex spatio-temporal dynamics, (iii) knowledge-guided prompts to enhance generalization capabilities. These designs together unlock the potential of building a universal model for various scenarios Extensive experiments on more than 20 spatio-temporal scenarios demonstrate {UniST}'s efficacy in advancing state-of-the-art performance, especially in few-shot and zero-shot prediction. The datasets and code implementation are released on https://github.com/tsinghua-fib-lab/{UniST}.},
  author     = {Yuan, Yuan and Ding, Jingtao and Feng, Jie and Jin, Depeng and Li, Yong},
  urldate    = {2024-07-15},
  date       = {2024-06-30},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.11838 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2024_UniST_Yuan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CM56MBWF\\2024_UniST_Yuan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\29TXY55M\\2402.html:text/html}
}

@misc{yue_linear_2023,
  title      = {Linear Recurrent Units for Sequential Recommendation},
  url        = {http://arxiv.org/abs/2310.02367},
  abstract   = {State-of-the-art sequential recommendation relies heavily on self-attention-based recommender models. Yet such models are computationally expensive and often too slow for real-time recommendation. Furthermore, the self-attention operation is performed at a sequence-level, thereby making low-cost incremental inference challenging. Inspired by recent advances in efficient language modeling, we propose linear recurrent units for sequential recommendation ({LRURec}). Similar to recurrent neural networks, {LRURec} offers rapid inference and can achieve incremental inference on sequential inputs. By decomposing the linear recurrence operation and designing recursive parallelization in our framework, {LRURec} provides the additional benefits of reduced model size and parallelizable training. Moreover, we optimize the architecture of {LRURec} by implementing a series of modifications to address the lack of non-linearity and improve training dynamics. To validate the effectiveness of our proposed {LRURec}, we conduct extensive experiments on multiple real-world datasets and compare its performance against state-of-the-art sequential recommenders. Experimental results demonstrate the effectiveness of {LRURec}, which consistently outperforms baselines by a significant margin. Results also highlight the efficiency of {LRURec} with our parallelized training paradigm and fast inference on long sequences, showing its potential to further enhance user experience in sequential recommendation.},
  number     = {{arXiv}:2310.02367},
  publisher  = {{arXiv}},
  author     = {Yue, Zhenrui and Wang, Yueqi and He, Zhankui and Zeng, Huimin and {McAuley}, Julian and Wang, Dong},
  urldate    = {2023-12-13},
  date       = {2023-11-08},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.02367 [cs]},
  keywords   = {/reading, /unread, Computer Science - Information Retrieval},
  file       = {2023_Linear Recurrent Units for Sequential Recommendation_Yue et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Linear Recurrent Units for Sequential Recommendation_Yue et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\6TH9F8X8\\2310.html:text/html}
}

@misc{zeng_are_2022,
  title      = {Are Transformers Effective for Time Series Forecasting?},
  url        = {http://arxiv.org/abs/2205.13504},
  abstract   = {Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting ({LTSF}) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Speciﬁcally, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the permutation-invariant self-attention mechanism inevitably results in temporal information loss.},
  number     = {{arXiv}:2205.13504},
  publisher  = {{arXiv}},
  author     = {Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  urldate    = {2023-07-25},
  date       = {2022-08-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2205.13504 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2022_Are Transformers Effective for Time Series Forecasting_Zeng et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\TCI2N9TP\\2022_Are Transformers Effective for Time Series Forecasting_Zeng et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\IPE5U6S6\\2205.html:text/html}
}

@misc{zhan_time_2024,
  title      = {Time Evidence Fusion Network: Multi-source View in Long-Term Time Series Forecasting},
  url        = {http://arxiv.org/abs/2405.06419},
  doi        = {10.48550/arXiv.2405.06419},
  shorttitle = {Time Evidence Fusion Network},
  abstract   = {In real-world scenarios, time series forecasting often demands timeliness, making research on model backbones a perennially hot topic. To meet these performance demands, we propose a novel backbone from the perspective of information fusion. Introducing the Basic Probability Assignment ({BPA}) Module and the Time Evidence Fusion Network ({TEFN}), based on evidence theory, allows us to achieve superior performance. On the other hand, the perspective of multi-source information fusion effectively improves the accuracy of forecasting. Due to the fact that {BPA} is generated by fuzzy theory, {TEFN} also has considerable interpretability. In real data experiments, the {TEFN} partially achieved state-of-the-art, with low errors comparable to {PatchTST}, and operating efficiency surpass performance models such as Dlinear. Meanwhile, {TEFN} has high robustness and small error fluctuations in the random hyperparameter selection. {TEFN} is not a model that achieves the ultimate in single aspect, but a model that balances performance, accuracy, stability, and interpretability.},
  number     = {{arXiv}:2405.06419},
  publisher  = {{arXiv}},
  author     = {Zhan, Tianxiang and He, Yuanpeng and Li, Zhen and Deng, Yong},
  urldate    = {2024-05-22},
  date       = {2024-05-10},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2405.06419 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
  file       = {2024_Time Evidence Fusion Network_Zhan et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\IZP26D4V\\2024_Time Evidence Fusion Network_Zhan et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RVSME6RZ\\2405.html:text/html}
}

@misc{zhang_chattraffic_2024,
  title      = {{ChatTraffic}: Text-to-Traffic Generation via Diffusion Model},
  url        = {http://arxiv.org/abs/2311.16203},
  doi        = {10.48550/arXiv.2311.16203},
  shorttitle = {{ChatTraffic}},
  abstract   = {Traffic prediction is one of the most significant foundations in Intelligent Transportation Systems ({ITS}). Traditional traffic prediction methods rely only on historical traffic data to predict traffic trends and face two main challenges. 1) insensitivity to unusual events. 2) limited performance in long-term prediction. In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic generation, and name the task Text-to-Traffic Generation ({TTG}). The key challenge of the {TTG} task is how to associate text with the spatial structure of the road network and traffic data for generating traffic situations. To this end, we propose {ChatTraffic}, the first diffusion model for text-to-traffic generation. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network ({GCN}) to extract spatial correlations of traffic data. In addition, we construct a large dataset containing text-traffic pairs for the {TTG} task. We benchmarked our model qualitatively and quantitatively on the released dataset. The experimental results indicate that {ChatTraffic} can generate realistic traffic situations from the text. Our code and dataset are available at https://github.com/{ChyaZhang}/{ChatTraffic}.},
  number     = {{arXiv}:2311.16203},
  publisher  = {{arXiv}},
  author     = {Zhang, Chengyang and Zhang, Yong and Shao, Qitan and Li, Bo and Lv, Yisheng and Piao, Xinglin and Yin, Baocai},
  urldate    = {2024-12-19},
  date       = {2024-02-05},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2311.16203 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\4C54SHLZ\\Zhang 等 - 2024 - ChatTraffic Text-to-Traffic Generation via Diffusion Model.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\WVR23Q5Y\\2311.html:text/html}
}

@article{zhang_deepsece_2023,
  title        = {{DeepSecE}: A Deep-Learning-Based Framework for Multiclass Prediction of Secreted Proteins in Gram-Negative Bacteria},
  volume       = {6},
  url          = {https://spj.science.org/doi/10.34133/research.0258},
  doi          = {10.34133/research.0258},
  shorttitle   = {{DeepSecE}},
  abstract     = {Proteins secreted by Gram-negative bacteria are tightly linked to the virulence and adaptability of these microbes to environmental changes. Accurate identification of such secreted proteins can facilitate the investigations of infections and diseases caused by these bacterial pathogens. However, current bioinformatic methods for predicting bacterial secreted substrate proteins have limited computational efficiency and application scope on a genome-wide scale. Here, we propose a novel deep-learning-based framework—{DeepSecE}—for the simultaneous inference of multiple distinct groups of secreted proteins produced by Gram-negative bacteria. {DeepSecE} remarkably improves their classification from nonsecreted proteins using a pretrained protein language model and transformer, achieving a macro-average accuracy of 0.883 on 5-fold cross-validation. Performance benchmarking suggests that {DeepSecE} achieves competitive performance with the state-of-the-art binary predictors specialized for individual types of secreted substrates. The attention mechanism corroborates salient patterns and motifs at the N or C termini of the protein sequences. Using this pipeline, we further investigate the genome-wide prediction of novel secreted proteins and their taxonomic distribution across {\textasciitilde}1,000 Gram-negative bacterial genomes. The present analysis demonstrates that {DeepSecE} has major potential for the discovery of disease-associated secreted proteins in a diverse range of Gram-negative bacteria. An online web server of {DeepSecE} is also publicly available to predict and explore various secreted substrate proteins via the input of bacterial genome sequences.},
  pages        = {0258},
  journaltitle = {Research},
  author       = {Zhang, Yumeng and Guan, Jiahao and Li, Chen and Wang, Zhikang and Deng, Zixin and Gasser, Robin B. and Song, Jiangning and Ou, Hong-Yu},
  urldate      = {2025-04-15},
  date         = {2023-10-25},
  note         = {Publisher: American Association for the Advancement of Science
                  {TLDR}: {DeepSecE} has major potential for the discovery of disease-associated secreted proteins in a diverse range of Gram-negative bacteria, and performance benchmarking suggests that {DeepSecE} achieves competitive performance with the state-of-the-art binary predictors specialized for individual types of secreted substrates.},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\XG9VIF3T\\Zhang 等 - 2023 - DeepSecE A Deep-Learning-Based Framework for Multiclass Prediction of Secreted Proteins in Gram-Neg.pdf:application/pdf}
}

@article{zhang_incorporating_2023,
  title        = {Incorporating multimodal context information into traffic speed forecasting through graph deep learning},
  volume       = {37},
  issn         = {1365-8816},
  url          = {https://doi.org/10.1080/13658816.2023.2234959},
  doi          = {10.1080/13658816.2023.2234959},
  abstract     = {Accurate traffic speed forecasting is a prerequisite for anticipating future traffic status and increasing the resilience of intelligent transportation systems. However, most studies ignore the involvement of context information ubiquitously distributed over the urban environment to boost speed prediction. The diversity and complexity of context information also hinder incorporating it into traffic forecasting. Therefore, this study proposes a multimodal context-based graph convolutional neural network ({MCGCN}) model to fuse context data into traffic speed prediction, including spatial and temporal contexts. The proposed model comprises three modules, ie (a) hierarchical spatial embedding to learn spatial representations by organizing spatial contexts from different dimensions, (b) multivariate temporal modeling to learn temporal representations by capturing dependencies of multivariate temporal contexts and (c) attention-based multimodal fusion to integrate traffic speed with the spatial and temporal context representations for multi-step speed prediction. We conduct extensive experiments in Singapore. Compared to the baseline model (spatial-temporal graph convolutional network, {STGCN}), our results demonstrate the importance of multimodal contexts with the mean-absolute-error improvement of 0.29 km/h, 0.45 km/h and 0.89 km/h in 30-min, 60-min and 120-min speed prediction, respectively. We also explore how different contexts affect traffic speed forecasting, providing references for stakeholders to understand the relationship between context information and transportation systems.},
  pages        = {1909--1935},
  number       = {9},
  journaltitle = {International Journal of Geographical Information Science},
  author       = {Zhang, Yatao and Zhao, Tianhong and Gao, Song and Raubal, Martin},
  urldate      = {2023-12-08},
  date         = {2023-09-02},
  langid       = {english},
  note         = {Publisher: Taylor \& Francis
                  \_eprint: https://doi.org/10.1080/13658816.2023.2234959},
  keywords     = {/reading, /unread, graph deep learning, multimodal context fusion, spatial context, temporal context, Traffic speed forecasting},
  file         = {2023_Incorporating multimodal context information into traffic speed forecasting_Zhang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_Incorporating multimodal context information into traffic speed forecasting_Zhang et al.pdf:application/pdf}
}

@misc{zhang_lemole_2024,
  title      = {{LeMoLE}: {LLM}-Enhanced Mixture of Linear Experts for Time Series Forecasting},
  url        = {http://arxiv.org/abs/2412.00053},
  doi        = {10.48550/arXiv.2412.00053},
  shorttitle = {{LeMoLE}},
  abstract   = {Recent research has shown that large language models ({LLMs}) can be effectively used for real-world time series forecasting due to their strong natural language understanding capabilities. However, aligning time series into semantic spaces of {LLMs} comes with high computational costs and inference complexity, particularly for long-range time series generation. Building on recent advancements in using linear models for time series, this paper introduces an {LLM}-enhanced mixture of linear experts for precise and efficient time series forecasting. This approach involves developing a mixture of linear experts with multiple lookback lengths and a new multimodal fusion mechanism. The use of a mixture of linear experts is efficient due to its simplicity, while the multimodal fusion mechanism adaptively combines multiple linear experts based on the learned features of the text modality from pre-trained large language models. In experiments, we rethink the need to align time series to {LLMs} by existing time-series large language models and further discuss their efficiency and effectiveness in time series forecasting. Our experimental results show that the proposed {LeMoLE} model presents lower prediction errors and higher computational efficiency than existing {LLM} models.},
  number     = {{arXiv}:2412.00053},
  publisher  = {{arXiv}},
  author     = {Zhang, Lingzheng and Shen, Lifeng and Zheng, Yimin and Piao, Shiyuan and Li, Ziyue and Tsung, Fugee},
  urldate    = {2024-12-12},
  date       = {2024-11-24},
  langid     = {american},
  eprinttype = {arxiv},
  eprint     = {2412.00053 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, ⭐⭐⭐⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\EU4QMQSZ\\Zhang 等 - 2024 - LeMoLE LLM-Enhanced Mixture of Linear Experts for Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\73AZM3IP\\2412.html:text/html}
}

@misc{zhang_llmforecaster_2024,
  title      = {{LLMForecaster}: Improving Seasonal Event Forecasts with Unstructured Textual Data},
  url        = {http://arxiv.org/abs/2412.02525},
  doi        = {10.48550/arXiv.2412.02525},
  shorttitle = {{LLMForecaster}},
  abstract   = {Modern time-series forecasting models often fail to make full use of rich unstructured information about the time series themselves. This lack of proper conditioning can lead to obvious model failures; for example, models may be unaware of the details of a particular product, and hence fail to anticipate seasonal surges in customer demand in the lead up to major exogenous events like holidays for clearly relevant products. To address this shortcoming, this paper introduces a novel forecast post-processor -- which we call {LLMForecaster} -- that fine-tunes large language models ({LLMs}) to incorporate unstructured semantic and contextual information and historical data to improve the forecasts from an existing demand forecasting pipeline. In an industry-scale retail application, we demonstrate that our technique yields statistically significantly forecast improvements across several sets of products subject to holiday-driven demand surges.},
  number     = {{arXiv}:2412.02525},
  publisher  = {{arXiv}},
  author     = {Zhang, Hanyu and Arvin, Chuck and Efimov, Dmitry and Mahoney, Michael W. and Perrault-Joncas, Dominique and Ramasubramanian, Shankar and Wilson, Andrew Gordon and Wolff, Malcolm},
  urldate    = {2024-12-12},
  date       = {2024-12-03},
  eprinttype = {arxiv},
  eprint     = {2412.02525 [cs]},
  note       = {{TLDR}: A novel forecast post-processor is introduced that fine-tunes large language models to incorporate unstructured semantic and contextual information and historical data to improve the forecasts from an existing demand forecasting pipeline and yields statistically significantly forecast improvements across several sets of products subject to holiday-driven demand surges.},
  keywords   = {Computer Science - Computation and Language, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\K8SXK7F8\\Zhang 等 - 2024 - LLMForecaster Improving Seasonal Event Forecasts with Unstructured Textual Data.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\93HHNT84\\2412.html:text/html}
}

@misc{zhang_mathverse_2024,
  title      = {{MathVerse}: Does Your Multi-modal {LLM} Truly See the Diagrams in Visual Math Problems?},
  url        = {http://arxiv.org/abs/2403.14624},
  doi        = {10.48550/arXiv.2403.14624},
  shorttitle = {{MathVerse}},
  abstract   = {The remarkable progress of Multi-modal Large Language Models ({MLLMs}) has garnered unparalleled attention, due to their superior performance in visual contexts. However, their capabilities in visual math problem-solving remain insufficiently evaluated and understood. We investigate current benchmarks to incorporate excessive visual content within textual questions, which potentially assist {MLLMs} in deducing answers without truly interpreting the input diagrams. To this end, we introduce {MathVerse}, an all-around visual math benchmark designed for an equitable and in-depth evaluation of {MLLMs}. We meticulously collect 2,612 high-quality, multi-subject math problems with diagrams from publicly available sources. Each problem is then transformed by human annotators into six distinct versions, each offering varying degrees of information content in multi-modality, contributing to 15K test samples in total. This approach allows {MathVerse} to comprehensively assess whether and how much {MLLMs} can truly understand the visual diagrams for mathematical reasoning. In addition, we propose a Chain-of-Thought ({CoT}) evaluation strategy for a fine-grained assessment of the output answers. Rather than naively judging True or False, we employ {GPT}-4(V) to adaptively extract crucial reasoning steps, and then score each step with detailed error analysis, which can reveal the intermediate {CoT} reasoning quality by {MLLMs}. We hope the {MathVerse} benchmark may provide unique insights to guide the future development of {MLLMs}. Project page: https://mathverse-cuhk.github.io},
  number     = {{arXiv}:2403.14624},
  publisher  = {{arXiv}},
  author     = {Zhang, Renrui and Jiang, Dongzhi and Zhang, Yichi and Lin, Haokun and Guo, Ziyu and Qiu, Pengshuo and Zhou, Aojun and Lu, Pan and Chang, Kai-Wei and Gao, Peng and Li, Hongsheng},
  urldate    = {2024-04-12},
  date       = {2024-03-21},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2403.14624 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
  file       = {2024_MathVerse_Zhang et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\264AK6TU\\2024_MathVerse_Zhang et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\VVRQ8L5I\\2403.html:text/html}
}

@inproceedings{zhang_promptst_2023,
  location   = {New York, {NY}, {USA}},
  title      = {{PromptST}: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction},
  isbn       = {979-8-4007-0124-5},
  url        = {https://doi.org/10.1145/3583780.3615016},
  doi        = {10.1145/3583780.3615016},
  series     = {{CIKM} '23},
  shorttitle = {{PromptST}},
  abstract   = {In the era of information explosion, spatio-temporal data mining serves as a critical part of urban management. Considering the various fields demanding attention, e.g., traffic state, human activity, and social event, predicting multiple spatio-temporal attributes simultaneously can alleviate regulatory pressure and foster smart city construction. However, current research can not handle the spatio-temporal multi-attribute prediction well due to the complex relationships between diverse attributes. The key challenge lies in how to address the common spatio-temporal patterns while tackling their distinctions. In this paper, we propose an effective solution for spatio-temporal multi-attribute prediction, {PromptST}. We devise a spatio-temporal transformer and a parameter-sharing training scheme to address the common knowledge among different spatio-temporal attributes. Then, we elaborate a spatio-temporal prompt tuning strategy to fit the specific attributes in a lightweight manner. Through the pretrain and prompt tuning phases, our {PromptST} is able to enhance the specific spatio-temoral characteristic capture by prompting the backbone model to fit the specific target attribute while maintaining the learned common knowledge. Extensive experiments on real-world datasets verify that our {PromptST} attains state-of-the-art performance. Furthermore, we also prove {PromptST} owns good transferability on unseen spatio-temporal attributes, which brings promising application potential in urban computing. The implementation code is available to ease reproducibility.},
  pages      = {3195--3205},
  booktitle  = {Proceedings of the 32nd {ACM} International Conference on Information and Knowledge Management},
  publisher  = {Association for Computing Machinery},
  author     = {Zhang, Zijian and Zhao, Xiangyu and Liu, Qidong and Zhang, Chunxu and Ma, Qian and Wang, Wanyu and Zhao, Hongwei and Wang, Yiqi and Liu, Zitao},
  urldate    = {2023-12-07},
  date       = {2023-10-21},
  keywords   = {/unread, multi-attribute prediction, prompt learning, smart city, spatio-temporal prediction},
  file       = {2023_PromptST_Zhang et al.pdf:C\:\\Users\\yanha\\zotero\\storage\\交通预测\\2023_PromptST_Zhang et al.pdf:application/pdf}
}

@misc{zhao_genformer_2024,
  title      = {{GenFormer}: A Deep-Learning-Based Approach for Generating Multivariate Stochastic Processes},
  url        = {http://arxiv.org/abs/2402.02010},
  doi        = {10.48550/arXiv.2402.02010},
  shorttitle = {{GenFormer}},
  abstract   = {Stochastic generators are essential to produce synthetic realizations that preserve target statistical properties. We propose {GenFormer}, a stochastic generator for spatio-temporal multivariate stochastic processes. It is constructed using a Transformer-based deep learning model that learns a mapping between a Markov state sequence and time series values. The synthetic data generated by the {GenFormer} model preserves the target marginal distributions and approximately captures other desired statistical properties even in challenging applications involving a large number of spatial locations and a long simulation horizon. The {GenFormer} model is applied to simulate synthetic wind speed data at various stations in Florida to calculate exceedance probabilities for risk management.},
  number     = {{arXiv}:2402.02010},
  publisher  = {{arXiv}},
  author     = {Zhao, Haoran and Uy, Wayne Isaac Tan},
  urldate    = {2024-08-06},
  date       = {2024-02-02},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2402.02010 [cs, stat]},
  keywords   = {Computer Science - Machine Learning, Statistics - Machine Learning, /unread},
  file       = {2024_GenFormer_Zhao_Uy.pdf:C\:\\Users\\yanha\\Zotero\\storage\\AHKIZL8T\\2024_GenFormer_Zhao_Uy.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\3WLYYFF8\\2402.html:text/html}
}

@article{zheng_large_2025,
  title        = {Large language models for scientific discovery in molecular property prediction},
  rights       = {2025 The Author(s), under exclusive licence to Springer Nature Limited},
  issn         = {2522-5839},
  url          = {https://www.nature.com/articles/s42256-025-00994-z},
  doi          = {10.1038/s42256-025-00994-z},
  abstract     = {Large language models ({LLMs}) are a form of artificial intelligence system encapsulating vast knowledge in the form of natural language. These systems are adept at numerous complex tasks including creative writing, storytelling, translation, question-answering, summarization and computer code generation. Although {LLMs} have seen initial applications in natural sciences, their potential for driving scientific discovery remains largely unexplored. In this work, we introduce {LLM}4SD, a framework designed to harness {LLMs} for driving scientific discovery in molecular property prediction by synthesizing knowledge from literature and inferring knowledge from scientific data. {LLMs} synthesize knowledge by extracting established information from scientific literature, such as molecular weight being key to predicting solubility. For inference, {LLMs} identify patterns in molecular data, particularly in Simplified Molecular Input Line Entry System-encoded structures, such as halogen-containing molecules being more likely to cross the blood–brain barrier. This information is presented as interpretable knowledge, enabling the transformation of molecules into feature vectors. By using these features with interpretable models such as random forest, {LLM}4SD can outperform the current state of the art across a range of benchmark tasks for predicting molecular properties. We foresee it providing interpretable and potentially new insights, aiding scientific discovery in molecular property prediction.},
  pages        = {1--11},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  author       = {Zheng, Yizhen and Koh, Huan Yee and Ju, Jiaxin and Nguyen, Anh T. N. and May, Lauren T. and Webb, Geoffrey I. and Pan, Shirui},
  urldate      = {2025-03-06},
  date         = {2025-02-25},
  langid       = {english},
  note         = {Publisher: Nature Publishing Group},
  keywords     = {Machine learning, Computational chemistry},
  file         = {Full Text PDF:C\:\\Users\\yanha\\Zotero\\storage\\4UV5FL98\\Zheng 等 - 2025 - Large language models for scientific discovery in molecular property prediction.pdf:application/pdf;PDF:C\:\\Users\\yanha\\Zotero\\storage\\TZITTUUE\\Zheng 等 - 2025 - Large language models for scientific discovery in molecular property prediction.pdf:application/pdf}
}

@misc{zheng_revisited_2024,
  title      = {Revisited Large Language Model for Time Series Analysis through Modality Alignment},
  url        = {http://arxiv.org/abs/2410.12326},
  doi        = {10.48550/arXiv.2410.12326},
  abstract   = {Large Language Models have demonstrated impressive performance in many pivotal web applications such as sensor data analysis. However, since {LLMs} are not designed for time series tasks, simpler models like linear regressions can often achieve comparable performance with far less complexity. In this study, we perform extensive experiments to assess the effectiveness of applying {LLMs} to key time series tasks, including forecasting, classification, imputation, and anomaly detection. We compare the performance of {LLMs} against simpler baseline models, such as single-layer linear models and randomly initialized {LLMs}. Our results reveal that {LLMs} offer minimal advantages for these core time series tasks and may even distort the temporal structure of the data. In contrast, simpler models consistently outperform {LLMs} while requiring far fewer parameters. Furthermore, we analyze existing reprogramming techniques and show, through data manifold analysis, that these methods fail to effectively align time series data with language and display pseudo-alignment behaviour in embedding space. Our findings suggest that the performance of {LLM}-based methods in time series tasks arises from the intrinsic characteristics and structure of time series data, rather than any meaningful alignment with the language model architecture.},
  number     = {{arXiv}:2410.12326},
  publisher  = {{arXiv}},
  author     = {Zheng, Liangwei Nathan and Dong, Chang George and Zhang, Wei Emma and Yue, Lin and Xu, Miao and Maennel, Olaf and Chen, Weitong},
  urldate    = {2024-10-23},
  date       = {2024-10-16},
  eprinttype = {arxiv},
  eprint     = {2410.12326},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\GD7GWWS3\\Zheng 等 - 2024 - Revisited Large Language Model for Time Series Analysis through Modality Alignment.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\RMEFW3W6\\2410.html:text/html}
}

@misc{zhou_can_2025,
  title      = {Can {LLMs} Understand Time Series Anomalies?},
  url        = {http://arxiv.org/abs/2410.05440},
  doi        = {10.48550/arXiv.2410.05440},
  abstract   = {Large Language Models ({LLMs}) have gained popularity in time series forecasting, but their potential for anomaly detection remains largely unexplored. Our study investigates whether {LLMs} can understand and detect anomalies in time series data, focusing on zero-shot and few-shot scenarios. Inspired by conjectures about {LLMs}' behavior from time series forecasting research, we formulate key hypotheses about {LLMs}' capabilities in time series anomaly detection. We design and conduct principled experiments to test each of these hypotheses. Our investigation reveals several surprising findings about {LLMs} for time series: (1) {LLMs} understand time series better as images rather than as text, (2) {LLMs} do not demonstrate enhanced performance when prompted to engage in explicit reasoning about time series analysis. (3) Contrary to common beliefs, {LLMs}' understanding of time series does not stem from their repetition biases or arithmetic abilities. (4) {LLMs}' behaviors and performance in time series analysis vary significantly across different models. This study provides the first comprehensive analysis of contemporary {LLM} capabilities in time series anomaly detection. Our results suggest that while {LLMs} can understand trivial time series anomalies, we have no evidence that they can understand more subtle real-world anomalies. Many common conjectures based on their reasoning capabilities do not hold. All synthetic dataset generators, final prompts, and evaluation scripts have been made available in https://github.com/rose-stl-lab/anomllm.},
  number     = {{arXiv}:2410.05440},
  publisher  = {{arXiv}},
  author     = {Zhou, Zihao and Yu, Rose},
  urldate    = {2025-03-30},
  date       = {2025-03-11},
  eprinttype = {arxiv},
  eprint     = {2410.05440 [cs]},
  note       = {{TLDR}: This study provides the first comprehensive analysis of contemporary {LLM} capabilities in time series anomaly detection, suggesting that while {LLMs} can understand trivial time series anomalies, they have no evidence that they can understand more subtle real-world anomalies.},
  keywords   = {Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\VFMRASZ7\\Zhou和Yu - 2025 - Can LLMs Understand Time Series Anomalies.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\CLH7UQ7S\\2410.html:text/html}
}

@misc{zhou_fedformer_2022,
  title      = {{FEDformer}: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting},
  url        = {http://arxiv.org/abs/2201.12740},
  doi        = {10.48550/arXiv.2201.12740},
  shorttitle = {{FEDformer}},
  abstract   = {Although Transformer-based methods have significantly improved state-of-the-art results for long-term series forecasting, they are not only computationally expensive but more importantly, are unable to capture the global view of time series (e.g. overall trend). To address these problems, we propose to combine Transformer with the seasonal-trend decomposition method, in which the decomposition method captures the global profile of time series while Transformers capture more detailed structures. To further enhance the performance of Transformer for long-term prediction, we exploit the fact that most time series tend to have a sparse representation in well-known basis such as Fourier transform, and develop a frequency enhanced Transformer. Besides being more effective, the proposed method, termed as Frequency Enhanced Decomposed Transformer (\{{\textbackslash}bf {FEDformer}\}), is more efficient than standard Transformer with a linear complexity to the sequence length. Our empirical studies with six benchmark datasets show that compared with state-of-the-art methods, {FEDformer} can reduce prediction error by \$14.8{\textbackslash}\%\$ and \$22.6{\textbackslash}\%\$ for multivariate and univariate time series, respectively. Code is publicly available at https://github.com/{MAZiqing}/{FEDformer}.},
  number     = {{arXiv}:2201.12740},
  publisher  = {{arXiv}},
  author     = {Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  urldate    = {2024-02-26},
  date       = {2022-06-16},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2201.12740 [cs, stat]},
  keywords   = {/reading, Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {2022_FEDformer_Zhou et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\WDLPVCD8\\2022_FEDformer_Zhou et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\VBAXL69Y\\2201.html:text/html}
}

@misc{zhou_fone_2025,
  title      = {{FoNE}: Precise Single-Token Number Embeddings via Fourier Features},
  url        = {http://arxiv.org/abs/2502.09741},
  doi        = {10.48550/arXiv.2502.09741},
  shorttitle = {{FoNE}},
  abstract   = {Large Language Models ({LLMs}) typically represent numbers using multiple tokens, which requires the model to aggregate these tokens to interpret numerical values. This fragmentation makes both training and inference less efficient and adversely affects the model's performance on number-related tasks. Inspired by the observation that pre-trained {LLMs} internally learn Fourier-like features for number tokens, we propose Fourier Number Embedding ({FoNE}), a novel method that directly maps numbers into the embedding space with their Fourier features. {FoNE} encodes each number as a single token with only two embedding dimensions per digit, effectively capturing numerical values without fragmentation. This compact representation accelerates both training and inference. Compared to traditional subword and digit-wise embeddings, {FoNE} not only reduces computational overhead but also achieves higher accuracy across various numerical tasks including addition, subtraction and multiplication. On 6-digit decimal addition, {FoNE} requires 64\${\textbackslash}times\$ less data to achieve 99\% accuracy than subword and digit-wise embeddings while using 3\${\textbackslash}times\$ and 6\${\textbackslash}times\$ fewer tokens per number, respectively. Furthermore, {FoNE} is the only method that yields 100\% accuracy on over 100,000 test examples for addition, subtraction, and multiplication. The codes and visualization are available at https://fouriernumber.github.io/.},
  number     = {{arXiv}:2502.09741},
  publisher  = {{arXiv}},
  author     = {Zhou, Tianyi and Fu, Deqing and Soltanolkotabi, Mahdi and Jia, Robin and Sharan, Vatsal},
  urldate    = {2025-02-25},
  date       = {2025-02-13},
  eprinttype = {arxiv},
  eprint     = {2502.09741 [cs]},
  note       = {{TLDR}: Inspired by the observation that pre-trained {LLMs} internally learn Fourier-like features for number tokens, Fourier Number Embedding ({FoNE}) is proposed, a novel method that directly maps numbers into the embedding space with their Fourier features.},
  keywords   = {Computer Science - Computation and Language, Computer Science - Machine Learning},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\NMNXVYHN\\Zhou 等 - 2025 - FoNE Precise Single-Token Number Embeddings via Fourier Features.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\K388DYAF\\2502.html:text/html}
}

@misc{zhou_informer_2021,
  title      = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  url        = {http://arxiv.org/abs/2012.07436},
  shorttitle = {Informer},
  abstract   = {Many real-world applications require the prediction of long sequence time-series, such as electricity consumption planning. Long sequence time-series forecasting ({LSTF}) demands a high prediction capacity of the model, which is the ability to capture precise long-range dependency coupling between output and input efﬁciently. Recent studies have shown the potential of Transformer to increase the prediction capacity. However, there are several severe issues with Transformer that prevent it from being directly applicable to {LSTF}, including quadratic time complexity, high memory usage, and inherent limitation of the encoder-decoder architecture. To address these issues, we design an efﬁcient transformer-based model for {LSTF}, named Informer, with three distinctive characteristics: (i) a {ProbSparse} self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, and has comparable performance on sequences’ dependency alignment. (ii) the self-attention distilling highlights dominating attention by halving cascading layer input, and efﬁciently handles extreme long input sequences. (iii) the generative style decoder, while conceptually simple, predicts the long time-series sequences at one forward operation rather than a step-by-step way, which drastically improves the inference speed of long-sequence predictions. Extensive experiments on four large-scale datasets demonstrate that Informer signiﬁcantly outperforms existing methods and provides a new solution to the {LSTF} problem.},
  number     = {{arXiv}:2012.07436},
  publisher  = {{arXiv}},
  author     = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  urldate    = {2023-07-25},
  date       = {2021-03-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2012.07436 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, /unread, Computer Science - Information Retrieval},
  file       = {2021_Informer_Zhou et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CHKIVDKJ\\2021_Informer_Zhou et al.pdf:application/pdf}
}

@misc{zhou_one_2023,
  title      = {One Fits All:Power General Time Series Analysis by Pretrained {LM}},
  url        = {http://arxiv.org/abs/2302.11939},
  shorttitle = {One Fits All},
  abstract   = {Although we have witnessed great success of pre-trained models in natural language processing ({NLP}) and computer vision ({CV}), limited progress has been made for general time series analysis. Unlike {NLP} and {CV} where a unified model can be used to perform different tasks, specially designed approach still dominates in each time series analysis task such as classification, anomaly detection, forecasting, and few-shot learning. The main challenge that blocks the development of pre-trained model for time series analysis is the lack of a large amount of data for training. In this work, we address this challenge by leveraging language or {CV} models, pre-trained from billions of tokens, for time series analysis. Specifically, we refrain from altering the self-attention and feedforward layers of the residual blocks in the pre-trained language or image model. This model, known as the Frozen Pretrained Transformer ({FPT}), is evaluated through fine-tuning on all major types of tasks involving time series. Our results demonstrate that pre-trained models on natural language or images can lead to a comparable or state-of-the-art performance in all main time series analysis tasks, as illustrated in Figure 1. We also found both theoretically and empirically that the self-attention module behaviors similarly to principle component analysis ({PCA}), an observation that helps explains how transformer bridges the domain gap and a crucial step towards understanding the universality of a pre-trained transformer.The code is publicly available at https://github.com/{DAMO}-{DI}-{ML}/One\_Fits\_All.},
  number     = {{arXiv}:2302.11939},
  publisher  = {{arXiv}},
  author     = {Zhou, Tian and Niu, {PeiSong} and Wang, Xue and Sun, Liang and Jin, Rong},
  urldate    = {2023-10-18},
  date       = {2023-10-15},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2302.11939 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
  file       = {2023_One Fits All_Zhou et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\WM7BIIBX\\2023_One Fits All_Zhou et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\UPTRNXQT\\2302.html:text/html;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\5ANCVEZR\\2302.html:text/html}
}

@misc{zhou_one_2023-1,
  title      = {One Fits All: Universal Time Series Analysis by Pretrained {LM} and Specially Designed Adaptors},
  url        = {http://arxiv.org/abs/2311.14782},
  doi        = {10.48550/arXiv.2311.14782},
  shorttitle = {One Fits All},
  abstract   = {Despite the impressive achievements of pre-trained models in the fields of natural language processing ({NLP}) and computer vision ({CV}), progress in the domain of time series analysis has been limited. In contrast to {NLP} and {CV}, where a single model can handle various tasks, time series analysis still relies heavily on task-specific methods for activities such as classification, anomaly detection, forecasting, and few-shot learning. The primary obstacle to developing a pre-trained model for time series analysis is the scarcity of sufficient training data. In our research, we overcome this obstacle by utilizing pre-trained models from language or {CV}, which have been trained on billions of data points, and apply them to time series analysis. We assess the effectiveness of the pre-trained transformer model in two ways. Initially, we maintain the original structure of the self-attention and feedforward layers in the residual blocks of the pre-trained language or image model, using the Frozen Pre-trained Transformer ({FPT}) for time series analysis with the addition of projection matrices for input and output. Additionally, we introduce four unique adapters, designed specifically for downstream tasks based on the pre-trained model, including forecasting and anomaly detection. These adapters are further enhanced with efficient parameter tuning, resulting in superior performance compared to all state-of-the-art methods.Our comprehensive experimental studies reveal that (a) the simple {FPT} achieves top-tier performance across various time series analysis tasks; and (b) fine-tuning the {FPT} with the custom-designed adapters can further elevate its performance, outshining specialized task-specific models.},
  number     = {{arXiv}:2311.14782},
  publisher  = {{arXiv}},
  author     = {Zhou, Tian and Niu, Peisong and Wang, Xue and Sun, Liang and Jin, Rong},
  urldate    = {2023-12-21},
  date       = {2023-11-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.14782 [cs]},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2023_One Fits All_Zhou et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\A5TMTF97\\2023_One Fits All_Zhou et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\HDBYAQW8\\2311.html:text/html}
}

@misc{zhou_scalable_2024,
  title      = {Scalable Transformer for High Dimensional Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2408.04245},
  doi        = {10.1145/3627673.3679757},
  abstract   = {Deep models for Multivariate Time Series ({MTS}) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional {MTS} data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address these issues, we propose {STHD}, the Scalable Transformer for High-Dimensional Multivariate Time Series Forecasting. {STHD} has three components: a) Relation Matrix Sparsity that limits the noise introduced and alleviates the memory issue; b) {ReIndex} applied as a training strategy to enable a more flexible batch size setting and increase the diversity of training data; and c) Transformer that handles 2-D inputs and captures channel dependencies. These components jointly enable {STHD} to manage the high-dimensional {MTS} while maintaining computational feasibility. Furthermore, experimental results show {STHD}'s considerable improvement on three high-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source code and dataset are publicly available https://github.com/xinzzzhou/{ScalableTransformer}4HighDimensionMTSF.git.},
  author     = {Zhou, Xin and Wang, Weiqing and Buntine, Wray and Qu, Shilin and Sriramulu, Abishek and Tan, Weicong and Bergmeir, Christoph},
  urldate    = {2024-08-13},
  date       = {2024-08-08},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2408.04245 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Information Retrieval, H.3},
  file       = {2024_Scalable Transformer for High Dimensional Multivariate Time Series Forecasting_Zhou et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CES626G4\\2024_Scalable Transformer for High Dimensional Multivariate Time Series Forecasting_Zhou et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JFXXIAJZ\\2408.html:text/html}
}

@misc{zhou_unveiling_2025,
  title      = {Unveiling the Potential of Text in High-Dimensional Time Series Forecasting},
  url        = {http://arxiv.org/abs/2501.07048},
  doi        = {10.48550/arXiv.2501.07048},
  abstract   = {Time series forecasting has traditionally focused on univariate and multivariate numerical data, often overlooking the benefits of incorporating multimodal information, particularly textual data. In this paper, we propose a novel framework that integrates time series models with Large Language Models to improve high-dimensional time series forecasting. Inspired by multimodal models, our method combines time series and textual data in the dual-tower structure. This fusion of information creates a comprehensive representation, which is then processed through a linear layer to generate the final forecast. Extensive experiments demonstrate that incorporating text enhances high-dimensional time series forecasting performance. This work paves the way for further research in multimodal time series forecasting.},
  number     = {{arXiv}:2501.07048},
  publisher  = {{arXiv}},
  author     = {Zhou, Xin and Wang, Weiqing and Qu, Shilin and Zhang, Zhiqiang and Bergmeir, Christoph},
  urldate    = {2025-03-06},
  date       = {2025-01-13},
  eprinttype = {arxiv},
  eprint     = {2501.07048 [cs]},
  note       = {{TLDR}: A novel framework that integrates time series models with Large Language Models to improve high-dimensional time series forecasting, Inspired by multimodal models, which combines time series and textual data in the dual-tower structure.},
  keywords   = {Computer Science - Artificial Intelligence, ⭐},
  file       = {Preprint PDF:C\:\\Users\\yanha\\Zotero\\storage\\RCG8U7DL\\Zhou 等 - 2025 - Unveiling the Potential of Text in High-Dimensional Time Series Forecasting.pdf:application/pdf;Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\JP2RYAJS\\2501.html:text/html}
}

@inproceedings{zhou2021informer,
  title     = {Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author    = {Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume    = {35},
  number    = {12},
  pages     = {11106--11115},
  year      = {2021}
}

@article{zhou2022film,
  title   = {Film: Frequency improved legendre memory model for long-term time series forecasting},
  author  = {Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Sun, Liang and Yao, Tao and Yin, Wotao and Jin, Rong and others},
  journal = {Advances in neural information processing systems},
  volume  = {35},
  pages   = {12677--12690},
  year    = {2022}
}

@misc{zhu_language_2024,
  title      = {A Language Model-Guided Framework for Mining Time Series with Distributional Shifts},
  url        = {http://arxiv.org/abs/2406.05249},
  doi        = {10.48550/arXiv.2406.05249},
  abstract   = {Effective utilization of time series data is often constrained by the scarcity of data quantity that reflects complex dynamics, especially under the condition of distributional shifts. Existing datasets may not encompass the full range of statistical properties required for robust and comprehensive analysis. And privacy concerns can further limit their accessibility in domains such as finance and healthcare. This paper presents an approach that utilizes large language models and data source interfaces to explore and collect time series datasets. While obtained from external sources, the collected data share critical statistical properties with primary time series datasets, making it possible to model and adapt to various scenarios. This method enlarges the data quantity when the original data is limited or lacks essential properties. It suggests that collected datasets can effectively supplement existing datasets, especially involving changes in data distribution. We demonstrate the effectiveness of the collected datasets through practical examples and show how time series forecasting foundation models fine-tuned on these datasets achieve comparable performance to those models without fine-tuning.},
  number     = {{arXiv}:2406.05249},
  publisher  = {{arXiv}},
  author     = {Zhu, Haibei and El-Laham, Yousef and Fons, Elizabeth and Vyetrenko, Svitlana},
  urldate    = {2024-08-06},
  date       = {2024-06-07},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2406.05249 [cs]},
  keywords   = {/reading, Computer Science - Artificial Intelligence, Computer Science - Computational Engineering, Finance, and Science},
  file       = {2024_A Language Model-Guided Framework for Mining Time Series with Distributional_Zhu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\CC4Z5Z7H\\2024_A Language Model-Guided Framework for Mining Time Series with Distributional_Zhu et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\PWC2YLYR\\2406.html:text/html}
}

@online{zhu_xtab_2023,
  title      = {{XTab}: Cross-table Pretraining for Tabular Transformers},
  url        = {https://arxiv.org/abs/2305.06090v1},
  shorttitle = {{XTab}},
  abstract   = {The success of self-supervised learning in computer vision and natural language processing has motivated pretraining methods on tabular data. However, most existing tabular self-supervised learning models fail to leverage information across multiple data tables and cannot generalize to new tables. In this work, we introduce {XTab}, a framework for cross-table pretraining of tabular transformers on datasets from various domains. We address the challenge of inconsistent column types and quantities among tables by utilizing independent featurizers and using federated learning to pretrain the shared component. Tested on 84 tabular prediction tasks from the {OpenML}-{AutoML} Benchmark ({AMLB}), we show that (1) {XTab} consistently boosts the generalizability, learning speed, and performance of multiple tabular transformers, (2) by pretraining {FT}-Transformer via {XTab}, we achieve superior performance than other state-of-the-art tabular deep learning models on various tasks such as regression, binary, and multiclass classification.},
  titleaddon = {{arXiv}.org},
  author     = {Zhu, Bingzhao and Shi, Xingjian and Erickson, Nick and Li, Mu and Karypis, George and Shoaran, Mahsa},
  urldate    = {2024-01-10},
  date       = {2023-05-10},
  langid     = {english},
  keywords   = {/reading},
  file       = {2023_XTab_Zhu et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\383XQQMA\\2023_XTab_Zhu et al.pdf:application/pdf}
}

@misc{zuo_spatiotemporal-linear_2023,
  title      = {Spatiotemporal-Linear: Towards Universal Multivariate Time Series Forecasting},
  url        = {http://arxiv.org/abs/2312.14869},
  doi        = {10.48550/arXiv.2312.14869},
  shorttitle = {Spatiotemporal-Linear},
  abstract   = {Within the field of complicated multivariate time series forecasting ({TSF}), popular techniques frequently rely on intricate deep learning architectures, ranging from transformer-based designs to recurrent neural networks. However, recent findings suggest that simple Linear models can surpass sophisticated constructs on diverse datasets. These models directly map observation to multiple future time steps, thereby minimizing error accumulation in iterative multi-step prediction. Yet, these models fail to incorporate spatial and temporal information within the data, which is critical for capturing patterns and dependencies that drive insightful predictions. This oversight often leads to performance bottlenecks, especially under specific sequence lengths and dataset conditions, preventing their universal application. In response, we introduce the {SpatioTemporal}-Linear ({STL}) framework. {STL} seamlessly integrates time-embedded and spatially-informed bypasses to augment the Linear-based architecture. These extra routes offer a more robust and refined regression to the data, particularly when the amount of observation is limited and the capacity of simple linear layers to capture dependencies declines. Empirical evidence highlights {STL}'s prowess, outpacing both Linear and Transformer benchmarks across varied observation and prediction durations and datasets. Such robustness accentuates its suitability across a spectrum of applications, including but not limited to, traffic trajectory and rare disease progression forecasting. Through this discourse, we not only validate the {STL}'s distinctive capacities to become a more general paradigm in multivariate time-series prediction using deep-learning techniques but also stress the need to tackle data-scarce prediction scenarios for universal application. Code will be made available.},
  number     = {{arXiv}:2312.14869},
  publisher  = {{arXiv}},
  author     = {Zuo, Aiyinsi and Zhang, Haixi and Li, Zirui and Zheng, Ce},
  urldate    = {2024-01-05},
  date       = {2023-12-22},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2312.14869 [cs]},
  note       = {{TLDR}: The {SpatioTemporal}-Linear ({STL}) framework is introduced, which validate the {STL}'s distinctive capacities to become a more general paradigm in multivariate time-series prediction using deep-learning techniques but also stress the need to tackle data-scarce prediction scenarios for universal application.},
  keywords   = {/reading, Computer Science - Machine Learning},
  file       = {2023_Spatiotemporal-Linear_Zuo et al.pdf:C\:\\Users\\yanha\\Zotero\\storage\\32CX36JU\\2023_Spatiotemporal-Linear_Zuo et al.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\yanha\\Zotero\\storage\\6DMD4Z9K\\2312.html:text/html}
}

@article{qwen,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={arXiv preprint arXiv:2309.16609},
  year={2023}
}