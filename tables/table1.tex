\begin{table}[ht]
    \centering
    \caption{Comparison of forecasting metrics (MAE, MSE and WAPE) under routine traffic conditions for different prediction horizons (15, 30, 60 min, and average). Models compared include our pre-trained spatio-temporal model and selected deep learning baselines (e.g., DLinear, FiLM, Informer, PatchTST, Chronos, iTransformer) on the Beijing dataset. Best results for each metric and horizon are highlighted.}
    \resizebox{\textwidth}{!}{
      \begin{tabular}{@{}cllllllllllll@{}}
    \toprule
    \multicolumn{1}{l}{} &
      \multicolumn{3}{c}{\textbf{15 min}} &
      \multicolumn{3}{c}{\textbf{30 min}} &
      \multicolumn{3}{c}{\textbf{60 min}} &
      \multicolumn{3}{c}{\textbf{Average}} \\ 
    \multicolumn{1}{l}{} &
      \multicolumn{1}{c}{\textbf{MAE}} &
      \multicolumn{1}{c}{\textbf{MSE}} &
      \multicolumn{1}{c}{\textbf{WAPE}} &
      \multicolumn{1}{c}{\textbf{MAE}} &
      \multicolumn{1}{c}{\textbf{MSE}} &
      \multicolumn{1}{c}{\textbf{WAPE}} &
      \multicolumn{1}{c}{\textbf{MAE}} &
      \multicolumn{1}{c}{\textbf{MSE}} &
      \multicolumn{1}{c}{\textbf{WAPE}} &
      \multicolumn{1}{c}{\textbf{MAE}} &
      \multicolumn{1}{c}{\textbf{MSE}} &
      \multicolumn{1}{c}{\textbf{WAPE}} \\ \midrule
    \textbf{DLinear} &
      0.270 &
      0.139 &
      0.384 &
      0.374 &
      0.257 &
      0.532 &
      0.542 &
      0.508 &
      0.769 &
      0.383 &
      0.285 &
      0.545 \\
    \textbf{FiLM} &
      0.423 &
      0.301 &
      0.602 &
      0.534 &
      0.491 &
      0.759 &
      0.669 &
      0.772 &
      0.949 &
      0.527 &
      0.496 &
      0.748 \\
    \textbf{Informer} &
      0.161 &
      0.060 &
      0.229 &
      0.167 &
      0.066 &
      0.237 &
      0.176 &
      0.074 &
      0.249 &
      0.166 &
      0.066 &
      0.236 \\
    \textbf{PatchTST} &
      0.201 &
      0.090 &
      0.286 &
      0.251 &
      0.147 &
      0.356 &
      0.347 &
      0.285 &
      0.491 &
      0.259 &
      0.164 &
      0.368 \\
    \textbf{chronos-b} &
      0.423 &
      0.427 &
      0.561 &
      0.342 &
      0.323 &
      0.495 &
      0.291 &
      0.325 &
      0.425 &
      0.424 &
      0.489 &
      0.602 \\
    \textbf{chronos-m} &
      0.433 &
      0.426 &
      0.574 &
      0.351 &
      0.328 &
      0.508 &
      0.301 &
      0.343 &
      0.440 &
      0.431 &
      0.495 &
      0.613 \\
    \textbf{chronos-s} &
      0.439 &
      0.443 &
      0.582 &
      0.349 &
      0.325 &
      0.505 &
      0.311 &
      0.374 &
      0.454 &
      0.436 &
      0.504 &
      0.620 \\
    \textbf{iTransformer} &
      0.194 &
      0.088 &
      0.275 &
      0.226 &
      0.130 &
      0.321 &
      0.293 &
      0.234 &
      0.416 &
      0.233 &
      0.143 &
      0.331 \\  \midrule
    \textbf{Ours} &
      \textbf{0.153} &
      \textbf{0.055} &
      \textbf{0.217} &
      \textbf{0.151} &
      \textbf{0.054} &
      \textbf{0.215} &
      \textbf{0.158} &
      \textbf{0.058} &
      \textbf{0.225} &
      \textbf{0.153} &
      \textbf{0.055} &
      \textbf{0.217} \\ \bottomrule
    \end{tabular}} \label{table:1}
  \end{table}